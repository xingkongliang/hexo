<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Tianliang</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.starlg.cn/"/>
  <updated>2019-07-13T07:46:08.388Z</updated>
  <id>https://www.starlg.cn/</id>
  
  <author>
    <name>Tianliang Zhang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>复式记账 Beancount 使用</title>
    <link href="https://www.starlg.cn/2019/07/13/Beancount-01/"/>
    <id>https://www.starlg.cn/2019/07/13/Beancount-01/</id>
    <published>2019-07-13T04:00:07.000Z</published>
    <updated>2019-07-13T07:46:08.388Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Beancount"><a href="#Beancount" class="headerlink" title="Beancount"></a>Beancount</h1><h2 id="Beancount-安装"><a href="#Beancount-安装" class="headerlink" title="Beancount 安装"></a>Beancount 安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 首先安装 beancount</span><br><span class="line">pip install beancount</span><br><span class="line"># 然后安装 fava</span><br><span class="line">pip install fava</span><br></pre></td></tr></table></figure><p>Fava 是复式簿记软件 Beancount 的 Web 界面，侧重于功能和可用性，使用非常友好。</p><p>我们可以先使用 <code>bean-exampl</code> 生成一个 <code>Beancount</code> 文件，文件的后缀名可以自己定义，一般用<code>.bean</code>或<code>.beancount</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">(base) XX@XX:~$ mkdir MyBean</span><br><span class="line">(base) XX@XX:~$ cd MyBean/</span><br><span class="line">(base) XX@XX:~/MyBean$ ls</span><br><span class="line">(base) XX@XX:~/MyBean$ bean-example &gt; example.bean</span><br><span class="line">INFO    : Generating Salary Employment Income</span><br><span class="line">INFO    : Generating Expenses from Banking Accounts</span><br><span class="line">INFO    : Generating Regular Expenses via Credit Card</span><br><span class="line">INFO    : Generating Credit Card Expenses for Trips</span><br><span class="line">INFO    : Generating Credit Card Payment Entries</span><br><span class="line">INFO    : Generating Tax Filings and Payments</span><br><span class="line">INFO    : Generating Opening of Banking Accounts</span><br><span class="line">INFO    : Generating Transfers to Investment Account</span><br><span class="line">INFO    : Generating Prices</span><br><span class="line">INFO    : Generating Employer Match Contribution</span><br><span class="line">INFO    : Generating Retirement Investments</span><br><span class="line">INFO    : Generating Taxes Investments</span><br><span class="line">INFO    : Generating Expense Accounts</span><br><span class="line">INFO    : Generating Equity Accounts</span><br><span class="line">INFO    : Generating Balance Checks</span><br><span class="line">INFO    : Outputting and Formatting Entries</span><br><span class="line">INFO    : Contextualizing to Realistic Names</span><br><span class="line">INFO    : Writing contents</span><br><span class="line">INFO    : Validating Results</span><br><span class="line">(base) XX@XX:~/MyBean$ ls</span><br><span class="line">example.bean</span><br></pre></td></tr></table></figure><p>运行 Beancount:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(base) XX@XX:~/MyBean$ fava example.bean</span><br><span class="line">Running Fava on http://localhost:5000</span><br></pre></td></tr></table></figure></p><p>在浏览器上打开 <a href="http://localhost:5000" target="_blank" rel="noopener">http://localhost:5000</a> ，就可以看到运行界面，如下：</p><img src="/2019/07/13/Beancount-01/beancount-fava-interface.png" title="Beancount 运行界面"><h2 id="example-bean-文件分析"><a href="#example-bean-文件分析" class="headerlink" title="example.bean 文件分析"></a>example.bean 文件分析</h2><p>复式记账的最基本的特点就是以账户为核心，Beancount的系统整体上就是围绕账户来实现的。之前提到的会计恒等式中有资产、负债和权益三大部分，现在我们再增加两个类别，分别是收入和支出。Beancount系统中预定义了五个分类：</p><ul><li>Assets 资产</li><li>Liabilities 负债</li><li>Equity 权益（净资产）</li><li>Expenses 支出</li><li>Income 收入</li></ul><h3 id="表头信息"><a href="#表头信息" class="headerlink" title="表头信息"></a>表头信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">;; -*- mode: org; mode: beancount; -*-</span><br><span class="line">;; Birth: 1980-05-12</span><br><span class="line">;; Dates: 2017-01-01 - 2019-07-12</span><br><span class="line">;; THIS FILE HAS BEEN AUTO-GENERATED.</span><br><span class="line">* Options</span><br><span class="line"></span><br><span class="line">option &quot;title&quot; &quot;Example Beancount file&quot;</span><br><span class="line">option &quot;operating_currency&quot; &quot;USD&quot;</span><br></pre></td></tr></table></figure><p>Beancount 文件中注释使用<code>;</code>作为标记。</p><p>这里定义了项目的名词：<code>Example Beancount file</code>，和使用的货币种类：美元 <code>USD</code>。我们如果想使用人民币，可以同时添加 <code>CNY</code>，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">option &quot;operating_currency&quot; &quot;CNY&quot;</span><br></pre></td></tr></table></figure><h3 id="Assets-资产"><a href="#Assets-资产" class="headerlink" title="Assets 资产"></a>Assets 资产</h3><p>顾名思义，<strong>Asserts</strong> 就相当于我们的存放 <strong>资产的账户</strong>，如果启用一个账户就使用 <code>open</code> 命令。</p><p>第一列是账户启用时间，第二列是命令，第三列是资产（Assets）名，最后一列是使用的货币种类。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">* Assets</span><br><span class="line"></span><br><span class="line">1990-09-04 open Assets:Cash:CNY CNY                    ; 人民币现金账户</span><br><span class="line">1990-09-04 open Assets:Cash:USD USD                    ; 美元现金账户</span><br><span class="line"></span><br><span class="line">1990-09-04 open Assets:Bank:China:CCB:CardXXX1 CNY     ; 银行账户</span><br><span class="line">1990-09-04 open Assets:Bank:China:CCB:CardXXX8 CNY     ; 银行账户</span><br><span class="line"></span><br><span class="line">1990-09-04 open Assets:Account:China:Alipay CNY        ; 支付宝账户</span><br><span class="line">1990-09-04 open Assets:Account:China:WeChat CNY        ; 微信账户</span><br><span class="line"></span><br><span class="line">1990-09-04 open Assets:Stock:China:GTJA2818 CNY        ; 股票账户</span><br></pre></td></tr></table></figure><p>我的命名规则是：资产：账户类型：国别：（银行缩写：银行卡号）/（账户名）</p><h3 id="Income-收入"><a href="#Income-收入" class="headerlink" title="Income 收入"></a>Income 收入</h3><p>这里定义我们的 <strong>收入来源</strong>，同样如果启用一个收入来源就使用 <code>open</code> 命令。</p><p>第一列是启用时间，第二列是命令，第三列是收入来源，最后一列是使用的货币种类。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">* Income</span><br><span class="line"></span><br><span class="line">1990-09-04 open Income:China:XXXCompany:Salary              CNY</span><br><span class="line">1990-09-04 open Income:China:PartTimeJob:Salary             CNY</span><br><span class="line">1990-09-04 open Income:China:Home:RedPacket                 CNY</span><br><span class="line">1990-09-04 open Income:China:Fund:Tianhong                  CNY</span><br></pre></td></tr></table></figure><h3 id="Expenses-支出"><a href="#Expenses-支出" class="headerlink" title="Expenses 支出"></a>Expenses 支出</h3><p>这里我们定义 <strong>花费支出</strong>，我根据自己的花销，把花费支出定义为 5 大组类，分别是：Food，Transport，Life，Fun，Health，Home，其中每个大类又有若干子类。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">* Expenses</span><br><span class="line"></span><br><span class="line">1990-09-04 open Expenses:Food:Groceries           ; 杂货店</span><br><span class="line">1990-09-04 open Expenses:Food:Restaurant          ; 餐馆</span><br><span class="line">1990-09-04 open Expenses:Food:Canteen             ; 食堂</span><br><span class="line">1990-09-04 open Expenses:Food:Cooking             ; 烹饪</span><br><span class="line">1990-09-04 open Expenses:Food:Drinks</span><br><span class="line">1990-09-04 open Expenses:Food:Fruits</span><br><span class="line"></span><br><span class="line">1990-09-04 open Expenses:Transport:TransCard</span><br><span class="line">1990-09-04 open Expenses:Transport:Airline</span><br><span class="line">1990-09-04 open Expenses:Transport:Train</span><br><span class="line">1990-09-04 open Expenses:Transport:Taxi</span><br><span class="line"></span><br><span class="line">1990-09-04 open Expenses:Life:Clothing</span><br><span class="line">1990-09-04 open Expenses:Life:RedPacket</span><br><span class="line">1990-09-04 open Expenses:Life:Sports</span><br><span class="line">1990-09-04 open Expenses:Life:Shopping</span><br><span class="line">1990-09-04 open Expenses:Life:Commodity           ; 商品</span><br><span class="line">1990-09-04 open Expenses:Life:SoftwareAndGame</span><br><span class="line">1990-09-04 open Expenses:Life:Vacation</span><br><span class="line">1990-09-04 open Expenses:Life:Others</span><br><span class="line"></span><br><span class="line">1990-09-04 open Expenses:Fun:Amusement</span><br><span class="line"></span><br><span class="line">1990-09-04 open Expenses:Health:Hospital</span><br><span class="line">1990-09-04 open Expenses:Health:Drug</span><br><span class="line"></span><br><span class="line">1990-09-04 open Expenses:Study:Book</span><br><span class="line">1990-09-04 open Expenses:Study:Tuition</span><br><span class="line">1990-09-04 open Expenses:Study:Others</span><br><span class="line"></span><br><span class="line">1990-09-04 open Expenses:Home:Rent</span><br><span class="line">1990-09-04 open Expenses:Home:Water</span><br><span class="line">1990-09-04 open Expenses:Home:Electricity</span><br><span class="line">1990-09-04 open Expenses:Home:Internet</span><br><span class="line">1990-09-04 open Expenses:Home:Phone</span><br></pre></td></tr></table></figure><p>最后我们记录的花销就会以下图呈现出来：</p><img src="/2019/07/13/Beancount-01/beancount-expenses.png" title="Expenses 截图"><h3 id="Liabilities-负债"><a href="#Liabilities-负债" class="headerlink" title="Liabilities 负债"></a>Liabilities 负债</h3><p>负债这里我开启了一张信用卡。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">* Liabilities</span><br><span class="line"></span><br><span class="line">1990-09-04 open Liabilities:China:CreditCard:CCB:CardXXX8 CNY</span><br></pre></td></tr></table></figure><h3 id="Equity-权益（净资产）"><a href="#Equity-权益（净资产）" class="headerlink" title="Equity 权益（净资产）"></a>Equity 权益（净资产）</h3><p>目前我只设置了一个 Equity 账户 Equity:Opening-Balances，用来平衡初始资产、负债账户时的会计恒等式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">* Equity</span><br><span class="line">1990-09-04 open Equity:Opening-Balances</span><br></pre></td></tr></table></figure><h2 id="什么是复式记账法"><a href="#什么是复式记账法" class="headerlink" title="什么是复式记账法?"></a>什么是复式记账法?</h2><p>复式记账法是以资产与权益平衡关系作为记账基础，对于每一笔经济业务，都要以相等的金额在两个或两个以上相互联系的账户中进行登记，系统地反映资金运动变化结果的一种记账方法。</p><p>复式记账是对每一项经济业务通过两个或两个以上有关账户相互联系起来进行登记的一种专门方法。任何一项经济活动都会引起资金的增减变动或财务收支的变动。</p><p>以上内容来自<a href="https://baike.baidu.com/item/%E5%A4%8D%E5%BC%8F%E8%AE%B0%E8%B4%A6/10359133?fr=aladdin" target="_blank" rel="noopener">百度百科</a>。</p><h2 id="如何记账"><a href="#如何记账" class="headerlink" title="如何记账"></a>如何记账</h2><p>当前账本的交易记录主要分为三种：记录收益，记录支出，结余调整。下面分别展开进行介绍。</p><h3 id="如何记录收益"><a href="#如何记录收益" class="headerlink" title="如何记录收益"></a>如何记录收益</h3><p>我们首先记录一下收入情况，我们将公司<code>CompanyA</code>和公司<code>CompanyB</code>的薪水转移到资产<code>Assets:Bank:China:CCB:CardXXX1</code>中，这个资产定义的是我的银行卡。双引号中间的内容是注释性说明。要确保转移数值平衡，即相加为 0 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">2019-06-21 * &quot;CompanyA&quot; &quot;Salary&quot;</span><br><span class="line">  Assets:Bank:China:CCB:CardXXX1                            13000.00 CNY</span><br><span class="line">  Income:China:CompanyA:Salary                             -13000.00 CNY</span><br><span class="line"></span><br><span class="line">2019-06-18 * &quot;CompanyB&quot; &quot;Salary&quot;</span><br><span class="line">  Assets:Bank:China:CCB:CardXXX1                            9000.00 CNY</span><br><span class="line">  Income:China:CompanyB:Salary                             -9000.00 CNY</span><br></pre></td></tr></table></figure><p>以上内容可以直接写到<code>.bean</code>文件中。</p><h3 id="如何记录消费"><a href="#如何记录消费" class="headerlink" title="如何记录消费"></a>如何记录消费</h3><p>记录消费情况和记录收益情况类似，但是要注意资产转移的方向，即数值的正负号。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">2019-04-17 * &quot;储蓄卡&quot; &quot;餐饮(储蓄卡)&quot;</span><br><span class="line">  Assets:Bank:China:CCB:CardXXX1  -35 CNY</span><br><span class="line">  Expenses:Food:Canteen            35 CNY</span><br><span class="line"></span><br><span class="line">2019-04-18 * &quot;储蓄卡&quot; &quot;餐饮(储蓄卡)&quot;</span><br><span class="line">  Assets:Bank:China:CCB:CardXXX1  -5 CNY</span><br><span class="line">  Expenses:Food:Canteen            5 CNY</span><br><span class="line"></span><br><span class="line">2019-04-20 * &quot;储蓄卡&quot; &quot;餐饮 金稻园&quot;</span><br><span class="line">  Assets:Bank:China:CCB:CardXXX1  -283 CNY</span><br><span class="line">  Expenses:Food:Restaurant         283 CNY</span><br><span class="line"></span><br><span class="line">2019-04-20 * &quot;储蓄卡&quot; &quot;水果(储蓄卡)&quot;</span><br><span class="line">  Assets:Bank:China:CCB:CardXXX1  -20.4 CNY</span><br><span class="line">  Expenses:Food:Fruits             20.4 CNY</span><br></pre></td></tr></table></figure><p>以上内容也可以直接写到<code>.bean</code>文件中。</p><h3 id="结余调整"><a href="#结余调整" class="headerlink" title="结余调整"></a>结余调整</h3><p>我们并不能完全记录每一笔收入和支出情况，所以会造成账本资产情况和实际资产情况数值不符。但是对于小数额的差值，我们可以使用结余调整。这样就把差值的资产补回来了。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2019-01-01 * &quot;结余调整&quot;</span><br><span class="line">  Assets:Bank:China:CCB:CardXXX1    200 CNY</span><br><span class="line">  Equity:Opening-Balances          -200 CNY</span><br></pre></td></tr></table></figure><p>上边的意思是，从账户 <code>Equity:Opening-Balances</code> 转给账户 <code>Assets:Bank:China:CCB:CardXXX1</code>。Beancount的规范是使用 <code>Equity:Opening-Balances</code>。<code>Equity:Opening-Balances</code> 是权益类别下面的账户，可以表示没有记录来源的资产。</p><h2 id="Beancount-项目目录结构"><a href="#Beancount-项目目录结构" class="headerlink" title="Beancount 项目目录结构"></a>Beancount 项目目录结构</h2><p>本人认为按照时间顺序记录账本的方法比较方便，所以我目前使用的目录结构如下；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">~/Documents/MyBean</span><br><span class="line">├── data</span><br><span class="line">│   ├── 2017.bean</span><br><span class="line">│   ├── 2018.bean</span><br><span class="line">│   └── 2017.bean</span><br><span class="line">├── documents.tmp/</span><br><span class="line">├── Importers</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── regexp.py    // 原来在位于 beancount/experiments/ingest/regexp.py</span><br><span class="line">│   └── alipay.py</span><br><span class="line">├── configs</span><br><span class="line">│   ├── alipay.config</span><br><span class="line">│   └── wechat.config</span><br><span class="line">├── main.bean</span><br><span class="line">└── strip_blank.py</span><br></pre></td></tr></table></figure></p><ul><li>main.bean：主要记录账户信息，包括 Assets，Liabilities，Equity，Expenses，Income 各类账户。其次使用 <code>include</code> 命令包含其他账本文件（<code>.bean</code>）；</li><li>data/：按照时间顺序存放收入和交易记录的账本文件（<code>.bean</code>）；</li><li>documents.tmp/：用于存放支付宝和微信的下载的交易记录文件（<code>.csv</code>）；</li><li>Importers/：用于存放自定义的导入脚本;</li><li>configs/：xxxx.config 文件负责定义如何阅读并提取csv账单文件；</li><li>strip_blank.py：删除 csv 文件中的所有多余空格的脚本；</li></ul><p>当然也有其他的目录结构，如 <a href="https://yuchi.me/post/beancount-intro/" target="_blank" rel="noopener">blog</a> 中提到的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">~/Documents/accounting</span><br><span class="line">├── documents</span><br><span class="line">│   ├── Assets/</span><br><span class="line">│   ├── Expenses/</span><br><span class="line">│   ├── Income/</span><br><span class="line">│   └── Liabilities/</span><br><span class="line">├── documents.tmp/</span><br><span class="line">├── importers</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">├── yc.bean</span><br><span class="line">└── yc.import</span><br></pre></td></tr></table></figure><h2 id="如何在主文件下包含其他-bean-文件"><a href="#如何在主文件下包含其他-bean-文件" class="headerlink" title="如何在主文件下包含其他 bean 文件"></a>如何在主文件下包含其他 bean 文件</h2><p>在上个章节–Beancount 项目目录结构–中，我们按照时间顺序存放收入和交易记录的账本文件（<code>.bean</code>），例如：2017.bean，2018.bean，2019.bean，那我们如何在主文件中导入这些子文件呢？可以使用 <code>include</code> 命令，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">* Include</span><br><span class="line"></span><br><span class="line">include &quot;data/2017.bean&quot;</span><br><span class="line">include &quot;data/2018.bean&quot;</span><br><span class="line">include &quot;data/2019.bean&quot;</span><br></pre></td></tr></table></figure><p>如果我们想把工资收入情况做单独的记录，那么可以单独建立一个 <code>Income.bean</code> 文件，然后在使用 <code>include</code> 命令包含进来。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">include &quot;Income/Income.bean&quot;</span><br></pre></td></tr></table></figure><h2 id="使用-CSV-账单文件生成流水-bean文件"><a href="#使用-CSV-账单文件生成流水-bean文件" class="headerlink" title="使用 CSV 账单文件生成流水.bean文件"></a>使用 CSV 账单文件生成流水<code>.bean</code>文件</h2><p>我们时间和精力有限，所以并不能手工记录每一次交易情况。为了方便生成交易账单，我们可以下载支付宝、微信、银行等交易记录，并且使用程序将他们转化为账单文件（<code>.bean</code>）。这样节省了很多时间，并且记录准确。</p><h3 id="bean-extract-命令"><a href="#bean-extract-命令" class="headerlink" title="bean-extract 命令"></a>bean-extract 命令</h3><p><code>bean-extract</code> 命令: 从每个文件中提取交易和日期。这会生成一些 Beancount 输入文本，这些文本（<code>.bean</code>）文件移动到您的输入文件中;</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bean-extract blais.config ~/Downloads</span><br></pre></td></tr></table></figure><h3 id="支付宝账单处理过程"><a href="#支付宝账单处理过程" class="headerlink" title="支付宝账单处理过程"></a>支付宝账单处理过程</h3><p>可以参考 <a href="http://lidongchao.com/2018/07/20/has_header_in_csv_Sniffer/" target="_blank" rel="noopener">blog</a>。</p><ol><li>先把 csv 使用 wps 转换为 xls；</li><li><p>在使用 pandas 将 xls 转换为 utf-8 格式的 csv；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data_xls = pd.read_excel(<span class="string">'alipay_record_20190712_2003_1.xls'</span>, index_col=<span class="number">0</span>)                                                                      </span><br><span class="line">data_xls.to_csv(<span class="string">'alipay_tmp.csv'</span>, encoding=<span class="string">'utf-8'</span>)</span><br></pre></td></tr></table></figure></li><li><p>最后去除首尾的非数据信息;</p></li><li><p>使用 strip_blank.py 删除文件中的所有多余空格;</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python strip_blank.py alipay_tmp.csv &gt; alipay.csv</span><br></pre></td></tr></table></figure></li><li><p>使用bean-extract提取beancount数据。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bean-extract my_alipay.config alipay.csv &gt; data_alipay.beancount</span><br></pre></td></tr></table></figure></li></ol><h2 id="Atom-Beancount-语法高亮工具"><a href="#Atom-Beancount-语法高亮工具" class="headerlink" title="Atom Beancount 语法高亮工具"></a>Atom Beancount 语法高亮工具</h2><p>如果你使用 Atom 打开 beancount，可以安装 language-beancount，这个库可以高亮 beancount 的语法。</p><img src="/2019/07/13/Beancount-01/language-beancount.png" title="高亮 beancount 的语法"><p><img src="language-beancount.png" alt="language-beancount"></p><h2 id="fava-使用技巧"><a href="#fava-使用技巧" class="headerlink" title="fava 使用技巧"></a>fava 使用技巧</h2><p><a href="https://beancount.github.io/fava/index.html" target="_blank" rel="noopener">https://beancount.github.io/fava/index.html</a></p><p>web端使用fava，可以远程访问。</p><p>可以使用如下命令，指定IP和端口号：<br><a href="https://github.com/beancount/fava/blob/master/contrib/deployment.rst" target="_blank" rel="noopener">https://github.com/beancount/fava/blob/master/contrib/deployment.rst</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fava --host localhost --port 5000 --prefix /fava /path/to/your/main.beancount</span><br></pre></td></tr></table></figure></p><hr><h2 id="Beancount-相关资料介绍"><a href="#Beancount-相关资料介绍" class="headerlink" title="Beancount 相关资料介绍"></a>Beancount 相关资料介绍</h2><h3 id="官方资料："><a href="#官方资料：" class="headerlink" title="官方资料："></a>官方资料：</h3><p><a href="http://furius.ca/beancount/" target="_blank" rel="noopener">Beancount官方网站</a></p><p><a href="http://furius.ca/beancount/doc/index" target="_blank" rel="noopener">Beancount官方文档</a></p><p><a href="https://groups.google.com/forum/#!forum/beancount" target="_blank" rel="noopener">Beancount邮件列表</a></p><p><a href="https://bitbucket.org/blais/beancount/src/default/" target="_blank" rel="noopener">Beancount 官方代码库 bitbucket</a></p><p><a href="https://github.com/beancount/beancount" target="_blank" rel="noopener">Beancount github</a></p><p><a href="https://beancount.github.io/fava/" target="_blank" rel="noopener">Fava</a> 是 Beancount 的 web 界面，非常友好。</p><p><a href="https://github.com/beancount/fava" target="_blank" rel="noopener">Fave github</a></p><h3 id="强烈推荐一下博客："><a href="#强烈推荐一下博客：" class="headerlink" title="强烈推荐一下博客："></a>强烈推荐一下博客：</h3><p><a href="https://www.byvoid.com/zhs/blog/beancount-bookkeeping-1" target="_blank" rel="noopener">byvoid blog</a><br>该博客介绍的非常系统</p><p><a href="http://lidongchao.com/2018/07/20/has_header_in_csv_Sniffer/" target="_blank" rel="noopener">Beancount使用经验</a><br>该博客介绍了通过Beancount导入支付宝csv账单的方法</p><p><a href="https://yuchi.me/post/beancount-intro/" target="_blank" rel="noopener">beancount 简易入门指南</a></p><p><a href="https://github.com/lidongchao/BeancountSample" target="_blank" rel="noopener">lidongchao/BeancountSample</a><br>这里包含一些代码，可以用于导入 csv 账单到 Beancount 中。</p><h3 id="其他介绍文章"><a href="#其他介绍文章" class="headerlink" title="其他介绍文章"></a>其他介绍文章</h3><p><a href="https://wzyboy.im/post/1063.html" target="_blank" rel="noopener">Beancount —— 命令行复式簿记</a></p><p><a href="http://morefreeze.github.io/2016/10/beancount-thinking.html" target="_blank" rel="noopener">beancount 起步</a></p><p><a href="http://freelancer-x.com/82/%E5%9F%BA%E7%A1%80%E8%AE%A4%E8%AF%86%EF%BD%9C%E5%88%A9%E7%94%A8-beancount-%E6%89%93%E9%80%A0%E4%B8%AA%E4%BA%BA%E7%9A%84%E8%AE%B0%E8%B4%A6%E7%B3%BB%E7%BB%9F%EF%BC%881%EF%BC%89/" target="_blank" rel="noopener">利用 Beancount 打造个人的记账系统</a></p>]]></content>
    
    <summary type="html">
    
      复式记账 Beancount 使用
    
    </summary>
    
      <category term="Tools" scheme="https://www.starlg.cn/categories/Tools/"/>
    
    
      <category term="Beancount" scheme="https://www.starlg.cn/tags/Beancount/"/>
    
      <category term="Tools" scheme="https://www.starlg.cn/tags/Tools/"/>
    
  </entry>
  
  <entry>
    <title>L2 Normalization</title>
    <link href="https://www.starlg.cn/2019/07/10/l2normalization/"/>
    <id>https://www.starlg.cn/2019/07/10/l2normalization/</id>
    <published>2019-07-10T07:38:15.000Z</published>
    <updated>2019-07-10T09:10:38.176Z</updated>
    
    <content type="html"><![CDATA[<p>论文：ParseNet: Looking Wider to See Better，<a href="https://arxiv.org/abs/1506.04579" target="_blank" rel="noopener">link</a></p><h2 id="L2-Normalization-layers"><a href="#L2-Normalization-layers" class="headerlink" title="L2 Normalization layers"></a>L2 Normalization layers</h2><p>这篇语义分割的文章提出使用 $L_2$ Normalization layers。问题提出的结构如下图所示：</p><img src="/2019/07/10/l2normalization/20190110_L2_Normalization_Figure1.png" title="Figure 1"><p>如图3所示，当我们需要组合两个或者更多的特征向量时，它们通常<strong>有不同的尺度和范数</strong>。简单的级联特征导致较差的性能，因为比较大的特征会主导较小的特征。虽然在训练期间，权重可能会相应调整，但需要非常仔细地调整参数，并且依赖于数据集，因此违背了稳健原则。我们发现，通过首先规范每个单独的特征，并学习以不同尺度进行放缩，这使得训练更加稳定，并且可以提高性能。</p><p>$L_2$ 范数层不仅在特征组合的时候使用。如上所述，在某些情况下，后期融合也同样有效，但仅在L2归一化的帮助下。例如，如果我们想使用底层的特征去学习分类器，如图3所示，一些特征可能有很大的范数。在没有只是的权重初始化和参数调整的情况下，这非常困难。关于这个策略的一个工作就是使用一个附加的卷积层，并且使用多级微调，例如底层使用更小的学习率。这违反了简单和鲁棒的原则。在这篇论文的工作中，对分类之前的特征的每个通道，作者使用了$L_2$-norm并且学习了缩放参数，这导致了更加稳定的训练。</p><img src="/2019/07/10/l2normalization/20190110_L2_Normalization_Figure3.png" title="Figure 3: 来自4个不同层的特征的激活，这些激活明显有不同的尺度。每一种颜色对饮给一个不同层的特征。蓝色和蓝绿色有着相似是尺度，红色和绿色的特征相比小了2个数量级。"><p>对于一个d维的输入 $\mathbf{x}=(x_1, …, x_d)$，我们使用 $L_2$-norm 规范它，即 $\hat{x}=\frac{x}{\lVert x \rVert_2}$，其中 $\lVert x \rVert_2=(\sum_{i=1}^{d} {\lvert x_i \rvert}^2)^{1/2}$ 是 $\mathbf{x}$ 的 $L_2$ 范数。</p><p>请注意，如果我们不相应地缩放它，只简单地规范化层的每个输入会改变层的尺度，将会减慢学习速度。例如，我们尝试规范化功能 s.t. $L_2$-norm 是1，但我们很难训练网络，因为特征变得非常小。 但是，如果我们将其规范化为，例如 10 或 20，网络开始较好的学习。在 batch normalization 和 PReLU 的推动下，我们为每个通道引入缩放参数 $\gamma_i$，它缩放了归一化的值 $y_i=\gamma_i \hat{x}_i$。</p><p>额外参数的数量等于通道的总数，并且可以忽略不计，并且可以通过反向传播来学习。 实际上，通过设置 $\gamma_i={\lVert x_i \rVert}^2$，我们可以恢复 $L_2$ 归一化的特征。这很容易实现，因为规范化和缩放参数学习仅依赖于每个输入特征向量，并且不需要像批量规范化那样聚合来自其他样本的信息。在训练期间，我们使用反向传播和链规则来计算关于缩放银子 $\gamma$ 和输入数据 $\mathbf{x}$ 的导数。</p><h2 id="Pytorch-Code"><a href="#Pytorch-Code" class="headerlink" title="Pytorch Code"></a>Pytorch Code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">x = F.normalize(x, p=<span class="number">2</span>, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">In [<span class="number">54</span>]: x = torch.randn((<span class="number">1</span>, <span class="number">1</span>, <span class="number">10</span>))                                                                                                                                                                        </span><br><span class="line"></span><br><span class="line">In [<span class="number">55</span>]: out = F.normalize(x, p=<span class="number">2</span>, dim=<span class="number">2</span>)                                                                                                                                                                   </span><br><span class="line"></span><br><span class="line">In [<span class="number">56</span>]: out                                                                                                                                                                                                </span><br><span class="line">Out[<span class="number">56</span>]:</span><br><span class="line">tensor([[[ <span class="number">0.2941</span>, <span class="number">-0.3471</span>, <span class="number">-0.0732</span>,  <span class="number">0.0674</span>, <span class="number">-0.3557</span>, <span class="number">-0.1949</span>,  <span class="number">0.6813</span>,</span><br><span class="line">          <span class="number">-0.1356</span>, <span class="number">-0.0153</span>, <span class="number">-0.3686</span>]]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">57</span>]: x / torch.sqrt((x**<span class="number">2</span>).sum(<span class="number">2</span>))                                                                                                                                                                      </span><br><span class="line">Out[<span class="number">57</span>]:</span><br><span class="line">tensor([[[ <span class="number">0.2941</span>, <span class="number">-0.3471</span>, <span class="number">-0.0732</span>,  <span class="number">0.0674</span>, <span class="number">-0.3557</span>, <span class="number">-0.1949</span>,  <span class="number">0.6813</span>,</span><br><span class="line">          <span class="number">-0.1356</span>, <span class="number">-0.0153</span>, <span class="number">-0.3686</span>]]])</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      L2 Normalization Layer
    
    </summary>
    
      <category term="Deep Learning" scheme="https://www.starlg.cn/categories/Deep-Learning/"/>
    
    
      <category term="Deep Learning" scheme="https://www.starlg.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Pandas Tutorial</title>
    <link href="https://www.starlg.cn/2019/06/23/Pandas-Tutorial/"/>
    <id>https://www.starlg.cn/2019/06/23/Pandas-Tutorial/</id>
    <published>2019-06-23T07:27:41.000Z</published>
    <updated>2019-06-24T14:12:11.807Z</updated>
    
    <content type="html"><![CDATA[<h2 id="10-Minutes-to-pandas"><a href="#10-Minutes-to-pandas" class="headerlink" title="10 Minutes to pandas"></a>10 Minutes to pandas</h2><p><a href="https://pandas.pydata.org/pandas-docs/stable/10min.html" target="_blank" rel="noopener">本文原网址</a></p><p>导入所需要的包。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">In [<span class="number">2</span>]: <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">In [<span class="number">3</span>]: <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure></p><h3 id="目标创建"><a href="#目标创建" class="headerlink" title="目标创建"></a>目标创建</h3><p>通过传递一个列表创建 <code>Series</code>，让pandas创建一个默认的整型索引：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">4</span>]: s = pd.Series([<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,np.nan,<span class="number">6</span>,<span class="number">8</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">5</span>]: s</span><br><span class="line">Out[<span class="number">5</span>]:</span><br><span class="line"><span class="number">0</span>    <span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>    <span class="number">3.0</span></span><br><span class="line"><span class="number">2</span>    <span class="number">5.0</span></span><br><span class="line"><span class="number">3</span>    NaN</span><br><span class="line"><span class="number">4</span>    <span class="number">6.0</span></span><br><span class="line"><span class="number">5</span>    <span class="number">8.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p><p>通过传递一个<code>Numpy</code>数组创建一个<code>DataFrame</code>数据，用时间和有标签的列作为索引：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">6</span>]: dates = pd.date_range(<span class="string">'20130101'</span>, periods=<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: dates</span><br><span class="line">Out[<span class="number">7</span>]:</span><br><span class="line">DatetimeIndex([<span class="string">'2013-01-01'</span>, <span class="string">'2013-01-02'</span>, <span class="string">'2013-01-03'</span>, <span class="string">'2013-01-04'</span>,</span><br><span class="line">               <span class="string">'2013-01-05'</span>, <span class="string">'2013-01-06'</span>],</span><br><span class="line">              dtype=<span class="string">'datetime64[ns]'</span>, freq=<span class="string">'D'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: df = pd.DataFrame(np.random.randn(<span class="number">6</span>,<span class="number">4</span>), index=dates, columns=list(<span class="string">'ABCD'</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: df</span><br><span class="line">Out[<span class="number">9</span>]:</span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.469112</span> <span class="number">-0.282863</span> <span class="number">-1.509059</span> <span class="number">-1.135632</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span> <span class="number">-1.044236</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">0.271860</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span> <span class="number">-1.087401</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span> <span class="number">-0.673690</span>  <span class="number">0.113648</span> <span class="number">-1.478427</span>  <span class="number">0.524988</span></span><br></pre></td></tr></table></figure></p><p>通过传递一个序列对象的字典创建<code>DataFrame</code>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">10</span>]: df2 = pd.DataFrame(&#123; <span class="string">'A'</span> : <span class="number">1.</span>,</span><br><span class="line">   ....:                      <span class="string">'B'</span> : pd.Timestamp(<span class="string">'20130102'</span>),</span><br><span class="line">   ....:                      <span class="string">'C'</span> : pd.Series(<span class="number">1</span>,index=list(range(<span class="number">4</span>)),dtype=<span class="string">'float32'</span>),</span><br><span class="line">   ....:                      <span class="string">'D'</span> : np.array([<span class="number">3</span>] * <span class="number">4</span>,dtype=<span class="string">'int32'</span>),</span><br><span class="line">   ....:                      <span class="string">'E'</span> : pd.Categorical([<span class="string">"test"</span>,<span class="string">"train"</span>,<span class="string">"test"</span>,<span class="string">"train"</span>]),</span><br><span class="line">   ....:                      <span class="string">'F'</span> : <span class="string">'foo'</span> &#125;)</span><br><span class="line">   ....:</span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: df2</span><br><span class="line">Out[<span class="number">11</span>]:</span><br><span class="line">     A          B    C  D      E    F</span><br><span class="line"><span class="number">0</span>  <span class="number">1.0</span> <span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.0</span>  <span class="number">3</span>   test  foo</span><br><span class="line"><span class="number">1</span>  <span class="number">1.0</span> <span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.0</span>  <span class="number">3</span>  train  foo</span><br><span class="line"><span class="number">2</span>  <span class="number">1.0</span> <span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.0</span>  <span class="number">3</span>   test  foo</span><br><span class="line"><span class="number">3</span>  <span class="number">1.0</span> <span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.0</span>  <span class="number">3</span>  train  foo</span><br></pre></td></tr></table></figure></p><p>得到的<code>DataFrame</code>的列有不同的类型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">12</span>]: df2.dtypes</span><br><span class="line">Out[<span class="number">12</span>]:</span><br><span class="line">A           float64</span><br><span class="line">B    datetime64[ns]</span><br><span class="line">C           float32</span><br><span class="line">D             int32</span><br><span class="line">E          category</span><br><span class="line">F            object</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure></p><h3 id="浏览数据"><a href="#浏览数据" class="headerlink" title="浏览数据"></a>浏览数据</h3><p>可以看<a href="https://pandas.pydata.org/pandas-docs/stable/basics.html#basics" target="_blank" rel="noopener">基本章节</a>。</p><p>这里我们查看一下frame的前几行和后几行：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">14</span>]: df.head()</span><br><span class="line">Out[<span class="number">14</span>]:</span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.469112</span> <span class="number">-0.282863</span> <span class="number">-1.509059</span> <span class="number">-1.135632</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span> <span class="number">-1.044236</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">0.271860</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span> <span class="number">-1.087401</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">15</span>]: df.tail(<span class="number">3</span>)</span><br><span class="line">Out[<span class="number">15</span>]:</span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">0.271860</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span> <span class="number">-1.087401</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span> <span class="number">-0.673690</span>  <span class="number">0.113648</span> <span class="number">-1.478427</span>  <span class="number">0.524988</span></span><br></pre></td></tr></table></figure></p><p>显示索引和列，并且显示隐含的NumPy数据：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">16</span>]: df.index</span><br><span class="line">Out[<span class="number">16</span>]:</span><br><span class="line">DatetimeIndex([<span class="string">'2013-01-01'</span>, <span class="string">'2013-01-02'</span>, <span class="string">'2013-01-03'</span>, <span class="string">'2013-01-04'</span>,</span><br><span class="line">               <span class="string">'2013-01-05'</span>, <span class="string">'2013-01-06'</span>],</span><br><span class="line">              dtype=<span class="string">'datetime64[ns]'</span>, freq=<span class="string">'D'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: df.columns</span><br><span class="line">Out[<span class="number">17</span>]: Index([<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>, <span class="string">'D'</span>], dtype=<span class="string">'object'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: df.values</span><br><span class="line">Out[<span class="number">18</span>]:</span><br><span class="line">array([[ <span class="number">0.4691</span>, <span class="number">-0.2829</span>, <span class="number">-1.5091</span>, <span class="number">-1.1356</span>],</span><br><span class="line">       [ <span class="number">1.2121</span>, <span class="number">-0.1732</span>,  <span class="number">0.1192</span>, <span class="number">-1.0442</span>],</span><br><span class="line">       [<span class="number">-0.8618</span>, <span class="number">-2.1046</span>, <span class="number">-0.4949</span>,  <span class="number">1.0718</span>],</span><br><span class="line">       [ <span class="number">0.7216</span>, <span class="number">-0.7068</span>, <span class="number">-1.0396</span>,  <span class="number">0.2719</span>],</span><br><span class="line">       [<span class="number">-0.425</span> ,  <span class="number">0.567</span> ,  <span class="number">0.2762</span>, <span class="number">-1.0874</span>],</span><br><span class="line">       [<span class="number">-0.6737</span>,  <span class="number">0.1136</span>, <span class="number">-1.4784</span>,  <span class="number">0.525</span> ]])</span><br></pre></td></tr></table></figure></p><p><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html#pandas.DataFrame.describe" target="_blank" rel="noopener">describe()</a>显示一个快速的你的数据的统计信息：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">19</span>]: df.describe()</span><br><span class="line">Out[<span class="number">19</span>]:</span><br><span class="line">              A         B         C         D</span><br><span class="line">count  <span class="number">6.000000</span>  <span class="number">6.000000</span>  <span class="number">6.000000</span>  <span class="number">6.000000</span></span><br><span class="line">mean   <span class="number">0.073711</span> <span class="number">-0.431125</span> <span class="number">-0.687758</span> <span class="number">-0.233103</span></span><br><span class="line">std    <span class="number">0.843157</span>  <span class="number">0.922818</span>  <span class="number">0.779887</span>  <span class="number">0.973118</span></span><br><span class="line">min   <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-1.509059</span> <span class="number">-1.135632</span></span><br><span class="line"><span class="number">25</span>%   <span class="number">-0.611510</span> <span class="number">-0.600794</span> <span class="number">-1.368714</span> <span class="number">-1.076610</span></span><br><span class="line"><span class="number">50</span>%    <span class="number">0.022070</span> <span class="number">-0.228039</span> <span class="number">-0.767252</span> <span class="number">-0.386188</span></span><br><span class="line"><span class="number">75</span>%    <span class="number">0.658444</span>  <span class="number">0.041933</span> <span class="number">-0.034326</span>  <span class="number">0.461706</span></span><br><span class="line">max    <span class="number">1.212112</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span>  <span class="number">1.071804</span></span><br></pre></td></tr></table></figure></p><p>转置你的数据：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">20</span>]: df.T</span><br><span class="line">Out[<span class="number">20</span>]:</span><br><span class="line">   <span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>  <span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">2013</span><span class="number">-01</span><span class="number">-05</span>  <span class="number">2013</span><span class="number">-01</span><span class="number">-06</span></span><br><span class="line">A    <span class="number">0.469112</span>    <span class="number">1.212112</span>   <span class="number">-0.861849</span>    <span class="number">0.721555</span>   <span class="number">-0.424972</span>   <span class="number">-0.673690</span></span><br><span class="line">B   <span class="number">-0.282863</span>   <span class="number">-0.173215</span>   <span class="number">-2.104569</span>   <span class="number">-0.706771</span>    <span class="number">0.567020</span>    <span class="number">0.113648</span></span><br><span class="line">C   <span class="number">-1.509059</span>    <span class="number">0.119209</span>   <span class="number">-0.494929</span>   <span class="number">-1.039575</span>    <span class="number">0.276232</span>   <span class="number">-1.478427</span></span><br><span class="line">D   <span class="number">-1.135632</span>   <span class="number">-1.044236</span>    <span class="number">1.071804</span>    <span class="number">0.271860</span>   <span class="number">-1.087401</span>    <span class="number">0.524988</span></span><br></pre></td></tr></table></figure></p><p>通过一个维度进行排序：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">21</span>]: df.sort_index(axis=<span class="number">1</span>, ascending=<span class="keyword">False</span>)</span><br><span class="line">Out[<span class="number">21</span>]:</span><br><span class="line">                   D         C         B         A</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span> <span class="number">-1.135632</span> <span class="number">-1.509059</span> <span class="number">-0.282863</span>  <span class="number">0.469112</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span> <span class="number">-1.044236</span>  <span class="number">0.119209</span> <span class="number">-0.173215</span>  <span class="number">1.212112</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>  <span class="number">1.071804</span> <span class="number">-0.494929</span> <span class="number">-2.104569</span> <span class="number">-0.861849</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.271860</span> <span class="number">-1.039575</span> <span class="number">-0.706771</span>  <span class="number">0.721555</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-1.087401</span>  <span class="number">0.276232</span>  <span class="number">0.567020</span> <span class="number">-0.424972</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span>  <span class="number">0.524988</span> <span class="number">-1.478427</span>  <span class="number">0.113648</span> <span class="number">-0.673690</span></span><br></pre></td></tr></table></figure></p><p>通过数值排序：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">22</span>]: df.sort_values(by=<span class="string">'B'</span>)</span><br><span class="line">Out[<span class="number">22</span>]:</span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">0.271860</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.469112</span> <span class="number">-0.282863</span> <span class="number">-1.509059</span> <span class="number">-1.135632</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span> <span class="number">-1.044236</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span> <span class="number">-0.673690</span>  <span class="number">0.113648</span> <span class="number">-1.478427</span>  <span class="number">0.524988</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span> <span class="number">-1.087401</span></span><br></pre></td></tr></table></figure></p><h3 id="选择"><a href="#选择" class="headerlink" title="选择"></a>选择</h3><h3 id="得到数据"><a href="#得到数据" class="headerlink" title="得到数据"></a>得到数据</h3><p>选择一个列，这会产生一个<code>Series</code>，　等同于<code>df.A</code>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">23</span>]: df[<span class="string">'A'</span>]</span><br><span class="line">Out[<span class="number">23</span>]:</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>    <span class="number">0.469112</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>    <span class="number">1.212112</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>   <span class="number">-0.861849</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>    <span class="number">0.721555</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span>   <span class="number">-0.424972</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span>   <span class="number">-0.673690</span></span><br><span class="line">Freq: D, Name: A, dtype: float64</span><br></pre></td></tr></table></figure></p><p>通过<code>[]</code>进行选择，这可以切开行：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">24</span>]: df[<span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line">Out[<span class="number">24</span>]:</span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.469112</span> <span class="number">-0.282863</span> <span class="number">-1.509059</span> <span class="number">-1.135632</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span> <span class="number">-1.044236</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: df[<span class="string">'20130102'</span>:<span class="string">'20130104'</span>]</span><br><span class="line">Out[<span class="number">25</span>]:</span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span> <span class="number">-1.044236</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">0.271860</span></span><br></pre></td></tr></table></figure></p><h3 id="通过标签选择"><a href="#通过标签选择" class="headerlink" title="通过标签选择"></a>通过标签选择</h3><p>更多请看<a href="https://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-label" target="_blank" rel="noopener">here</a>。</p><p>使用标签获得一个截面：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">26</span>]: df.loc[dates[<span class="number">0</span>]]</span><br><span class="line">Out[<span class="number">26</span>]:</span><br><span class="line">A    <span class="number">0.469112</span></span><br><span class="line">B   <span class="number">-0.282863</span></span><br><span class="line">C   <span class="number">-1.509059</span></span><br><span class="line">D   <span class="number">-1.135632</span></span><br><span class="line">Name: <span class="number">2013</span><span class="number">-01</span><span class="number">-01</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>, dtype: float64</span><br></pre></td></tr></table></figure></p><p>通过标签选择多个轴线：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">27</span>]: df.loc[:,[<span class="string">'A'</span>,<span class="string">'B'</span>]]</span><br><span class="line">Out[<span class="number">27</span>]:</span><br><span class="line">                   A         B</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.469112</span> <span class="number">-0.282863</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span> <span class="number">-0.673690</span>  <span class="number">0.113648</span></span><br></pre></td></tr></table></figure></p><p>显示一个标签切片，并且也包括结束点：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">28</span>]: df.loc[<span class="string">'20130102'</span>:<span class="string">'20130104'</span>,[<span class="string">'A'</span>,<span class="string">'B'</span>]]</span><br><span class="line">Out[<span class="number">28</span>]:</span><br><span class="line">                   A         B</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span></span><br></pre></td></tr></table></figure></p><h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><h3 id="基础绘画-plot"><a href="#基础绘画-plot" class="headerlink" title="基础绘画: plot"></a>基础绘画: plot</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">2</span>]: ts = pd.Series(np.random.randn(<span class="number">1000</span>), index=pd.date_range(<span class="string">'1/1/2000'</span>, periods=<span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: ts = ts.cumsum()</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: ts.plot()</span><br><span class="line">Out[<span class="number">4</span>]: &lt;matplotlib.axes._subplots.AxesSubplot at <span class="number">0x1c2ead5a20</span>&gt;</span><br></pre></td></tr></table></figure><p><img src="./1527073248624.png" alt="Alt text"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">15</span>]: plt.figure();</span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: df.iloc[<span class="number">5</span>].plot.bar(); plt.axhline(<span class="number">0</span>, color=<span class="string">'k'</span>)</span><br><span class="line">Out[<span class="number">16</span>]: &lt;matplotlib.lines.Line2D at <span class="number">0x1c318b4f60</span>&gt;</span><br></pre></td></tr></table></figure><p><img src="./1527073276506.png" alt="Alt text"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">17</span>]: df2 = pd.DataFrame(np.random.rand(<span class="number">10</span>, <span class="number">4</span>), columns=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: df2.plot.bar();</span><br></pre></td></tr></table></figure><p><img src="./1527073289369.png" alt="Alt text"></p><h3 id="直方图（Histograms）"><a href="#直方图（Histograms）" class="headerlink" title="直方图（Histograms）"></a>直方图（Histograms）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">21</span>]: df4 = pd.DataFrame(&#123;<span class="string">'a'</span>: np.random.randn(<span class="number">1000</span>) + <span class="number">1</span>, <span class="string">'b'</span>: np.random.randn(<span class="number">1000</span>),</span><br><span class="line">   ....:                     <span class="string">'c'</span>: np.random.randn(<span class="number">1000</span>) - <span class="number">1</span>&#125;, columns=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>])</span><br><span class="line">   ....:</span><br><span class="line"></span><br><span class="line">In [<span class="number">22</span>]: plt.figure();</span><br><span class="line"></span><br><span class="line">In [<span class="number">23</span>]: df4.plot.hist(alpha=<span class="number">0.5</span>)</span><br><span class="line">Out[<span class="number">23</span>]: &lt;matplotlib.axes._subplots.AxesSubplot at <span class="number">0x1c2f3fb2e8</span>&gt;</span><br></pre></td></tr></table></figure><p><img src="./1527073328778.png" alt="Alt text"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">24</span>]: plt.figure();</span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: df4.plot.hist(stacked=<span class="keyword">True</span>, bins=<span class="number">20</span>)</span><br><span class="line">Out[<span class="number">25</span>]: &lt;matplotlib.axes._subplots.AxesSubplot at <span class="number">0x1233ad2b0</span>&gt;</span><br></pre></td></tr></table></figure><p><img src="./1527073341559.png" alt="Alt text"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">28</span>]: plt.figure();</span><br><span class="line"></span><br><span class="line">In [<span class="number">29</span>]: df[<span class="string">'A'</span>].diff().hist()</span><br><span class="line">Out[<span class="number">29</span>]: &lt;matplotlib.axes._subplots.AxesSubplot at <span class="number">0x1c333967f0</span>&gt;</span><br></pre></td></tr></table></figure><p><img src="./1527073360969.png" alt="Alt text"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">30</span>]: plt.figure()</span><br><span class="line">Out[<span class="number">30</span>]: &lt;Figure size <span class="number">640</span>x480 <span class="keyword">with</span> <span class="number">0</span> Axes&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">31</span>]: df.diff().hist(color=<span class="string">'k'</span>, alpha=<span class="number">0.5</span>, bins=<span class="number">50</span>)</span><br><span class="line">Out[<span class="number">31</span>]:</span><br><span class="line">array([[&lt;matplotlib.axes._subplots.AxesSubplot object at <span class="number">0x1c2b9669e8</span>&gt;,</span><br><span class="line">        &lt;matplotlib.axes._subplots.AxesSubplot object at <span class="number">0x1c3184a0b8</span>&gt;],</span><br><span class="line">       [&lt;matplotlib.axes._subplots.AxesSubplot object at <span class="number">0x1c2e766668</span>&gt;,</span><br><span class="line">        &lt;matplotlib.axes._subplots.AxesSubplot object at <span class="number">0x1c319e1240</span>&gt;]], dtype=object)</span><br></pre></td></tr></table></figure><p><img src="./1527073377545.png" alt="Alt text"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">32</span>]: data = pd.Series(np.random.randn(<span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">33</span>]: data.hist(by=np.random.randint(<span class="number">0</span>, <span class="number">4</span>, <span class="number">1000</span>), figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line">Out[<span class="number">33</span>]:</span><br><span class="line">array([[&lt;matplotlib.axes._subplots.AxesSubplot object at <span class="number">0x1c2f245898</span>&gt;,</span><br><span class="line">        &lt;matplotlib.axes._subplots.AxesSubplot object at <span class="number">0x1c2fd204a8</span>&gt;],</span><br><span class="line">       [&lt;matplotlib.axes._subplots.AxesSubplot object at <span class="number">0x1c2f326240</span>&gt;,</span><br><span class="line">        &lt;matplotlib.axes._subplots.AxesSubplot object at <span class="number">0x1c2e751b00</span>&gt;]], dtype=object)</span><br></pre></td></tr></table></figure><p><img src="./1527073572668.png" alt="Alt text"></p>]]></content>
    
    <summary type="html">
    
      Pandas Tutorial
    
    </summary>
    
      <category term="Python" scheme="https://www.starlg.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.starlg.cn/tags/Python/"/>
    
      <category term="Pandas" scheme="https://www.starlg.cn/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>变量——看见社会小趋势</title>
    <link href="https://www.starlg.cn/2019/06/20/Book-BianLiang/"/>
    <id>https://www.starlg.cn/2019/06/20/Book-BianLiang/</id>
    <published>2019-06-20T14:25:21.000Z</published>
    <updated>2019-06-25T06:04:36.653Z</updated>
    
    <content type="html"><![CDATA[<h1 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h1><p>何帆，男，现任北京大学汇丰商学院经济学教授，兼熵一资本首席经济学家。曾任中国社会科学院世界经济与政治研究所副所长，在政策研究领域研究已经超过20年 [3]  ，发表学术论文100多篇，出版专著10余部，如《变量》《何帆大局观》等 。现被厦门大学EMBA管理学院特聘为EMBA讲师，同陆磊教授一同讲授EMBA课程-《宏观经济理论与实践》。同时，何帆是得到App《何帆大局观》《何帆的读书俱乐部》《何帆报告》课程主理人。</p><p>作者简介来自百度百科</p><h1 id="摘抄"><a href="#摘抄" class="headerlink" title="摘抄"></a>摘抄</h1><h2 id="第一章-这样观察一棵树"><a href="#第一章-这样观察一棵树" class="headerlink" title="第一章　这样观察一棵树"></a>第一章　这样观察一棵树</h2><p>2018年是一个新的开端。生活在2018年的人感受到的是中国经济遇到的各种冲击：中美贸易战、经济增长回落、股市下跌。他们会感到焦虑和担忧。旧路标已经消失，新秩序尚未出现。未来30年出现的一系列变化将挑战我们的认知，但历史从来都是一位“魔术师”，未来会出现意想不到的变化。在这一章，我会讲述如何像细致地观察一棵树一样观察历史，怎样从每年长出的“嫩芽”去判断中国文明这棵大树的生命力。我还会告诉你两个重要的概念：<strong>慢变量</strong>和<strong>小趋势</strong>。感知历史，就要会从慢变量中寻找小趋势。</p><h2 id="第二章-在无人地带寻找无人机"><a href="#第二章-在无人地带寻找无人机" class="headerlink" title="第二章　在无人地带寻找无人机"></a>第二章　在无人地带寻找无人机</h2><p>2018年，关于技术发展路径的讨论引起全民关注。中国到底是应该集中全力补上“核心技术”，还是应该扬己所长发展“应用技术”呢？我将带你回顾美国在工业革命时期的经验，并试图发现中国在信息化时代的最佳战略。我找到的第二个变量是：<strong>技术赋能</strong>。在创新阶段，寻找新技术的应用场景更重要，在边缘地带更容易找到新技术的应用场景，技术必须与市场需求匹配。我们会到新疆去看无人机，而你很可能会在酒店里邂逅机器人。中国革命的成功靠的是“群众路线”，中国经济的崛起也要走“群众路线”。</p><h2 id="第三章-老兵不死"><a href="#第三章-老兵不死" class="headerlink" title="第三章　老兵不死"></a>第三章　老兵不死</h2><p>2018年，谁是新兴产业，谁是传统产业？哪个更胜一筹？在过去几年，互联网大军就好像当年来自中亚大草原的游牧民族，兵强马壮，来去如风。在互联网大军的攻势下，传统产业的护城河形同虚设。到了2018年，这股“为跨不破”，精于“降维打击”的大军，却在一座城堡前久攻不下。这就是工业化的代表————已经有上百年历史的汽车行业。2018年，我发现的第三个变量是：<strong>老兵不死</strong>。我要带你到传统制造业的腹地，看看他们是如何抵御互联网行业的迅猛攻势。在这里，你会看到，传统行业的老兵早已经悄悄穿上了新的军装，而新兴的产业正在积极地想传统产业学习。新兴产业和传统产业的边界，也许并没有你想象的那般泾渭分明。</p><h2 id="第四章-在菜市场遇见城市设计师"><a href="#第四章-在菜市场遇见城市设计师" class="headerlink" title="第四章　在菜市场遇见城市设计师"></a>第四章　在菜市场遇见城市设计师</h2><p>2018年，人们最关心的是房价是否会出现拐点，但从长时间来看更值得关注的是城市化的拐点。自上而下的城市化已不可持续。我观察到的第四个变量是：<strong>自下而上的力量浮出水面</strong>。城市化的进程不会停止，未来会有更多的城市圈，但这些都市圈是放大了的城市，还是一种新的城市物种呢？未来的城市不一定都能扩张，假如城市不得不“收缩”，该怎样才能像瘦身一样，瘦了更健康？未来的城市将深受互联网影响，城市空间布局会跟过去有很大的不同。“位置、位置、位置”的传统房地产“金律”很可能不再适用。我们会看到，城市会爆发一场“颜值革命”。这场“颜值革命”来自哪里呢？归根到底，它来自人民群众自己创造美好生活的能量。</p><h2 id="第五章-阿那亚和范家小学"><a href="#第五章-阿那亚和范家小学" class="headerlink" title="第五章　阿那亚和范家小学"></a>第五章　阿那亚和范家小学</h2><p>2018年，我们听到了很多负面的社会新闻：米脂杀人、衡阳装车、高铁霸座……这个社会变得越来越糟糕了吗？其中这是一种误解。虽然从表明上看，有些人只关心自我私利，但大家对集体生活的向往并没有泯灭。中国人已经意识到，只有重建集体生活，才能更好地发现自我。我看到的第五个变量就是：<strong>重建社群</strong>。有哪些地方的人们正在“凝结”起来，形成新的社群？这些新的社群只是孤岛，还是将成为群岛？培养孩子也需要一个社群。我会带你到一所偏僻的农村小学看看。2018年，我找到的中国教育理念最先进的小学不是北京或上海名校，而是山区里的一所农村小学。你不必吃惊，社会发展的剧情经常会有令人意想不到的转变。</p>]]></content>
    
    <summary type="html">
    
      变量——看见社会小趋势
    
    </summary>
    
      <category term="Book" scheme="https://www.starlg.cn/categories/Book/"/>
    
    
      <category term="Book" scheme="https://www.starlg.cn/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>High-level Semantic Feature Detection A New Perspective for Pedestrian Detection</title>
    <link href="https://www.starlg.cn/2019/05/29/CVPR2019-CSP/"/>
    <id>https://www.starlg.cn/2019/05/29/CVPR2019-CSP/</id>
    <published>2019-05-29T02:16:27.000Z</published>
    <updated>2019-06-24T14:07:26.202Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1904.02948v1" target="_blank" rel="noopener">Paper Link</a></p><p><a href="https://github.com/liuwei16/CSP" target="_blank" rel="noopener">Code</a></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>CSP: Center and Scale Prediction</p><p><img src="./cVPR19_CSP_pipeline.png" alt="CVPR19_CSP_pipeline"></p><p><img src="./20190529_CVPR19_CSP_architecture.png" alt="20190529_CVPR19_CSP_architecture"></p><p><img src="./20190529_CVPR19_CSP_annotations.png" alt="20190529_CVPR19_CSP_annotations"></p><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p><img src="./20190529_CVPR19_CSP_points.png" alt="20190529_CVPR19_CSP_points"></p><p><img src="./20190529_CVPR19_CSP_scale.png" alt="20190529_CVPR19_CSP_scale"></p><p><img src="./20190529_CVPR19_CSP_downsampling_factors.png" alt="20190529_CVPR19_CSP_downsampling_factors"></p><p><img src="./20190529_CVPR19_CSP_multi_scale.png" alt="20190529_CVPR19_CSP_multi_scale"></p><p><img src="./20190529_CVPR19_CSP_Caltech_new.png" alt="20190529_CVPR19_CSP_Caltech_new"></p><p><img src="./20190529_CVPR19_CSP_CityPersons.png" alt="20190529_CVPR19_CSP_CityPersons"></p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><h2 id="准备ground-truth"><a href="#准备ground-truth" class="headerlink" title="准备ground truth"></a>准备ground truth</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_gt_center</span><span class="params">(C, img_data,r=<span class="number">2</span>, down=<span class="number">4</span>,scale=<span class="string">'h'</span>,offset=True)</span>:</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gaussian</span><span class="params">(kernel)</span>:</span></span><br><span class="line">sigma = ((kernel<span class="number">-1</span>) * <span class="number">0.5</span> - <span class="number">1</span>) * <span class="number">0.3</span> + <span class="number">0.8</span></span><br><span class="line">s = <span class="number">2</span>*(sigma**<span class="number">2</span>)</span><br><span class="line">dx = np.exp(-np.square(np.arange(kernel) - int(kernel / <span class="number">2</span>)) / s)</span><br><span class="line"><span class="keyword">return</span> np.reshape(dx,(<span class="number">-1</span>,<span class="number">1</span>))</span><br><span class="line">gts = np.copy(img_data[<span class="string">'bboxes'</span>])</span><br><span class="line">igs = np.copy(img_data[<span class="string">'ignoreareas'</span>])</span><br><span class="line">scale_map = np.zeros((int(C.size_train[<span class="number">0</span>]/down), int(C.size_train[<span class="number">1</span>]/down), <span class="number">2</span>))</span><br><span class="line"><span class="keyword">if</span> scale==<span class="string">'hw'</span>:</span><br><span class="line">scale_map = np.zeros((int(C.size_train[<span class="number">0</span>] / down), int(C.size_train[<span class="number">1</span>] / down), <span class="number">3</span>))</span><br><span class="line"><span class="keyword">if</span> offset:</span><br><span class="line">offset_map = np.zeros((int(C.size_train[<span class="number">0</span>] / down), int(C.size_train[<span class="number">1</span>] / down), <span class="number">3</span>))</span><br><span class="line">seman_map = np.zeros((int(C.size_train[<span class="number">0</span>]/down), int(C.size_train[<span class="number">1</span>]/down), <span class="number">3</span>))</span><br><span class="line">seman_map[:,:,<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> len(igs) &gt; <span class="number">0</span>:</span><br><span class="line">igs = igs/down</span><br><span class="line"><span class="keyword">for</span> ind <span class="keyword">in</span> range(len(igs)):</span><br><span class="line">x1,y1,x2,y2 = int(igs[ind,<span class="number">0</span>]), int(igs[ind,<span class="number">1</span>]), int(np.ceil(igs[ind,<span class="number">2</span>])), int(np.ceil(igs[ind,<span class="number">3</span>]))</span><br><span class="line">seman_map[y1:y2, x1:x2,<span class="number">1</span>] = <span class="number">0</span>  <span class="comment"># 被忽视的区域在第１个通道上置０</span></span><br><span class="line"><span class="keyword">if</span> len(gts)&gt;<span class="number">0</span>:</span><br><span class="line">gts = gts/down</span><br><span class="line"><span class="keyword">for</span> ind <span class="keyword">in</span> range(len(gts)):</span><br><span class="line"><span class="comment"># x1, y1, x2, y2 = int(round(gts[ind, 0])), int(round(gts[ind, 1])), int(round(gts[ind, 2])), int(round(gts[ind, 3]))</span></span><br><span class="line">x1, y1, x2, y2 = int(np.ceil(gts[ind, <span class="number">0</span>])), int(np.ceil(gts[ind, <span class="number">1</span>])), int(gts[ind, <span class="number">2</span>]), int(gts[ind, <span class="number">3</span>])</span><br><span class="line">c_x, c_y = int((gts[ind, <span class="number">0</span>] + gts[ind, <span class="number">2</span>]) / <span class="number">2</span>), int((gts[ind, <span class="number">1</span>] + gts[ind, <span class="number">3</span>]) / <span class="number">2</span>)</span><br><span class="line">dx = gaussian(x2-x1)</span><br><span class="line">dy = gaussian(y2-y1)</span><br><span class="line">gau_map = np.multiply(dy, np.transpose(dx))</span><br><span class="line">seman_map[y1:y2, x1:x2,<span class="number">0</span>] = np.maximum(seman_map[y1:y2, x1:x2,<span class="number">0</span>], gau_map)  <span class="comment"># 在第０个通道上置高斯值</span></span><br><span class="line">seman_map[y1:y2, x1:x2,<span class="number">1</span>] = <span class="number">1</span>  <span class="comment"># 前景在第１个通道上置１</span></span><br><span class="line">seman_map[c_y, c_x, <span class="number">2</span>] = <span class="number">1</span>  <span class="comment"># 在第２个通道上目标中心位置１</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> scale == <span class="string">'h'</span>:</span><br><span class="line">scale_map[c_y-r:c_y+r+<span class="number">1</span>, c_x-r:c_x+r+<span class="number">1</span>, <span class="number">0</span>] = np.log(gts[ind, <span class="number">3</span>] - gts[ind, <span class="number">1</span>])</span><br><span class="line">scale_map[c_y-r:c_y+r+<span class="number">1</span>, c_x-r:c_x+r+<span class="number">1</span>, <span class="number">1</span>] = <span class="number">1</span></span><br><span class="line"><span class="keyword">elif</span> scale==<span class="string">'w'</span>:</span><br><span class="line">scale_map[c_y-r:c_y+r+<span class="number">1</span>, c_x-r:c_x+r+<span class="number">1</span>, <span class="number">0</span>] = np.log(gts[ind, <span class="number">2</span>] - gts[ind, <span class="number">0</span>])</span><br><span class="line">scale_map[c_y-r:c_y+r+<span class="number">1</span>, c_x-r:c_x+r+<span class="number">1</span>, <span class="number">1</span>] = <span class="number">1</span></span><br><span class="line"><span class="keyword">elif</span> scale==<span class="string">'hw'</span>:</span><br><span class="line">scale_map[c_y-r:c_y+r+<span class="number">1</span>, c_x-r:c_x+r+<span class="number">1</span>, <span class="number">0</span>] = np.log(gts[ind, <span class="number">3</span>] - gts[ind, <span class="number">1</span>])</span><br><span class="line">scale_map[c_y-r:c_y+r+<span class="number">1</span>, c_x-r:c_x+r+<span class="number">1</span>, <span class="number">1</span>] = np.log(gts[ind, <span class="number">2</span>] - gts[ind, <span class="number">0</span>])</span><br><span class="line">scale_map[c_y-r:c_y+r+<span class="number">1</span>, c_x-r:c_x+r+<span class="number">1</span>, <span class="number">2</span>] = <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> offset:</span><br><span class="line">offset_map[c_y, c_x, <span class="number">0</span>] = (gts[ind, <span class="number">1</span>] + gts[ind, <span class="number">3</span>]) / <span class="number">2</span> - c_y - <span class="number">0.5</span></span><br><span class="line">offset_map[c_y, c_x, <span class="number">1</span>] = (gts[ind, <span class="number">0</span>] + gts[ind, <span class="number">2</span>]) / <span class="number">2</span> - c_x - <span class="number">0.5</span></span><br><span class="line">offset_map[c_y, c_x, <span class="number">2</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> offset:</span><br><span class="line"><span class="keyword">return</span> seman_map,scale_map,offset_map</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">return</span> seman_map, scale_map</span><br></pre></td></tr></table></figure><p>seman_map有三个位面，第一个是高斯值mask，第二个是学习权重，第三个是目标中心点的位置。</p><p><img src="./20190529_CVPR19_CSP_seman_map0.png" alt="20190529_CVPR19_CSP_seman_map0"></p><p><img src="./20190529_CVPR19_CSP_seman_map2.png" alt="20190529_CVPR19_CSP_seman_map2"></p><p><img src="./20190529_CVPR19_CSP_scale_map0.png" alt="20190529_CVPR19_CSP_scale_map0"></p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nn_p3p4p5</span><span class="params">(img_input=None, offset=True, num_scale=<span class="number">1</span>, trainable=False)</span>:</span></span><br><span class="line">    bn_axis = <span class="number">3</span></span><br><span class="line">    x = ZeroPadding2D((<span class="number">3</span>, <span class="number">3</span>))(img_input)</span><br><span class="line">    x = Convolution2D(<span class="number">64</span>, (<span class="number">7</span>, <span class="number">7</span>), strides=(<span class="number">2</span>, <span class="number">2</span>), name=<span class="string">'conv1'</span>, trainable=<span class="keyword">False</span>)(x)</span><br><span class="line">    x = BatchNormalization(axis=bn_axis, name=<span class="string">'bn_conv1'</span>)(x)</span><br><span class="line">    x = Activation(<span class="string">'relu'</span>)(x)</span><br><span class="line">    x = MaxPooling2D((<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">'same'</span>)(x)</span><br><span class="line">    x = conv_block(x, <span class="number">3</span>, [<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], stage=<span class="number">2</span>, block=<span class="string">'a'</span>, strides=(<span class="number">1</span>, <span class="number">1</span>), trainable=<span class="keyword">False</span>)</span><br><span class="line">    x = identity_block(x, <span class="number">3</span>, [<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], stage=<span class="number">2</span>, block=<span class="string">'b'</span>, trainable=<span class="keyword">False</span>)</span><br><span class="line">    stage2 = identity_block(x, <span class="number">3</span>, [<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], stage=<span class="number">2</span>, block=<span class="string">'c'</span>, trainable=<span class="keyword">False</span>)</span><br><span class="line">    <span class="comment"># print('stage2: ', stage2._keras_shape[1:])</span></span><br><span class="line">    x = conv_block(stage2, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">'a'</span>, trainable=trainable)</span><br><span class="line">    x = identity_block(x, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">'b'</span>, trainable=trainable)</span><br><span class="line">    x = identity_block(x, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">'c'</span>, trainable=trainable)</span><br><span class="line">    stage3 = identity_block(x, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">'d'</span>, trainable=trainable)</span><br><span class="line">    <span class="comment"># print('stage3: ', stage3._keras_shape[1:])</span></span><br><span class="line">    x = conv_block(stage3, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'a'</span>, trainable=trainable)</span><br><span class="line">    x = identity_block(x, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'b'</span>, trainable=trainable)</span><br><span class="line">    x = identity_block(x, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'c'</span>, trainable=trainable)</span><br><span class="line">    x = identity_block(x, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'d'</span>, trainable=trainable)</span><br><span class="line">    x = identity_block(x, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'e'</span>, trainable=trainable)</span><br><span class="line">    stage4 = identity_block(x, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'f'</span>, trainable=trainable)</span><br><span class="line">    <span class="comment"># print('stage4: ', stage4._keras_shape[1:])</span></span><br><span class="line">    x = conv_block(stage4, <span class="number">3</span>, [<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], stage=<span class="number">5</span>, block=<span class="string">'a'</span>, strides=(<span class="number">1</span>, <span class="number">1</span>), dila=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                   trainable=trainable)</span><br><span class="line">    x = identity_block(x, <span class="number">3</span>, [<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], stage=<span class="number">5</span>, block=<span class="string">'b'</span>, dila=(<span class="number">2</span>, <span class="number">2</span>), trainable=trainable)</span><br><span class="line">    stage5 = identity_block(x, <span class="number">3</span>, [<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], stage=<span class="number">5</span>, block=<span class="string">'c'</span>, dila=(<span class="number">2</span>, <span class="number">2</span>), trainable=trainable)</span><br><span class="line">    <span class="comment"># print('stage5: ', stage5._keras_shape[1:])</span></span><br><span class="line"></span><br><span class="line">    P3_up = Deconvolution2D(<span class="number">256</span>, kernel_size=<span class="number">4</span>, strides=<span class="number">2</span>, padding=<span class="string">'same'</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">'glorot_normal'</span>, name=<span class="string">'P3up'</span>, trainable=trainable)(stage3)</span><br><span class="line">    <span class="comment"># print('P3_up: ', P3_up._keras_shape[1:])</span></span><br><span class="line">    P4_up = Deconvolution2D(<span class="number">256</span>, kernel_size=<span class="number">4</span>, strides=<span class="number">4</span>, padding=<span class="string">'same'</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">'glorot_normal'</span>, name=<span class="string">'P4up'</span>, trainable=trainable)(stage4)</span><br><span class="line">    <span class="comment"># print('P4_up: ', P4_up._keras_shape[1:])</span></span><br><span class="line">    P5_up = Deconvolution2D(<span class="number">256</span>, kernel_size=<span class="number">4</span>, strides=<span class="number">4</span>, padding=<span class="string">'same'</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">'glorot_normal'</span>, name=<span class="string">'P5up'</span>, trainable=trainable)(stage5)</span><br><span class="line">    <span class="comment"># print('P5_up: ', P5_up._keras_shape[1:])</span></span><br><span class="line"></span><br><span class="line">    P3_up = L2Normalization(gamma_init=<span class="number">10</span>, name=<span class="string">'P3norm'</span>)(P3_up)</span><br><span class="line">    P4_up = L2Normalization(gamma_init=<span class="number">10</span>, name=<span class="string">'P4norm'</span>)(P4_up)</span><br><span class="line">    P5_up = L2Normalization(gamma_init=<span class="number">10</span>, name=<span class="string">'P5norm'</span>)(P5_up)</span><br><span class="line">    conc = Concatenate(axis=<span class="number">-1</span>)([P3_up, P4_up, P5_up])</span><br><span class="line"></span><br><span class="line">    feat = Convolution2D(<span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'same'</span>, kernel_initializer=<span class="string">'glorot_normal'</span>, name=<span class="string">'feat'</span>,</span><br><span class="line">                         trainable=trainable)(conc)</span><br><span class="line">    feat = BatchNormalization(axis=bn_axis, name=<span class="string">'bn_feat'</span>)(feat)</span><br><span class="line">    feat = Activation(<span class="string">'relu'</span>)(feat)</span><br><span class="line"></span><br><span class="line">    x_class = Convolution2D(<span class="number">1</span>, (<span class="number">1</span>, <span class="number">1</span>), activation=<span class="string">'sigmoid'</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">'glorot_normal'</span>,</span><br><span class="line">                            bias_initializer=prior_probability_onecls(probability=<span class="number">0.01</span>),</span><br><span class="line">                            name=<span class="string">'center_cls'</span>, trainable=trainable)(feat)</span><br><span class="line">    x_regr = Convolution2D(num_scale, (<span class="number">1</span>, <span class="number">1</span>), activation=<span class="string">'linear'</span>, kernel_initializer=<span class="string">'glorot_normal'</span>,</span><br><span class="line">                           name=<span class="string">'height_regr'</span>, trainable=trainable)(feat)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> offset:</span><br><span class="line">        x_offset = Convolution2D(<span class="number">2</span>, (<span class="number">1</span>, <span class="number">1</span>), activation=<span class="string">'linear'</span>, kernel_initializer=<span class="string">'glorot_normal'</span>,</span><br><span class="line">                                 name=<span class="string">'offset_regr'</span>, trainable=trainable)(feat)</span><br><span class="line">        <span class="keyword">return</span> [x_class, x_regr, x_offset]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> [x_class, x_regr]</span><br></pre></td></tr></table></figure><h2 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cls_center</span><span class="params">(y_true, y_pred)</span>:</span></span><br><span class="line"></span><br><span class="line">classification_loss = K.binary_crossentropy(y_pred[:, :, :, <span class="number">0</span>], y_true[:, :, :, <span class="number">2</span>])</span><br><span class="line"><span class="comment"># firstly we compute the focal weight</span></span><br><span class="line">positives = y_true[:, :, :, <span class="number">2</span>]</span><br><span class="line">negatives = y_true[:, :, :, <span class="number">1</span>]-y_true[:, :, :, <span class="number">2</span>]</span><br><span class="line">foreground_weight = positives * (<span class="number">1.0</span> - y_pred[:, :, :, <span class="number">0</span>]) ** <span class="number">2.0</span></span><br><span class="line">background_weight = negatives * ((<span class="number">1.0</span> - y_true[:, :, :, <span class="number">0</span>])**<span class="number">4.0</span>)*(y_pred[:, :, :, <span class="number">0</span>] ** <span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">focal_weight = foreground_weight + background_weight</span><br><span class="line"></span><br><span class="line">assigned_boxes = tf.reduce_sum(y_true[:, :, :, <span class="number">2</span>])</span><br><span class="line">class_loss = <span class="number">0.01</span>*tf.reduce_sum(focal_weight*classification_loss) / tf.maximum(<span class="number">1.0</span>, assigned_boxes)</span><br><span class="line"> assigned_boxes)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> class_loss</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      CVPR-19 High-level Semantic Feature Detection A New Perspective for Pedestrian Detection
    
    </summary>
    
      <category term="Pedestrian Detection" scheme="https://www.starlg.cn/categories/Pedestrian-Detection/"/>
    
    
      <category term="Pedestrian Detection" scheme="https://www.starlg.cn/tags/Pedestrian-Detection/"/>
    
      <category term="Deep Learning" scheme="https://www.starlg.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Deep High-Resolution Representation Learning for Human Pose Estimation</title>
    <link href="https://www.starlg.cn/2019/05/23/CVPR19-HRNet/"/>
    <id>https://www.starlg.cn/2019/05/23/CVPR19-HRNet/</id>
    <published>2019-05-23T06:29:55.000Z</published>
    <updated>2019-06-24T14:06:58.838Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1902.09212" target="_blank" rel="noopener">Paper Link</a></p><p><a href="https://github.com/leoxiaobin/deep-high-resolution-net.pytorch" target="_blank" rel="noopener">Code</a></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>High-Resolution Net (HRNet)</p><p>这篇论文解决人体姿态估计问题，重点关注学习高分辨率表示。大多数现有的方法通过一个由高到低分辨率的网络，从一个低分辨率的表示中恢复高分辨率的表示。相反，本论文提出的网络自始至终都保持了高分辨率的表示。</p><p>作者从高分辨率子网作为第一个阶段，逐渐添加 高-&gt;低 分辨率的子网形成更多的阶段，并且并行连接这些多分辨率子网。作者多次进行多尺度融合，使得每一个高-&gt;低分辨率的表示可以从其他并行的表示中接收信息，从而生成丰富的高分辨率表示。因此，预测的关键点热图可以更准确，空间更精确。作者在COCO关键点检测数据集和MPII Human Pose数据集上进行了验证。</p><h1 id="与其他方法之前的区别"><a href="#与其他方法之前的区别" class="headerlink" title="与其他方法之前的区别"></a>与其他方法之前的区别</h1><ol><li><p>该方法并行级联高-&gt;低分辨率子网，而不是以序列的方式。因此，该方法保持了高分辨率，而不是从低分辨率中恢复高分辨率。所以预测的热图的空间上更准确。</p></li><li><p>现存的融合策略集成底层（low-level）和高层（high-level）的表示。 而该方法通过相似深度和相同层级的低分辨率表示的帮助，执行重复的多尺度融合提升高分率表示。</p></li></ol><img src="/2019/05/23/CVPR19-HRNet/cVPR19-HRNet.png" title="Figure 1. 提出的HRNet的结构"><p>图1展示了提出的HRNet网络的结构。它包含并行的高-&gt;低分辨率的子网，重复的在不同分辨率子网之间的信息交换，即多尺度融合。水平和垂直方向分别对应于网络的深度和特征图的比例。</p><img src="/2019/05/23/CVPR19-HRNet/hRNet-framework.png" title="Figure 2. 依靠high-to-low和low-to-high框架的姿态估计网络结构"><p>图2展示了其他方法的一些网络结构，这些方法都是依靠high-to-low和low-to-high框架的姿态估计网络结构。其中（a)表示Hourglass网络，（b）表示Cascaded pyramid networks，（c）表示SimpleBaseline网络：转置卷积（transposed convolutions）用于low-to-high过程。（d）组合空洞卷积（dilated convolutions）。</p><h1 id="方法介绍"><a href="#方法介绍" class="headerlink" title="方法介绍"></a>方法介绍</h1><h2 id="序列多尺度子网"><a href="#序列多尺度子网" class="headerlink" title="序列多尺度子网"></a>序列多尺度子网</h2><p>用$N_{sr}$表示子网络在第s个stage，r表示分辨率的序号，它的分辨率是第一个子网络分辨率的$\frac{1}{r^{r-1}}$倍。有S=4个stege的high-to-low网络可以表示为：</p><p>$$N_{11} \to N_{22} \to N_{33} \to N_{44}$$</p><h2 id="并行多尺度子网"><a href="#并行多尺度子网" class="headerlink" title="并行多尺度子网"></a>并行多尺度子网</h2><p>我们从一个高分辨率子网络作为第一个stage起始，逐渐地增加high-to-low分辨率子网络，形成新的sgates，并且并行地连接多分辨率子网络。因此，后一阶段并行子网的分辨率包括前一阶段的分辨率和一个更低的分辨率。</p><p>这里给出一个网络结构的例子，包含4个并行的子网络，如下：</p><img src="/2019/05/23/CVPR19-HRNet/hRNet-eq2.png"><h2 id="重复多尺度融合"><a href="#重复多尺度融合" class="headerlink" title="重复多尺度融合"></a>重复多尺度融合</h2><img src="/2019/05/23/CVPR19-HRNet/hRNet-exchange-unit.png" title="Figure 3. Exchange Unit"><p>图3展示了交换单元（Exchange Unit）如何为高、中和底层融合信息的。右侧的注释表示：strided 3x3=stride 3x3卷积，up samp. 1x1=最近邻上采样和一个1x1卷积。</p><p>我们在不同的并行子网之间引入交换单元（exchange unit），这样每个子网可以重叠地从其他并行网络中接收信息。这里给出了一个交换信息框架的例子，如下图表示的结构。我们将第三个stage分成几个exchange blocks，并且每一个block有三个并行的卷积单元构成，一个交换单元在并行的卷积单元之间，如下：</p><img src="/2019/05/23/CVPR19-HRNet/hRNet-eq3.png"><p>其中，$C^b_{sr}$表示在第s个stage，第b个block的第r分辨率的卷积单元。$\varepsilon^b_s$是对应的交换的单元。</p><p>交换单元如图3所示。</p><img src="/2019/05/23/CVPR19-HRNet/hRNet-exchange-unit-2.png"><h2 id="热图估计"><a href="#热图估计" class="headerlink" title="热图估计"></a>热图估计</h2><p>我们简单地从最后一个交换单元（exhcange unit）输出的高分辨率表示中回归热图。损失函数（定义为均方误差）用于比较预测的热图和groundtruth热图。通过应用2D高斯生成的groundtruth热图，其中标准偏差为1像素，并以每个关键点的标注位置为中心。</p><h2 id="网络实例"><a href="#网络实例" class="headerlink" title="网络实例"></a>网络实例</h2><p>实验中提出了两种网络，一个小网络HRNet-W32，一个大网络HRNet-W48，其中32和48分别表示在后3个sgate中的高分辨率子网络的宽度（C）。对于HRNet-W32，其他三个并行的子网络的宽度分别是64，128,256，对于HRNet-W48是96，192，384。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><img src="/2019/05/23/CVPR19-HRNet/hRNet-COCO-validation.png" title="Figure 1."><img src="/2019/05/23/CVPR19-HRNet/hRNet-COCO-test.png" title="Figure 1."><img src="/2019/05/23/CVPR19-HRNet/hRNet-MPII.png" title="Figure 1."><img src="/2019/05/23/CVPR19-HRNet/hRNet-Qualitative-Results.png" title="Figure 1."><img src="/2019/05/23/CVPR19-HRNet/hRNet-1x2x4x.png" title="Figure 1."><img src="/2019/05/23/CVPR19-HRNet/hRNet-SimpleBaseline-performance.png" title="Figure 1."><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><h2 id="Exchange-Unit"><a href="#Exchange-Unit" class="headerlink" title="Exchange Unit"></a>Exchange Unit</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_make_fuse_layers</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> self.num_branches == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">    num_branches = self.num_branches</span><br><span class="line">    num_inchannels = self.num_inchannels</span><br><span class="line">    fuse_layers = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_branches <span class="keyword">if</span> self.multi_scale_output <span class="keyword">else</span> <span class="number">1</span>):</span><br><span class="line">        fuse_layer = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(num_branches):</span><br><span class="line">            <span class="keyword">if</span> j &gt; i:</span><br><span class="line">                fuse_layer.append(</span><br><span class="line">                    nn.Sequential(</span><br><span class="line">                        nn.Conv2d(</span><br><span class="line">                            num_inchannels[j],</span><br><span class="line">                            num_inchannels[i],</span><br><span class="line">                            <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="keyword">False</span></span><br><span class="line">                        ),</span><br><span class="line">                        nn.BatchNorm2d(num_inchannels[i]),</span><br><span class="line">                        nn.Upsample(scale_factor=<span class="number">2</span>**(j-i), mode=<span class="string">'nearest'</span>)</span><br><span class="line">                    )</span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">elif</span> j == i:</span><br><span class="line">                fuse_layer.append(<span class="keyword">None</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                conv3x3s = []</span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> range(i-j):</span><br><span class="line">                    <span class="keyword">if</span> k == i - j - <span class="number">1</span>:</span><br><span class="line">                        num_outchannels_conv3x3 = num_inchannels[i]</span><br><span class="line">                        conv3x3s.append(</span><br><span class="line">                            nn.Sequential(</span><br><span class="line">                                nn.Conv2d(</span><br><span class="line">                                    num_inchannels[j],</span><br><span class="line">                                    num_outchannels_conv3x3,</span><br><span class="line">                                    <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="keyword">False</span></span><br><span class="line">                                ),</span><br><span class="line">                                nn.BatchNorm2d(num_outchannels_conv3x3)</span><br><span class="line">                            )</span><br><span class="line">                        )</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        num_outchannels_conv3x3 = num_inchannels[j]</span><br><span class="line">                        conv3x3s.append(</span><br><span class="line">                            nn.Sequential(</span><br><span class="line">                                nn.Conv2d(</span><br><span class="line">                                    num_inchannels[j],</span><br><span class="line">                                    num_outchannels_conv3x3,</span><br><span class="line">                                    <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="keyword">False</span></span><br><span class="line">                                ),</span><br><span class="line">                                nn.BatchNorm2d(num_outchannels_conv3x3),</span><br><span class="line">                                nn.ReLU(<span class="keyword">True</span>)</span><br><span class="line">                            )</span><br><span class="line">                        )</span><br><span class="line">                fuse_layer.append(nn.Sequential(*conv3x3s))</span><br><span class="line">        fuse_layers.append(nn.ModuleList(fuse_layer))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nn.ModuleList(fuse_layers)</span><br></pre></td></tr></table></figure><h2 id="HighResolutionModule"><a href="#HighResolutionModule" class="headerlink" title="HighResolutionModule"></a>HighResolutionModule</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HighResolutionModule</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_branches, blocks, num_blocks, num_inchannels,</span></span></span><br><span class="line"><span class="function"><span class="params">                 num_channels, fuse_method, multi_scale_output=True)</span>:</span></span><br><span class="line">        super(HighResolutionModule, self).__init__()</span><br><span class="line">        self._check_branches(</span><br><span class="line">            num_branches, blocks, num_blocks, num_inchannels, num_channels)</span><br><span class="line"></span><br><span class="line">        self.num_inchannels = num_inchannels</span><br><span class="line">        self.fuse_method = fuse_method</span><br><span class="line">        self.num_branches = num_branches</span><br><span class="line"></span><br><span class="line">        self.multi_scale_output = multi_scale_output</span><br><span class="line"></span><br><span class="line">        self.branches = self._make_branches(</span><br><span class="line">            num_branches, blocks, num_blocks, num_channels)</span><br><span class="line">        self.fuse_layers = self._make_fuse_layers()</span><br><span class="line">        self.relu = nn.ReLU(<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_check_branches</span><span class="params">(self, num_branches, blocks, num_blocks,</span></span></span><br><span class="line"><span class="function"><span class="params">                        num_inchannels, num_channels)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> num_branches != len(num_blocks):</span><br><span class="line">            error_msg = <span class="string">'NUM_BRANCHES(&#123;&#125;) &lt;&gt; NUM_BLOCKS(&#123;&#125;)'</span>.format(</span><br><span class="line">                num_branches, len(num_blocks))</span><br><span class="line">            logger.error(error_msg)</span><br><span class="line">            <span class="keyword">raise</span> ValueError(error_msg)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> num_branches != len(num_channels):</span><br><span class="line">            error_msg = <span class="string">'NUM_BRANCHES(&#123;&#125;) &lt;&gt; NUM_CHANNELS(&#123;&#125;)'</span>.format(</span><br><span class="line">                num_branches, len(num_channels))</span><br><span class="line">            logger.error(error_msg)</span><br><span class="line">            <span class="keyword">raise</span> ValueError(error_msg)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> num_branches != len(num_inchannels):</span><br><span class="line">            error_msg = <span class="string">'NUM_BRANCHES(&#123;&#125;) &lt;&gt; NUM_INCHANNELS(&#123;&#125;)'</span>.format(</span><br><span class="line">                num_branches, len(num_inchannels))</span><br><span class="line">            logger.error(error_msg)</span><br><span class="line">            <span class="keyword">raise</span> ValueError(error_msg)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_make_one_branch</span><span class="params">(self, branch_index, block, num_blocks, num_channels,</span></span></span><br><span class="line"><span class="function"><span class="params">                         stride=<span class="number">1</span>)</span>:</span></span><br><span class="line">        downsample = <span class="keyword">None</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> \</span><br><span class="line">           self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:</span><br><span class="line">            downsample = nn.Sequential(</span><br><span class="line">                nn.Conv2d(</span><br><span class="line">                    self.num_inchannels[branch_index],</span><br><span class="line">                    num_channels[branch_index] * block.expansion,</span><br><span class="line">                    kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="keyword">False</span></span><br><span class="line">                ),</span><br><span class="line">                nn.BatchNorm2d(</span><br><span class="line">                    num_channels[branch_index] * block.expansion,</span><br><span class="line">                    momentum=BN_MOMENTUM</span><br><span class="line">                ),</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(</span><br><span class="line">            block(</span><br><span class="line">                self.num_inchannels[branch_index],</span><br><span class="line">                num_channels[branch_index],</span><br><span class="line">                stride,</span><br><span class="line">                downsample</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        self.num_inchannels[branch_index] = \</span><br><span class="line">            num_channels[branch_index] * block.expansion</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, num_blocks[branch_index]):</span><br><span class="line">            layers.append(</span><br><span class="line">                block(</span><br><span class="line">                    self.num_inchannels[branch_index],</span><br><span class="line">                    num_channels[branch_index]</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_make_branches</span><span class="params">(self, num_branches, block, num_blocks, num_channels)</span>:</span></span><br><span class="line">        branches = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_branches):</span><br><span class="line">            branches.append(</span><br><span class="line">                self._make_one_branch(i, block, num_blocks, num_channels)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.ModuleList(branches)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_make_fuse_layers</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.num_branches == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">        num_branches = self.num_branches</span><br><span class="line">        num_inchannels = self.num_inchannels</span><br><span class="line">        fuse_layers = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_branches <span class="keyword">if</span> self.multi_scale_output <span class="keyword">else</span> <span class="number">1</span>):</span><br><span class="line">            fuse_layer = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(num_branches):</span><br><span class="line">                <span class="keyword">if</span> j &gt; i:</span><br><span class="line">                    fuse_layer.append(</span><br><span class="line">                        nn.Sequential(</span><br><span class="line">                            nn.Conv2d(</span><br><span class="line">                                num_inchannels[j],</span><br><span class="line">                                num_inchannels[i],</span><br><span class="line">                                <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="keyword">False</span></span><br><span class="line">                            ),</span><br><span class="line">                            nn.BatchNorm2d(num_inchannels[i]),</span><br><span class="line">                            nn.Upsample(scale_factor=<span class="number">2</span>**(j-i), mode=<span class="string">'nearest'</span>)</span><br><span class="line">                        )</span><br><span class="line">                    )</span><br><span class="line">                <span class="keyword">elif</span> j == i:</span><br><span class="line">                    fuse_layer.append(<span class="keyword">None</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    conv3x3s = []</span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> range(i-j):</span><br><span class="line">                        <span class="keyword">if</span> k == i - j - <span class="number">1</span>:</span><br><span class="line">                            num_outchannels_conv3x3 = num_inchannels[i]</span><br><span class="line">                            conv3x3s.append(</span><br><span class="line">                                nn.Sequential(</span><br><span class="line">                                    nn.Conv2d(</span><br><span class="line">                                        num_inchannels[j],</span><br><span class="line">                                        num_outchannels_conv3x3,</span><br><span class="line">                                        <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="keyword">False</span></span><br><span class="line">                                    ),</span><br><span class="line">                                    nn.BatchNorm2d(num_outchannels_conv3x3)</span><br><span class="line">                                )</span><br><span class="line">                            )</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            num_outchannels_conv3x3 = num_inchannels[j]</span><br><span class="line">                            conv3x3s.append(</span><br><span class="line">                                nn.Sequential(</span><br><span class="line">                                    nn.Conv2d(</span><br><span class="line">                                        num_inchannels[j],</span><br><span class="line">                                        num_outchannels_conv3x3,</span><br><span class="line">                                        <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="keyword">False</span></span><br><span class="line">                                    ),</span><br><span class="line">                                    nn.BatchNorm2d(num_outchannels_conv3x3),</span><br><span class="line">                                    nn.ReLU(<span class="keyword">True</span>)</span><br><span class="line">                                )</span><br><span class="line">                            )</span><br><span class="line">                    fuse_layer.append(nn.Sequential(*conv3x3s))</span><br><span class="line">            fuse_layers.append(nn.ModuleList(fuse_layer))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.ModuleList(fuse_layers)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_num_inchannels</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.num_inchannels</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.num_branches == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> [self.branches[<span class="number">0</span>](x[<span class="number">0</span>])]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.num_branches):</span><br><span class="line">            x[i] = self.branches[i](x[i])</span><br><span class="line"></span><br><span class="line">        x_fuse = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.fuse_layers)):</span><br><span class="line">            y = x[<span class="number">0</span>] <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> self.fuse_layers[i][<span class="number">0</span>](x[<span class="number">0</span>])</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, self.num_branches):</span><br><span class="line">                <span class="keyword">if</span> i == j:</span><br><span class="line">                    y = y + x[j]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    y = y + self.fuse_layers[i][j](x[j])</span><br><span class="line">            x_fuse.append(self.relu(y))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x_fuse</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      CVPR-2019 Deep High-Resolution Representation Learning for Human Pose Estimation
    
    </summary>
    
      <category term="Deep Learning" scheme="https://www.starlg.cn/categories/Deep-Learning/"/>
    
    
      <category term="Deep Learning" scheme="https://www.starlg.cn/tags/Deep-Learning/"/>
    
      <category term="Pose Estimation" scheme="https://www.starlg.cn/tags/Pose-Estimation/"/>
    
  </entry>
  
  <entry>
    <title>Adaptive NMS Refining Pedestrian Detection in a Crowd</title>
    <link href="https://www.starlg.cn/2019/05/20/Adaptive-NMS/"/>
    <id>https://www.starlg.cn/2019/05/20/Adaptive-NMS/</id>
    <published>2019-05-20T09:11:31.000Z</published>
    <updated>2019-05-23T08:57:19.019Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://arxiv.org/abs/1904.03629" target="_blank" rel="noopener">paper link</a></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>这篇论文主要提出一个新颖的非极大值抑制（Non-Maximum Suppression, NMS）算法更好地改善检测器给出的检测框。本文主要贡献：</p><ol><li>提出adaptive-NMS，该算法根据目标的密度使用一个动态抑制阈值。</li><li>设计一个高效网络学习密度得分，这个得分可以方便地嵌入到single-stage和two-stage检测器中。</li><li>实现了CityPersons和CrowdHuman数据集上的 state of the art 结果。</li></ol><h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><img src="/2019/05/20/Adaptive-NMS/2019-05-20-greddy-NMS-results.png" title="Figure 1. greedy-NMS不同阈值的结果"><p>图1展示了不同阈值下的greedy-NMS的结果。蓝色的框表示丢失的目标，红色的框表示假正例（false positives）。（b）中的检测框是Faster R-CNN在NMS之前的检测结果。如图c，一个低的NMS阈值可能会移除正例（true positives）。如同d，一个高的NMS阈值可能会增加假正例（false positives）。</p><p>在本文中，作者提出了一种新的NMS算法，名为adaptive-NMS，它可以作为人群中行人检测的更有效的替代方案。直观地，高NMS阈值保持更多拥挤的实例，而低NMS阈值消除更多误报。因此，自适应NMS应用动态抑制策略，其中阈值随着实例聚集和相互遮挡而上升，并且当实例单独出现时衰减。为此，我们设计了一个辅助且可学习的子网络来预测每个实例的自适应NMS阈值。</p><h1 id="Adaptive-NMS"><a href="#Adaptive-NMS" class="headerlink" title="Adaptive-NMS"></a>Adaptive-NMS</h1><img src="/2019/05/20/Adaptive-NMS/adaptive-nms-pseudo-code.png" title="Figure 2. adaptive-NMS伪代码"><p>当物体处于拥挤区域时，增加NMS的阈值可以保留高覆盖率。同样，在稀疏场景下，应该去掉重复度高的候选框，因为它们很可能是假正例。</p><p>$$<br>d_i:= \max_{b_j \in \mathcal{G}, i \neq j} \mathrm{iou}(b_i, b_j)<br>$$</p><p>目标$i$的密度被定义和在ground truth集合$\mathcal{G}$中的其他目标的最大紧致框的IoU的值。目标的密度表示拥挤遮挡的程度。</p><p>使用这个定义，我们提出更新下面策略中的移除步骤，</p><p>$$<br>N_\mathcal{M} := \max(N_t, d_\mathcal{M})<br>$$</p><img src="/2019/05/20/Adaptive-NMS/2019-05-20-greddy-NMS-eq3.png"><p>$N_t$表示对于$\mathcal{M}$的adaptive NMS的阈值，$d_{\mathcal{M}}$表示目标$\mathcal{M}$覆盖的密度。</p><p>这个抑制策略有三个性质：</p><ol><li>当相邻的框远离$\mathcal{M}$时，即$\mathrm{iou}(\mathcal{M}, b_i) &lt; N_t$，它们与原始NMS保持一致。</li><li>如果$\mathcal{M}$定位到拥挤的区域，即$d_{\mathcal{M}} &gt; N_t$，$\mathcal{M}$的密度被使用作为adaptive NMS的阈值。</li><li>对与稀疏区域的目标，即$d_{\mathcal{M}} \leq N_t$，NMS阈值$N_\mathcal{M}$和原始NMS阈值相等，非常接近的框被作为假正例所抑制。</li></ol><p>这个算法具体步骤如图2所示。</p><h1 id="Density-Prediction"><a href="#Density-Prediction" class="headerlink" title="Density Prediction"></a>Density Prediction</h1><img src="/2019/05/20/Adaptive-NMS/CVPR19_CSP_Adaptive_NMS.png" title="Figure 3. 密度估计网络"><p>作者把密度估计作为一个回归问题，目标密度值的计算根据它的定义，使用Smooth-L1损失函数作为训练损失。</p><p>一个天然的方式就是为这个回归在网络顶部添加一个并行的层，像分类和定位一样。然而，用于检测的特征仅仅包含目标自己的信息，比如外表、语义特征和位置。对于密度估计，使用独立目标的信息很难估计其密度，密度估计需要使用其周围目标的更多的线索。</p><p>为了解决这个，作者设计了一个额外的网络，它由三层卷积层构成，如图3所示。首选使用一个1x1的卷积层做特征维度降维，然后级联降维后的特征、用于RPN分类的特征和用于RPN回归的特征。最后使用一个大尺度的卷积核5x5作为最后的卷积层，为了把周围的信息送入网络。具体如图中Density subnet绿色框区域结构。</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><img src="/2019/05/20/Adaptive-NMS/2019-05-20-Adaptive-NMS-Comparison.png" title="Table 2. 在CityPersons验证集上的性能"><img src="/2019/05/20/Adaptive-NMS/2019-05-20-Adaptive-NMS-compare-detection-results.png" title="Figure 5. 部分结果对比"><img src="/2019/05/20/Adaptive-NMS/2019-05-20-Adaptive-NMS-Comparison-CityPersons-test.png" title="Table 3. 在CityPersons测试集上的性能"><img src="/2019/05/20/Adaptive-NMS/2019-05-20-Adaptive-NMS-CrowdHuman-val.png" title="Table 5. 在CrowdHuman验证集上full body的测试结果">]]></content>
    
    <summary type="html">
    
      CVPR-19 oral Adaptive NMS Refining Pedestrian Detection in a Crowd
    
    </summary>
    
      <category term="Pedestrian Detection" scheme="https://www.starlg.cn/categories/Pedestrian-Detection/"/>
    
    
      <category term="Pedestrian Detection" scheme="https://www.starlg.cn/tags/Pedestrian-Detection/"/>
    
      <category term="Deep Learning" scheme="https://www.starlg.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Squeeze-and-Excitation Networks</title>
    <link href="https://www.starlg.cn/2019/05/17/Squeeze-and-Excitation-Networks/"/>
    <id>https://www.starlg.cn/2019/05/17/Squeeze-and-Excitation-Networks/</id>
    <published>2019-05-17T06:57:27.000Z</published>
    <updated>2019-05-20T09:08:45.112Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SENet介绍"><a href="#SENet介绍" class="headerlink" title="SENet介绍"></a>SENet介绍</h1><p>卷积神经网络（CNNs）的核心模块是卷积操作，这个操作使得网络能够通过每层的局部感受野融合空间和通道的信息，来构建有信息的特征。之前大量的工作已经研究了这种关系的空间组成部分，试图通过提高整个特征层次中空间编码的质量来增强CNN的表征能力。在这项工作中，作者将重点放在通道关系上，并且提出一个新的构架单元，成为“Squeeze-and-Excitation”（SE）块，通过明确地建模通道之间的相互依赖性来自适应地重新校准通道方面的特征响应。</p><h1 id="Squeeze-and-Excitation-Blocks"><a href="#Squeeze-and-Excitation-Blocks" class="headerlink" title="Squeeze-and-Excitation Blocks"></a>Squeeze-and-Excitation Blocks</h1><img src="/2019/05/17/Squeeze-and-Excitation-Networks/sENet.png"><img src="/2019/05/17/Squeeze-and-Excitation-Networks/sENet-eq1.png"><h2 id="Squeeze-全局信息嵌入"><a href="#Squeeze-全局信息嵌入" class="headerlink" title="Squeeze: 全局信息嵌入"></a>Squeeze: 全局信息嵌入</h2><img src="/2019/05/17/Squeeze-and-Excitation-Networks/sENet-eq2.png"><h2 id="Excition-适应性地校准"><a href="#Excition-适应性地校准" class="headerlink" title="Excition: 适应性地校准"></a>Excition: 适应性地校准</h2><img src="/2019/05/17/Squeeze-and-Excitation-Networks/sENet-eq3.png"><img src="/2019/05/17/Squeeze-and-Excitation-Networks/sENet-eq4.png"><h1 id="实例化到ResNet和Inception"><a href="#实例化到ResNet和Inception" class="headerlink" title="实例化到ResNet和Inception"></a>实例化到ResNet和Inception</h1><img src="/2019/05/17/Squeeze-and-Excitation-Networks/sE-Inception.png" title="Figure 1. SE-Inception module"><img src="/2019/05/17/Squeeze-and-Excitation-Networks/sE-ResNet.png" title="Figure 1. SE-Inception module"><img src="/2019/05/17/Squeeze-and-Excitation-Networks/sENet-Table1.png" title="Figure 1. SE-Inception module"><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><h2 id="Caffe"><a href="#Caffe" class="headerlink" title="Caffe"></a>Caffe</h2><p><a href="https://github.com/hujie-frank/SENet" target="_blank" rel="noopener">Caffe SENet</a></p><h2 id="第三方实现"><a href="#第三方实现" class="headerlink" title="第三方实现"></a>第三方实现</h2><ol start="0"><li>Caffe. SE-mudolues are integrated with a modificated ResNet-50 using a stride 2 in the 3x3 convolution instead of the first 1x1 convolution which obtains better performance: <a href="https://github.com/shicai/SENet-Caffe" target="_blank" rel="noopener">Repository</a>.</li><li>TensorFlow. SE-modules are integrated with a pre-activation ResNet-50 which follows the setup in <a href="https://github.com/facebook/fb.resnet.torch" target="_blank" rel="noopener">fb.resnet.torch</a>: <a href="https://github.com/ppwwyyxx/tensorpack/tree/master/examples/ResNet" target="_blank" rel="noopener">Repository</a>.</li><li>TensorFlow. Simple Tensorflow implementation of SENets using Cifar10: <a href="https://github.com/taki0112/SENet-Tensorflow" target="_blank" rel="noopener">Repository</a>.</li><li>MatConvNet. All the released SENets are imported into <a href="https://github.com/vlfeat/matconvnet" target="_blank" rel="noopener">MatConvNet</a>: <a href="https://github.com/albanie/mcnSENets" target="_blank" rel="noopener">Repository</a>.</li><li>MXNet. SE-modules are integrated with the ResNeXt and more architectures are coming soon: <a href="https://github.com/bruinxiong/SENet.mxnet" target="_blank" rel="noopener">Repository</a>.</li><li>PyTorch. Implementation of SENets by PyTorch: <a href="https://github.com/moskomule/senet.pytorch" target="_blank" rel="noopener">Repository</a>.</li><li>Chainer. Implementation of SENets by Chainer: <a href="https://github.com/nutszebra/SENets" target="_blank" rel="noopener">Repository</a>.</li></ol><h2 id="Pytorch实现SE模块"><a href="#Pytorch实现SE模块" class="headerlink" title="Pytorch实现SE模块"></a>Pytorch实现SE模块</h2><p>来自<a href="https://github.com/moskomule/senet.pytorch/blob/master/senet/se_module.py的se_module.py文件" target="_blank" rel="noopener">https://github.com/moskomule/senet.pytorch/blob/master/senet/se_module.py的se_module.py文件</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">from torch import nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class SELayer(nn.Module):</span><br><span class="line">    def __init__(self, channel, reduction=16):</span><br><span class="line">        super(SELayer, self).__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(1)</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(channel, channel // reduction, bias=False),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Linear(channel // reduction, channel, bias=False),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        b, c, _, _ = x.size()</span><br><span class="line">        y = self.avg_pool(x).view(b, c)</span><br><span class="line">        y = self.fc(y).view(b, c, 1, 1)</span><br><span class="line">        return x * y.expand_as(x)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      SENet
    
    </summary>
    
      <category term="Deep Learning" scheme="https://www.starlg.cn/categories/Deep-Learning/"/>
    
    
      <category term="Deep Learning" scheme="https://www.starlg.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Pillow Tutorial</title>
    <link href="https://www.starlg.cn/2019/04/11/Pillow-Tutorial/"/>
    <id>https://www.starlg.cn/2019/04/11/Pillow-Tutorial/</id>
    <published>2019-04-11T07:56:55.000Z</published>
    <updated>2019-06-23T07:54:00.201Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Pillow-教程"><a href="#Pillow-教程" class="headerlink" title="Pillow 教程"></a>Pillow 教程</h1><p>PIL(Python Image Library)是python的第三方图像处理库。其官方主页为:PIL。 PIL历史悠久，原来是只支持python2.x的版本的，后来出现了移植到python3的库pillow, pillow号称是friendly fork for PIL。</p><p>Pillow is the friendly PIL fork by Alex Clark and Contributors. PIL is the Python Imaging Library by Fredrik Lundh and Contributors.</p><p>for Python2<br><a href="http://pythonware.com/products/pil/" target="_blank" rel="noopener">Python Imaging Library (PIL)</a></p><p>for Python3<br><a href="http://www.effbot.org/imagingbook/" target="_blank" rel="noopener">The Python Imaging Library Handbook</a></p><p><a href="https://python-pillow.org/" target="_blank" rel="noopener">python-pillow</a></p><p><a href="https://github.com/python-pillow/Pillow" target="_blank" rel="noopener">Pillow Github</a></p><p><a href="https://pillow.readthedocs.io/en/stable/" target="_blank" rel="noopener">Pillow Docs</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><p>从一个文件加载图片，使用在<code>Image</code>模块下的<code>open()</code>函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">im = Image.open(<span class="string">"lena.jpg"</span>)</span><br></pre></td></tr></table></figure><h2 id="1-使用Image类"><a href="#1-使用Image类" class="headerlink" title="1. 使用Image类"></a>1. 使用Image类</h2><p>如果成功，这个函数会返回一个<code>Image</code>目标。你可以使用实例属性去测试这个文件的内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line">print(im.format, im.size, im.mode)</span><br></pre></td></tr></table></figure><pre><code>JPEG (512, 512) RGB</code></pre><p><code>format</code>属性判断图片的来源。如果一个图片不是从一个文件读入，它会被设置成None。<code>size</code>属性是一个2元组，包含宽和高。<code>mode</code>属性定义图片通道的数量和名字，以及像素类型和深度。通常的模式包含：“L”（luminance）表示灰度图像，”RGB“表示真彩色图像，”CMYK“表示印前（pre-press）图像</p><p>如果文件没有被打开，会给出<code>IOError</code>。</p><p>一旦你有一个<code>Image</code>类的实例，你可以使用这个类定义的方法取处理这个图片。例如，显示我们刚加载的图片：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">im.show()</span><br></pre></td></tr></table></figure><p>使用matplotlib进行可视化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(im)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x7f1173b85518&gt;</code></pre><p><img src="output_12_1.png" alt="png"></p><h2 id="2-读取和写入图像"><a href="#2-读取和写入图像" class="headerlink" title="2. 读取和写入图像"></a>2. 读取和写入图像</h2><h2 id="3-剪切、复制和合并图像"><a href="#3-剪切、复制和合并图像" class="headerlink" title="3. 剪切、复制和合并图像"></a>3. 剪切、复制和合并图像</h2><p><code>Image</code>类包含允许您操作图像中的区域的方法。要从图像中提取矩形区域，请使用<code>crop()</code>方法。</p><h3 id="从一个图片中复制一个矩形区域"><a href="#从一个图片中复制一个矩形区域" class="headerlink" title="从一个图片中复制一个矩形区域"></a>从一个图片中复制一个矩形区域</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">box = (<span class="number">100</span>, <span class="number">100</span>, <span class="number">400</span>, <span class="number">400</span>)</span><br><span class="line">region = im.crop(box)</span><br><span class="line">print(region.size)</span><br></pre></td></tr></table></figure><pre><code>(300, 300)</code></pre><p>这个区域使用一个4元组定义，它的坐标是(left, upper, right, lower)。Python Imaging Library在左上角使用(0, 0)的坐标系统。坐标表示像素之间的位置，因此上边例子中的区域是300x300像素。</p><h3 id="处理一个矩形区域，并且把它粘贴回原来位置"><a href="#处理一个矩形区域，并且把它粘贴回原来位置" class="headerlink" title="处理一个矩形区域，并且把它粘贴回原来位置"></a>处理一个矩形区域，并且把它粘贴回原来位置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">region = region.transpose(Image.ROTATE_180)</span><br><span class="line">im.paste(region, box)</span><br><span class="line">plt.imshow(im)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x7f11721e2518&gt;</code></pre><p><img src="output_20_1.png" alt="png"></p><p>当把区域粘贴回去，区域的尺寸必须相同。除此之外，这个区域不能超越图像的边界。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">roll</span><span class="params">(image, delta)</span>:</span></span><br><span class="line">    <span class="string">"""Roll an image sideways."""</span></span><br><span class="line">    xsize, ysize = image.size</span><br><span class="line"></span><br><span class="line">    delta = delta % xsize</span><br><span class="line">    <span class="keyword">if</span> delta == <span class="number">0</span>: <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line">    part1 = image.crop((<span class="number">0</span>, <span class="number">0</span>, delta, ysize))</span><br><span class="line">    part2 = image.crop((delta, <span class="number">0</span>, xsize, ysize))</span><br><span class="line">    image.paste(part1, (xsize-delta, <span class="number">0</span>, xsize, ysize))</span><br><span class="line">    image.paste(part2, (<span class="number">0</span>, <span class="number">0</span>, xsize-delta, ysize))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image</span><br></pre></td></tr></table></figure><h3 id="拆分和合并通道"><a href="#拆分和合并通道" class="headerlink" title="拆分和合并通道"></a>拆分和合并通道</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">r, g, b = im.split()</span><br><span class="line">im = Image.merge(<span class="string">"RGB"</span>, (b, g, r))</span><br><span class="line">plt.imshow(im)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x7f11721c9b38&gt;</code></pre><p><img src="output_24_1.png" alt="png"></p><h3 id="保存图像"><a href="#保存图像" class="headerlink" title="保存图像"></a>保存图像</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">im.save(<span class="string">r'out.jpg'</span>)</span><br></pre></td></tr></table></figure><h3 id="新建图像"><a href="#新建图像" class="headerlink" title="新建图像"></a>新建图像</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">newIm= Image.new(<span class="string">'RGB'</span>, (<span class="number">50</span>, <span class="number">50</span>), <span class="string">'red'</span>)</span><br><span class="line">plt.imshow(newIm)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x7f1175c2d630&gt;</code></pre><p><img src="output_28_1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 十六进制颜色</span></span><br><span class="line">newIm = Image.new(<span class="string">'RGBA'</span>,(<span class="number">100</span>, <span class="number">50</span>), <span class="string">'#FF0000'</span>)</span><br><span class="line">plt.imshow(newIm)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x7f1175bfd8d0&gt;</code></pre><p><img src="output_29_1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 传入元组形式的RGBA值或者RGB值</span></span><br><span class="line"><span class="comment"># 在RGB模式下，第四个参数失效，默认255，在RGBA模式下，也可只传入前三个值，A值默认255</span></span><br><span class="line">newIm = Image.new(<span class="string">'RGB'</span>,(<span class="number">200</span>, <span class="number">100</span>), (<span class="number">255</span>, <span class="number">255</span>, <span class="number">0</span>, <span class="number">120</span>))</span><br><span class="line">plt.imshow(newIm)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x7f1175bd1be0&gt;</code></pre><p><img src="output_30_1.png" alt="png"></p><h3 id="复制图片"><a href="#复制图片" class="headerlink" title="复制图片"></a>复制图片</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">copyIm = im.copy()</span><br><span class="line">copyIm.size</span><br></pre></td></tr></table></figure><pre><code>(512, 512)</code></pre><h3 id="调整图片大小"><a href="#调整图片大小" class="headerlink" title="调整图片大小"></a>调整图片大小</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">width, height = copyIm.size</span><br><span class="line">resizedIm = im.resize((width, int(<span class="number">0.5</span>* height)))</span><br><span class="line">resizedIm.size</span><br></pre></td></tr></table></figure><pre><code>(512, 256)</code></pre><h2 id="4-几何变换"><a href="#4-几何变换" class="headerlink" title="4. 几何变换"></a>4. 几何变换</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">im = Image.open(<span class="string">"lena.jpg"</span>)</span><br><span class="line">out = im.resize((<span class="number">128</span>, <span class="number">128</span>))</span><br><span class="line">out = im.rotate(<span class="number">45</span>) <span class="comment"># degrees counter-clockwise</span></span><br><span class="line">plt.imshow(out)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x7f11721370b8&gt;</code></pre><p><img src="output_36_1.png" alt="png"></p><h3 id="转置图像"><a href="#转置图像" class="headerlink" title="转置图像"></a>转置图像</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">out = im.transpose(Image.FLIP_LEFT_RIGHT)</span><br><span class="line">out = im.transpose(Image.FLIP_TOP_BOTTOM)</span><br><span class="line">out = im.transpose(Image.ROTATE_90)</span><br><span class="line">out = im.transpose(Image.ROTATE_180)</span><br><span class="line">out = im.transpose(Image.ROTATE_270)</span><br><span class="line">plt.imshow(out)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x7f1172111080&gt;</code></pre><p><img src="output_38_1.png" alt="png"></p><h2 id="5-颜色变换"><a href="#5-颜色变换" class="headerlink" title="5. 颜色变换"></a>5. 颜色变换</h2><h3 id="在不同models之间转换"><a href="#在不同models之间转换" class="headerlink" title="在不同models之间转换"></a>在不同models之间转换</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">im = Image.open(<span class="string">"lena.jpg"</span>).convert(<span class="string">"L"</span>)</span><br><span class="line">print(im.mode)</span><br></pre></td></tr></table></figure><pre><code>L</code></pre><h2 id="6-图片增强"><a href="#6-图片增强" class="headerlink" title="6. 图片增强"></a>6. 图片增强</h2><h3 id="滤波器"><a href="#滤波器" class="headerlink" title="滤波器"></a>滤波器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> ImageFilter</span><br><span class="line">out = im.filter(ImageFilter.DETAIL)</span><br><span class="line">plt.imshow(out)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x7f1172073860&gt;</code></pre><p><img src="output_44_1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 高斯模糊</span></span><br><span class="line">out = im.filter(ImageFilter.GaussianBlur)</span><br><span class="line">plt.imshow(out)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x7f117204f470&gt;</code></pre><p><img src="output_45_1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 边缘增强</span></span><br><span class="line">im.filter(ImageFilter.EDGE_ENHANCE)</span><br><span class="line">plt.imshow(out)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x7f1171faf0b8&gt;</code></pre><p><img src="output_46_1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 普通模糊</span></span><br><span class="line">im.filter(ImageFilter.BLUR)</span><br><span class="line"><span class="comment"># 找到边缘</span></span><br><span class="line">im.filter(ImageFilter.FIND_EDGES)</span><br><span class="line"><span class="comment"># 浮雕</span></span><br><span class="line">im.filter(ImageFilter.EMBOSS)</span><br><span class="line"><span class="comment"># 轮廓</span></span><br><span class="line">im.filter(ImageFilter.CONTOUR)</span><br><span class="line"><span class="comment"># 锐化</span></span><br><span class="line">im.filter(ImageFilter.SHARPEN)</span><br><span class="line"><span class="comment"># 平滑</span></span><br><span class="line">im.filter(ImageFilter.SMOOTH)</span><br><span class="line"><span class="comment"># 细节</span></span><br><span class="line">im.filter(ImageFilter.DETAIL)</span><br></pre></td></tr></table></figure><p><img src="output_47_0.png" alt="png"></p><h3 id="应用点变换"><a href="#应用点变换" class="headerlink" title="应用点变换"></a>应用点变换</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># multiply each pixel by 1.2</span></span><br><span class="line">out = im.point(<span class="keyword">lambda</span> i: i * <span class="number">1.2</span>)</span><br></pre></td></tr></table></figure><h3 id="增强图像"><a href="#增强图像" class="headerlink" title="增强图像"></a>增强图像</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> ImageEnhance</span><br><span class="line"></span><br><span class="line">enh = ImageEnhance.Contrast(im)</span><br><span class="line">out = enh.enhance(<span class="number">1.3</span>)</span><br><span class="line">plt.imshow(out)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x7f1171f906a0&gt;</code></pre><p><img src="output_51_1.png" alt="png"></p><h2 id="7-图片序列"><a href="#7-图片序列" class="headerlink" title="7. 图片序列"></a>7. 图片序列</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">im = Image.open(<span class="string">"chi.gif"</span>)</span><br><span class="line">im.seek(<span class="number">1</span>) <span class="comment"># skip to the second frame</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        im.seek(im.tell()+<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># do something to im</span></span><br><span class="line"><span class="keyword">except</span> EOFError:</span><br><span class="line">    <span class="keyword">pass</span> <span class="comment"># end of sequence</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(im)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x7f1171eec208&gt;</code></pre><p><img src="output_54_1.png" alt="png"></p><h3 id="使用ImageSequence-Iterator类"><a href="#使用ImageSequence-Iterator类" class="headerlink" title="使用ImageSequence Iterator类"></a>使用ImageSequence Iterator类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> ImageSequence</span><br><span class="line">count = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> frame <span class="keyword">in</span> ImageSequence.Iterator(im):</span><br><span class="line">    <span class="comment"># ...do something to frame...</span></span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> count % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        plt.imshow(frame)</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_56_0.png" alt="png"></p><p><img src="output_56_1.png" alt="png"></p><p><img src="output_56_2.png" alt="png"></p><h2 id="8-Postscript-printing"><a href="#8-Postscript-printing" class="headerlink" title="8. Postscript printing"></a>8. Postscript printing</h2><h3 id="Drawing-Postscript"><a href="#Drawing-Postscript" class="headerlink" title="Drawing Postscript"></a>Drawing Postscript</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> PSDraw</span><br><span class="line"></span><br><span class="line">im = Image.open(<span class="string">"hopper.ppm"</span>)</span><br><span class="line">title = <span class="string">"hopper"</span></span><br><span class="line">box = (<span class="number">1</span>*<span class="number">72</span>, <span class="number">2</span>*<span class="number">72</span>, <span class="number">7</span>*<span class="number">72</span>, <span class="number">10</span>*<span class="number">72</span>) <span class="comment"># in points</span></span><br><span class="line"></span><br><span class="line">ps = PSDraw.PSDraw() <span class="comment"># default is sys.stdout</span></span><br><span class="line">ps.begin_document(title)</span><br><span class="line"></span><br><span class="line"><span class="comment"># draw the image (75 dpi)</span></span><br><span class="line">ps.image(box, im, <span class="number">75</span>)</span><br><span class="line">ps.rectangle(box)</span><br><span class="line"></span><br><span class="line"><span class="comment"># draw title</span></span><br><span class="line">ps.setfont(<span class="string">"HelveticaNarrow-Bold"</span>, <span class="number">36</span>)</span><br><span class="line">ps.text((<span class="number">3</span>*<span class="number">72</span>, <span class="number">4</span>*<span class="number">72</span>), title)</span><br><span class="line"></span><br><span class="line">ps.end_document()</span><br></pre></td></tr></table></figure><pre><code>%!PS-Adobe-3.0save/showpage { } def%%EndComments%%BeginDocument/S { show } bind def/P { moveto show } bind def/M { moveto } bind def/X { 0 rmoveto } bind def/Y { 0 exch rmoveto } bind def/E {    findfont        dup maxlength dict begin        {                1 index /FID ne { def } { pop pop } ifelse        } forall        /Encoding exch def        dup /FontName exch def        currentdict end definefont pop} bind def/F {    findfont exch scalefont dup setfont        [ exch /setfont cvx ] cvx bind def} bind def/Vm { moveto } bind def/Va { newpath arcn stroke } bind def/Vl { moveto lineto stroke } bind def/Vc { newpath 0 360 arc closepath } bind def/Vr {   exch dup 0 rlineto        exch dup neg 0 exch rlineto        exch neg 0 rlineto        0 exch rlineto        100 div setgray fill 0 setgray } bind def/Tm matrix def/Ve {   Tm currentmatrix pop        translate scale newpath 0 0 .5 0 360 arc closepath        Tm setmatrix} bind def/Vf { currentgray exch setgray fill setgray } bind def%%EndProloggsave226.560000 370.560000 translate0.960000 0.960000 scalegsave10 dict begin/buf 384 string def128 128 scale128 128 8[128 0 0 -128 0 128]{ currentfile buf readhexstring pop } bindfalse 3 colorimage%%%%EndBinarygrestore endgrestore72 144 M 504 720 0 Vr/PSDraw-HelveticaNarrow-Bold ISOLatin1Encoding /HelveticaNarrow-Bold E/F0 36 /PSDraw-HelveticaNarrow-Bold F216 288 M (hopper) S%%EndDocumentrestore showpage%%End</code></pre><h2 id="9-更多关于图像读取"><a href="#9-更多关于图像读取" class="headerlink" title="9. 更多关于图像读取"></a>9. 更多关于图像读取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">im = Image.open(<span class="string">"hopper.ppm"</span>)</span><br><span class="line">plt.imshow(im)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x7f1171d5a400&gt;</code></pre><p><img src="output_60_1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"hopper.ppm"</span>, <span class="string">"rb"</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    im = Image.open(fp)</span><br><span class="line">    plt.imshow(im)</span><br></pre></td></tr></table></figure><p><img src="output_61_0.png" alt="png"></p><h2 id="10-控制解码器"><a href="#10-控制解码器" class="headerlink" title="10. 控制解码器"></a>10. 控制解码器</h2><h3 id="使用草稿（draft）模式读取"><a href="#使用草稿（draft）模式读取" class="headerlink" title="使用草稿（draft）模式读取"></a>使用草稿（draft）模式读取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">im = Image.open(<span class="string">"lena.jpg"</span>)</span><br><span class="line">print(<span class="string">"original ="</span>, im.mode, im.size)</span><br><span class="line"></span><br><span class="line">im.draft(<span class="string">"L"</span>, (<span class="number">100</span>, <span class="number">100</span>))</span><br><span class="line">print(<span class="string">"draft ="</span>, im.mode, im.size)</span><br></pre></td></tr></table></figure><pre><code>original = RGB (512, 512)draft = L (128, 128)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      Pillow 教程
    
    </summary>
    
      <category term="Python" scheme="https://www.starlg.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.starlg.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Panoptic Feature Pyramid Networks</title>
    <link href="https://www.starlg.cn/2019/01/11/Panoptic-Feature-Pyramid-Networks/"/>
    <id>https://www.starlg.cn/2019/01/11/Panoptic-Feature-Pyramid-Networks/</id>
    <published>2019-01-11T03:10:04.000Z</published>
    <updated>2019-04-11T08:01:44.134Z</updated>
    
    <content type="html"><![CDATA[<p>论文链接：<a href="http://arxiv.org/abs/1901.02446" target="_blank" rel="noopener">http://arxiv.org/abs/1901.02446</a></p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>全景分割(panoptic segmentation)</p><p>实例分割(instance segmentation)(for thing classes)</p><p>语义分割(semantic segmentation)(for stuff classes)</p><p>之前的一些方法使用了分开的不相似的网络做实例分割和语义分割，它们之间没有任何共享计算。在这个工作中，作者在结构层面统一了这些方法，设计了一个单一网络用于这些任务。</p><p>该方法使用一个语义分割分支扩展Mask-RCNN，使其具有全景分割的能力。该分支使用了一个共享的特征金字塔网络主干。该方法不仅保持了实例分割的性能，也得到了一个轻量级权重的、高性能的语义分割方法。</p><a id="more"></a><hr><img src="/2019/01/11/Panoptic-Feature-Pyramid-Networks/panopticFPN.png" title="Figure 1. Panoptic FPN."><img src="/2019/01/11/Panoptic-Feature-Pyramid-Networks/panopticfpnResults.png" title="Figure 2. Panoptic FPN results on COCO (top) and Cityscapes (bottom) using a single ResNet-101-FPN network."><p>图２展示了Panoptic　Feature　Pyramid　Networks的预测结果。</p><h2 id="Panoptic-Feature-Pyramid-Network"><a href="#Panoptic-Feature-Pyramid-Network" class="headerlink" title="Panoptic Feature Pyramid Network"></a>Panoptic Feature Pyramid Network</h2><p>该网络结构在原有的Feature Pyramid Network的基础上，保持了原有的Instance segmentation branch，新提出了Panoptic FPN。</p><p>Panoptic FPN: As discussed, our approach is to modify Mask R-CNN with FPN to enable pixel-wise semantic seg- mentation prediction. However, to achieve accurate predic- tions, the features used for this task should: (1) be of suit- ably high resolution to capture fine structures, (2) encode sufficiently rich semantics to accurately predict class labels, and (3) capture multi-scale information to predict stuff re- gions at multiple resolutions. Although FPN was designed for object detection, these requirements – high-resolution, rich, multi-scale features – identify exactly the characteris- tics of FPN. We thus propose to attach to FPN a simple and fast semantic segmentation branch, described next.</p><h3 id="Semantic-segmentation-branch"><a href="#Semantic-segmentation-branch" class="headerlink" title="Semantic segmentation branch"></a>Semantic segmentation branch</h3><img src="/2019/01/11/Panoptic-Feature-Pyramid-Networks/semanticSegmentationBranch.png" title="Figure 3: Semantic segmentation branch."><p>图３显示了语义分割分支。左侧的每个FPN层通过卷积和双线性插值上采样被上采样，直到它达到1/4的尺度（右侧），这些输出被加和，并且最终转换为一个像素级别的输出。</p><p>重点介绍语义分割分支：</p><p>为了从FPN特征生成语义分割的输出，作者提出一个简单的设计去融合来自FPN金字塔层中所有信息到一个单一的输出，如上图３所示。开始与最深层的FPN(在尺度1/32上)，我们执行山歌上采样阶段去产生一个1/4尺度的特征图，这里每一个上采样阶段包含3x3卷积，group norm, ReLU，和2x bilinear upsampling。这些策略被重复用在其他FPN尺度上(1/16,1/8和1/4)，并且渐进地减少上采样步骤。这个结果是在1/4尺度的输出特征层的一个集合，该集合是通过元素相加的方法组合成的。1x1卷积，4x bilinear upsampling和softmax被用于在原始图像分辨率上生成每个像素的类别标签。</p><img src="/2019/01/11/Panoptic-Feature-Pyramid-Networks/semanticSegmentationBranchTmp.png"><img src="/2019/01/11/Panoptic-Feature-Pyramid-Networks/backboneArchitecturesPFPN.png" title="Figure 5: Backbone architectures for increasing feature resolution."><p>图５是用于增加分辨率的骨干网结构。(a)是标准的卷积网络，(维度定义为#blocksx#channels#xresolution)。(b)通过使用空洞卷积(dilated convolutions)来减少卷积的步长。(c)一个U-Net风格的网络，使用一个对称的解码器镜像bottom-up通路，但是是反向的。(d)FPN可以被视为一个非对称的、轻权重的解码器，它的top-down通路中每个stage仅仅有一个block，并且使用了一个相同的通道维度。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;论文链接：&lt;a href=&quot;http://arxiv.org/abs/1901.02446&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://arxiv.org/abs/1901.02446&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;全景分割(panoptic segmentation)&lt;/p&gt;
&lt;p&gt;实例分割(instance segmentation)(for thing classes)&lt;/p&gt;
&lt;p&gt;语义分割(semantic segmentation)(for stuff classes)&lt;/p&gt;
&lt;p&gt;之前的一些方法使用了分开的不相似的网络做实例分割和语义分割，它们之间没有任何共享计算。在这个工作中，作者在结构层面统一了这些方法，设计了一个单一网络用于这些任务。&lt;/p&gt;
&lt;p&gt;该方法使用一个语义分割分支扩展Mask-RCNN，使其具有全景分割的能力。该分支使用了一个共享的特征金字塔网络主干。该方法不仅保持了实例分割的性能，也得到了一个轻量级权重的、高性能的语义分割方法。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Focal Loss for Dense Object Detection</title>
    <link href="https://www.starlg.cn/2019/01/10/Focal-Loss/"/>
    <id>https://www.starlg.cn/2019/01/10/Focal-Loss/</id>
    <published>2019-01-10T13:03:52.000Z</published>
    <updated>2019-04-11T08:01:17.105Z</updated>
    
    <content type="html"><![CDATA[<p>本文代码：<a href="https://github.com/facebookresearch/Detectron" target="_blank" rel="noopener">https://github.com/facebookresearch/Detectron</a></p><p>本文主要解决在one-stage的密集检测器中，大量前景和背景不平衡的问题。作者通过降低被很好分类样本的权重来解决类别不平衡的问题。Focal Loss集中于在稀疏难样本(hard examples)上的训练，并且在训练中防止大量的容易的反例(easy negatives)淹没检测器。</p><ol><li>提出Focal Loss, 解决正负样本不平衡问题;</li><li>提出one-stage检测模型，RetinaNet。</li></ol><a id="more"></a><img src="/2019/01/10/Focal-Loss/focalLoss.png" title="Figure 1. Focal Loss"><p>作者提出一个新的损失函数 Focal Loss, 该方法通过添加因子$(1-p_t)^\gamma$到标准的交叉熵损失函数。设定$\gamma&gt;0$会减少被很好分类样本($p&gt;0.5$)的相对损失，更加关注于难和错误分类的样本。</p><img src="/2019/01/10/Focal-Loss/seedVs.Accuracy.png" title="Figure 2. Speed (ms) versus accuracy (AP) on COCO test-dev."><p>图中显示了，RetinaNet检测器使用了focal loss，结果由于之前的one-stage和two-stage检测器。</p><h3 id="类别不平衡问题"><a href="#类别不平衡问题" class="headerlink" title="类别不平衡问题"></a>类别不平衡问题</h3><p>在R-CNN这一类检测器中，类别不平衡问题通过two-stage级联和采样策略被解决。在候选区域提取阶段，Selective Search, EdgeBoxes, RPN等方法，缩小候选区域位置的数量到１~2k个，大量过滤掉了背景。在第二分类阶段，采样策略，例如固定前景背景比率(1:3)，或者在线难样本挖掘(OHEM)方法被执行用于保持前景和背景的一个可控的平衡。</p><h2 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h2><p>Focal Loss被设计用以解决one-state目标检测器训练中大量正反例样本不平衡的问题，通常是(1:1000)。我们首先介绍二值分类的交叉熵损失:</p><p>$$ CE(p, y)=\begin{cases}<br>-log(p) &amp; y=1\<br>-log(1-p) &amp; otherwise.<br>\end{cases} $$</p><h3 id="3-1-Balanced-Cross-Entropy"><a href="#3-1-Balanced-Cross-Entropy" class="headerlink" title="3.1 Balanced Cross Entropy"></a>3.1 Balanced Cross Entropy</h3><p>一种通用的解决类别不平衡的方法是对类别1引入一个权重因子$\alpha \in [0, 1]$，对类别class-1引入$1-\alpha$。我们写成$\alpha-$balanced CE loss:</p><p>$$CE(p_t)=-\alpha_t log(p_t)$$</p><h3 id="3-2-Focal-Loss-Definition"><a href="#3-2-Focal-Loss-Definition" class="headerlink" title="3.2 Focal Loss Definition"></a>3.2 Focal Loss Definition</h3><p>试验中显示，在训练dense detectors是遭遇的大量类别不平衡会压倒交叉熵损失。容易分类的样本会占损失的大部分，并且主导梯度。尽管$\alpha$平衡了正负(positive/negative)样本的重要性，但是它没有区分易和难的样本(easy/hard)。相反，作者提出的更改过后的损失函数降低了容易样本的权重并且集中训练难反例样本。</p><p>我们定义focal loss：</p><p>$$FL(p_t)=-(1-p_t)^\gamma log(p_t)$$</p><h3 id="3-4-Class-Imbalance-and-Two-stage-Detectors"><a href="#3-4-Class-Imbalance-and-Two-stage-Detectors" class="headerlink" title="3.4 Class Imbalance and Two-stage Detectors"></a>3.4 Class Imbalance and Two-stage Detectors</h3><p>Two-stage检测器通常没有使用$\alpha-$balancing 或者我们提出的loss。代替这些，他们使用了两个机制来解决类别不平衡问题：(1) 一个两级的级联，(2) 有偏置的小批量采样。第一级联阶段的候选区域提取机制减少了大量可能的候选位置。重要的是，这些选择的候选框不是随机的，而是选择更像前景的可能位置，这样就移除了大量的容易的难反例样本(easy negatives)。第二阶段，有偏置的采样通常使用1:3比率的正负样本构建小批量(minibatches)。这个采样率类似$\alpha-$balancing因子，并且通过采样来实现。作者提出的focal loss主要设计用于解决one-stage检测系统中的这些问题。</p><img src="/2019/01/10/Focal-Loss/ablationExperimentsForFocalLoss.png" title="Table 1. Ablation experiments for RetinaNet and Focal Loss (FL)."><img src="/2019/01/10/Focal-Loss/objectDetectionRetinanet.png" title="Table 2. Object detection single-model results (bounding box AP), vs. state-of-the-art on COCO test-dev. We">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文代码：&lt;a href=&quot;https://github.com/facebookresearch/Detectron&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/facebookresearch/Detectron&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文主要解决在one-stage的密集检测器中，大量前景和背景不平衡的问题。作者通过降低被很好分类样本的权重来解决类别不平衡的问题。Focal Loss集中于在稀疏难样本(hard examples)上的训练，并且在训练中防止大量的容易的反例(easy negatives)淹没检测器。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;提出Focal Loss, 解决正负样本不平衡问题;&lt;/li&gt;
&lt;li&gt;提出one-stage检测模型，RetinaNet。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="Detection" scheme="https://www.starlg.cn/categories/Detection/"/>
    
    
      <category term="Object Detection" scheme="https://www.starlg.cn/tags/Object-Detection/"/>
    
  </entry>
  
  <entry>
    <title>Docker 安装与使用</title>
    <link href="https://www.starlg.cn/2018/10/10/docker/"/>
    <id>https://www.starlg.cn/2018/10/10/docker/</id>
    <published>2018-10-10T08:20:12.000Z</published>
    <updated>2018-10-10T08:30:24.708Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Docker-安装与使用"><a href="#Docker-安装与使用" class="headerlink" title="Docker 安装与使用"></a>Docker 安装与使用</h1><p>@(工具学习记录)[Docker]</p><h2 id="1-Docker安装"><a href="#1-Docker安装" class="headerlink" title="1. Docker安装"></a>1. Docker安装</h2><p>参考<a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/" target="_blank" rel="noopener">官网教程</a></p><h3 id="卸载旧的版本"><a href="#卸载旧的版本" class="headerlink" title="卸载旧的版本"></a>卸载旧的版本</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get remove docker docker-engine docker.iSET UP THE REPOSITORY</span><br></pre></td></tr></table></figure><p>SET UP THE REPOSITORY</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get update</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install \</span><br><span class="line">    apt-transport-https \</span><br><span class="line">    ca-certificates \</span><br><span class="line">    curl \</span><br><span class="line">    software-properties-common</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-key fingerprint 0EBFCD88</span><br><span class="line"></span><br><span class="line">pub   4096R/0EBFCD88 2017-02-22</span><br><span class="line">      Key fingerprint = 9DC8 5822 9FC7 DD38 854A  E2D8 8D81 803C 0EBF CD88</span><br><span class="line">uid                  Docker Release (CE deb) &lt;docker@docker.com&gt;</span><br><span class="line">sub   4096R/F273FCD8 2017-02-22</span><br></pre></td></tr></table></figure><p>x86_64/amd64<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo add-apt-repository \</span><br><span class="line">   &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \</span><br><span class="line">   $(lsb_release -cs) \</span><br><span class="line">   stable&quot;</span><br></pre></td></tr></table></figure></p><h3 id="安装-DOCKER-CE"><a href="#安装-DOCKER-CE" class="headerlink" title="安装 DOCKER CE"></a>安装 DOCKER CE</h3><p>更新包的索引<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get update</span><br></pre></td></tr></table></figure></p><p>安装最新版本的Docker CE<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install docker-ce</span><br></pre></td></tr></table></figure></p><p>安装特定版本Docker CE<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ apt-cache madison docker-ce</span><br><span class="line"></span><br><span class="line">docker-ce | 18.03.0~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages</span><br></pre></td></tr></table></figure></p><p>验证是否安装正确<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run hello-world</span><br></pre></td></tr></table></figure></p><h2 id="2-nvidia-docker-安装"><a href="#2-nvidia-docker-安装" class="headerlink" title="2.nvidia-docker 安装"></a>2.nvidia-docker 安装</h2><p>参考<a href="https://github.com/NVIDIA/nvidia-docker" target="_blank" rel="noopener">nvidia-docker</a><br>nstalling version 2.0</p><p>Debian-based distributions<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | \</span><br><span class="line">  sudo apt-key add -</span><br><span class="line">distribution=$(. /etc/os-release;echo $ID$VERSION_ID)</span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \</span><br><span class="line">  sudo tee /etc/apt/sources.list.d/nvidia-docker.list</span><br><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install nvidia-docker2</span><br><span class="line">sudo pkill -SIGHUP dockerd</span><br></pre></td></tr></table></figure><h2 id="3-detectron-配置"><a href="#3-detectron-配置" class="headerlink" title="3. detectron 配置"></a>3. detectron 配置</h2><p>参考<a href="https://github.com/facebookresearch/Detectron/blob/master/INSTALL.md" target="_blank" rel="noopener">detectron install</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $DETECTRON/docker</span><br><span class="line">docker build -t detectron:c2-cuda9-cudnn7 .</span><br></pre></td></tr></table></figure></p><p>运行这个镜像<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-docker run --rm -it detectron:c2-cuda9-cudnn7 python detectron/tests/test_batch_permutation_op.py</span><br></pre></td></tr></table></figure></p><h2 id="4-docker-基本命令"><a href="#4-docker-基本命令" class="headerlink" title="4. docker 基本命令"></a>4. docker 基本命令</h2><h3 id="对容器生命周期管理"><a href="#对容器生命周期管理" class="headerlink" title="对容器生命周期管理"></a>对容器生命周期管理</h3><h4 id="run"><a href="#run" class="headerlink" title="run"></a>run</h4><p>docker run ：创建一个新的容器并运行一个命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">使用docker镜像nginx:latest以后台模式启动一个容器,并将容器命名为mynginx。</span><br><span class="line"></span><br><span class="line">docker run --name mynginx -d nginx:latest</span><br><span class="line">使用镜像nginx:latest以后台模式启动一个容器,并将容器的80端口映射到主机随机端口。</span><br><span class="line"></span><br><span class="line">docker run -P -d nginx:latest</span><br><span class="line">使用镜像 nginx:latest，以后台模式启动一个容器,将容器的 80 端口映射到主机的 80 端口,主机的目录 /data 映射到容器的 /data。</span><br><span class="line"></span><br><span class="line">docker run -p 80:80 -v /data:/data -d nginx:latest</span><br><span class="line">绑定容器的 8080 端口，并将其映射到本地主机 127.0.0.1 的 80 端口上。</span><br><span class="line"></span><br><span class="line">$ docker run -p 127.0.0.1:80:8080/tcp ubuntu bash</span><br><span class="line">使用镜像nginx:latest以交互模式启动一个容器,在容器内执行/bin/bash命令。</span><br><span class="line"></span><br><span class="line">runoob@runoob:~$ docker run -it nginx:latest /bin/bash</span><br><span class="line">root@b8573233d675:/#</span><br></pre></td></tr></table></figure></p><h4 id="start-stop-restart"><a href="#start-stop-restart" class="headerlink" title="start/stop/restart"></a>start/stop/restart</h4><h4 id="kill"><a href="#kill" class="headerlink" title="kill"></a>kill</h4><h4 id="rm"><a href="#rm" class="headerlink" title="rm"></a>rm</h4><p>docker rm ：删除一个或多少容器</p><p>语法<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rm [OPTIONS] CONTAINER [CONTAINER...]</span><br></pre></td></tr></table></figure></p><p><strong>OPTIONS说明：</strong></p><ul><li><p>-f :通过SIGKILL信号强制删除一个运行中的容器</p></li><li><p>-l :移除容器间的网络连接，而非容器本身</p></li><li><p>-v :-v 删除与容器关联的卷docker rm ：删除一个或多少容器</p></li></ul><p>语法<br>docker rm [OPTIONS] CONTAINER [CONTAINER…]<br>OPTIONS说明：</p><p>-f :通过SIGKILL信号强制删除一个运行中的容器</p><p>-l :移除容器间的网络连接，而非容器本身</p><p>-v :-v 删除与容器关联的卷<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">强制删除容器db01、db02</span><br><span class="line"></span><br><span class="line">docker rm -f db01 db02</span><br><span class="line">移除容器nginx01对容器db01的连接，连接名db</span><br><span class="line"></span><br><span class="line">docker rm -l db </span><br><span class="line">删除容器nginx01,并删除容器挂载的数据卷</span><br><span class="line"></span><br><span class="line">docker rm -v nginx01</span><br></pre></td></tr></table></figure></p><h4 id="pause-unpause"><a href="#pause-unpause" class="headerlink" title="pause/unpause"></a>pause/unpause</h4><h4 id="create"><a href="#create" class="headerlink" title="create"></a>create</h4><h4 id="exec"><a href="#exec" class="headerlink" title="exec"></a>exec</h4><p>docker exec ：在运行的容器中执行命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">在容器mynginx中以交互模式执行容器内/root/runoob.sh脚本</span><br><span class="line"></span><br><span class="line">runoob@runoob:~$ docker exec -it mynginx /bin/sh /root/runoob.sh</span><br><span class="line">http://www.runoob.com/</span><br><span class="line">在容器mynginx中开启一个交互模式的终端</span><br><span class="line"></span><br><span class="line">runoob@runoob:~$ docker exec -i -t  mynginx /bin/bash</span><br><span class="line">root@b1a0703e41e7:/#</span><br></pre></td></tr></table></figure></p><h3 id="commit-命令"><a href="#commit-命令" class="headerlink" title="commit 命令"></a>commit 命令</h3><p>docker commit :从容器创建一个新的镜像。</p><ul><li>-a :提交的镜像作者；</li><li>-c :使用Dockerfile指令来创建镜像；</li><li>-m :提交时的说明文字；</li><li>-p :在commit时，将容器暂停。</li></ul><p>将容器a404c6c174a2 保存为新的镜像,并添加提交人信息和说明信息。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">runoob@runoob:~$ docker commit -a &quot;runoob.com&quot; -m &quot;my apache&quot; a404c6c174a2  mymysql:v1 </span><br><span class="line">sha256:37af1236adef1544e8886be23010b66577647a40bc02c0885a6600b33ee28057</span><br><span class="line">runoob@runoob:~$ docker images mymysql:v1</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">mymysql             v1                  37af1236adef        15 seconds ago      329 MB</span><br></pre></td></tr></table></figure></p><h3 id="容器与本地之间拷贝文件"><a href="#容器与本地之间拷贝文件" class="headerlink" title="容器与本地之间拷贝文件"></a>容器与本地之间拷贝文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">将主机./RS-MapReduce目录拷贝到容器30026605dcfe的/home/cloudera目录下。</span><br><span class="line">docker cp RS-MapReduce 30026605dcfe:/home/cloudera</span><br><span class="line"></span><br><span class="line">将容器30026605dcfe的/home/cloudera/RS-MapReduce目录拷贝到主机的/tmp目录中。</span><br><span class="line">docker cp  30026605dcfe:/home/cloudera/RS-MapReduce /tmp/</span><br></pre></td></tr></table></figure><h2 id="5-学习资源"><a href="#5-学习资源" class="headerlink" title="5. 学习资源"></a>5. 学习资源</h2><ul><li><a href="http://www.runoob.com/docker/docker-tutorial.html" target="_blank" rel="noopener">runoob docker</a></li><li><a href="https://zhuanlan.zhihu.com/p/23599229" target="_blank" rel="noopener">只要一小时，零基础入门Docker</a></li></ul>]]></content>
    
    <summary type="html">
    
      Docker 安装与使用
    
    </summary>
    
    
      <category term="docker" scheme="https://www.starlg.cn/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Conda使用指南</title>
    <link href="https://www.starlg.cn/2018/09/09/Conda-Tutorials/"/>
    <id>https://www.starlg.cn/2018/09/09/Conda-Tutorials/</id>
    <published>2018-09-09T05:07:18.000Z</published>
    <updated>2018-09-09T05:57:42.588Z</updated>
    
    <content type="html"><![CDATA[<img src="/2018/09/09/Conda-Tutorials/anconda.png" title="Anconda"><p>Python渐渐成为最流行的编程语言之一，在数据分析、机器学习和深度学习等方向Python语言更是主流。Python的版本比较多，并且它的库也非常广泛，同时库和库之间存在很多依赖关系，所以在库的安装和版本的管理上很麻烦。Conda是一个管理版本和Python环境的工具，它使用起来非常容易。</p><p>首先你需要安装<a href="https://www.anaconda.com/" target="_blank" rel="noopener">Anconda</a>软件，点击链接<a href="https://www.anaconda.com/download/" target="_blank" rel="noopener">download</a>。选择对应的系统和版本类型。</p><h2 id="Conda的环境管理"><a href="#Conda的环境管理" class="headerlink" title="Conda的环境管理"></a>Conda的环境管理</h2><h3 id="创建环境"><a href="#创建环境" class="headerlink" title="创建环境"></a>创建环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个名为python34的环境，指定Python版本是3.5（不用管是3.5.x，conda会为我们自动寻找3.５.x中的最新版本）</span><br><span class="line">conda create --name py35 python=3.5</span><br></pre></td></tr></table></figure><h3 id="激活环境"><a href="#激活环境" class="headerlink" title="激活环境"></a>激活环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 安装好后，使用activate激活某个环境</span><br><span class="line">activate py35 # for Windows</span><br><span class="line">source activate py35 # for Linux &amp; Mac</span><br><span class="line">(py35) user@user-XPS-8920:~$</span><br><span class="line"> # 激活后，会发现terminal输入的地方多了py35的字样，实际上，此时系统做的事情就是把默认2.7环境从PATH中去除，再把3.4对应的命令加入PATH</span><br><span class="line"> </span><br><span class="line">(py35) user@user-XPS-8920:~$ python --version</span><br><span class="line">Python 3.5.5 :: Anaconda, Inc.</span><br><span class="line"># 可以得到`Python 3.5.5 :: Anaconda, Inc.`，即系统已经切换到了3.５的环境</span><br></pre></td></tr></table></figure><h3 id="返回主环境"><a href="#返回主环境" class="headerlink" title="返回主环境"></a>返回主环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 如果想返回默认的python 2.7环境，运行</span><br><span class="line">deactivate py35 # for Windows</span><br><span class="line">source deactivate py35 # for Linux &amp; Mac</span><br></pre></td></tr></table></figure><h3 id="删除环境"><a href="#删除环境" class="headerlink" title="删除环境"></a>删除环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 删除一个已有的环境</span><br><span class="line">conda remove --name py35 --all</span><br></pre></td></tr></table></figure><h3 id="查看系统中的所有环境"><a href="#查看系统中的所有环境" class="headerlink" title="查看系统中的所有环境"></a>查看系统中的所有环境</h3><p>用户安装的不同Python环境会放在<code>~/anaconda/envs</code>目录下。查看当前系统中已经安装了哪些环境，使用<code>conda info -e</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">user@user-XPS-8920:~$ conda info -e</span><br><span class="line"># conda environments:</span><br><span class="line">#</span><br><span class="line">base                  *  /home/user/anaconda2</span><br><span class="line">caffe                    /home/user/anaconda2/envs/caffe</span><br><span class="line">py35                    /home/user/anaconda2/envs/py35</span><br><span class="line">tf                       /home/user/anaconda2/envs/tf</span><br></pre></td></tr></table></figure><h2 id="Conda的包管理"><a href="#Conda的包管理" class="headerlink" title="Conda的包管理"></a>Conda的包管理</h2><h3 id="安装库"><a href="#安装库" class="headerlink" title="安装库"></a>安装库</h3><p>为当前环境安装库<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># numpy</span><br><span class="line">conda install numpy</span><br><span class="line"># conda会从从远程搜索numpy的相关信息和依赖项目</span><br></pre></td></tr></table></figure></p><p>###　查看已经安装的库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 查看已经安装的packages</span><br><span class="line">conda list</span><br><span class="line"># 最新版的conda是从site-packages文件夹中搜索已经安装的包，可以显示出通过各种方式安装的包</span><br></pre></td></tr></table></figure><h3 id="查看某个环境的已安装包"><a href="#查看某个环境的已安装包" class="headerlink" title="查看某个环境的已安装包"></a>查看某个环境的已安装包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查看某个指定环境的已安装包</span><br><span class="line">conda list -n py35</span><br></pre></td></tr></table></figure><h3 id="搜索package的信息"><a href="#搜索package的信息" class="headerlink" title="搜索package的信息"></a>搜索package的信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查找package信息</span><br><span class="line">conda search numpy</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Loading channels: done</span><br><span class="line"># Name                  Version           Build  Channel             </span><br><span class="line">numpy                     1.5.1          py26_1  pkgs/free           </span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">numpy                    1.15.1  py37hec00662_0  anaconda/pkgs/main  </span><br><span class="line">numpy                    1.15.1  py37hec00662_0  pkgs/main</span><br></pre></td></tr></table></figure><h3 id="安装package到指定的环境"><a href="#安装package到指定的环境" class="headerlink" title="安装package到指定的环境"></a>安装package到指定的环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 安装package</span><br><span class="line">conda install -n py35 numpy</span><br><span class="line"># 如果不用-n指定环境名称，则被安装在当前活跃环境</span><br><span class="line"># 也可以通过-c指定通过某个channel安装</span><br></pre></td></tr></table></figure><h3 id="更新package"><a href="#更新package" class="headerlink" title="更新package"></a>更新package</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 更新package</span><br><span class="line">conda update -n py35 numpy</span><br></pre></td></tr></table></figure><h3 id="删除package"><a href="#删除package" class="headerlink" title="删除package"></a>删除package</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 删除package</span><br><span class="line">conda remove -n py35 numpy</span><br></pre></td></tr></table></figure><h3 id="更新conda"><a href="#更新conda" class="headerlink" title="更新conda"></a>更新conda</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 更新conda，保持conda最新</span><br><span class="line">conda update conda</span><br></pre></td></tr></table></figure><h3 id="更新anaconda"><a href="#更新anaconda" class="headerlink" title="更新anaconda"></a>更新anaconda</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 更新anaconda</span><br><span class="line">conda update anaconda</span><br></pre></td></tr></table></figure><h3 id="更新Python"><a href="#更新Python" class="headerlink" title="更新Python"></a>更新Python</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 更新python</span><br><span class="line">conda update python</span><br><span class="line"># 假设当前环境是python 3.5, conda会将python升级为3.5.x系列的当前最新版本</span><br></pre></td></tr></table></figure><h2 id="设置国内镜像"><a href="#设置国内镜像" class="headerlink" title="设置国内镜像"></a>设置国内镜像</h2><p>因为Anaconda.org的服务器在国外，所有有些库下载缓慢，可以使用清华Anaconda镜像源。</p><p>网站地址: <a href="https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/" target="_blank" rel="noopener">清华大学开源软件镜像站</a></p><h3 id="Anaconda-镜像"><a href="#Anaconda-镜像" class="headerlink" title="Anaconda　镜像"></a>Anaconda　镜像</h3><p>Anaconda 安装包可以到 <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/</a> 下载。</p><p>TUNA还提供了Anaconda仓库的镜像，运行以下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></table></figure></p><p>即可添加 Anaconda Python 免费仓库。</p><p>运行 <code>conda install numpy</code> 测试一下吧。</p><h3 id="Miniconda-镜像"><a href="#Miniconda-镜像" class="headerlink" title="Miniconda　镜像"></a>Miniconda　镜像</h3><p>Miniconda 是一个 Anaconda 的轻量级替代，默认只包含了 python 和 conda，但是可以通过 pip 和 conda 来安装所需要的包。</p><p>Miniconda 安装包可以到 <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/</a> 下载。</p>]]></content>
    
    <summary type="html">
    
      Python环境管理工具
    
    </summary>
    
      <category term="Python" scheme="https://www.starlg.cn/categories/Python/"/>
    
    
  </entry>
  
  <entry>
    <title>[MLIA] Logistic Regression</title>
    <link href="https://www.starlg.cn/2018/09/05/MLIA-Logistic-Regression/"/>
    <id>https://www.starlg.cn/2018/09/05/MLIA-Logistic-Regression/</id>
    <published>2018-09-05T14:45:58.000Z</published>
    <updated>2018-09-06T02:42:43.010Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h1><p>本代码来自Machine Learning in Action。</p><p>想要了解更多的朋友可以参考此书。</p><h2 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h2><p>$$\sigma(z) = \frac{1}{(1+e^{-z})}$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(inX)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1</span>+np.exp(-inX))</span><br><span class="line"></span><br><span class="line">z = np.linspace(<span class="number">-5</span>, <span class="number">5</span>, <span class="number">100</span>)</span><br><span class="line">y = sigmoid(z)</span><br><span class="line">plt.plot(z, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_2_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">z = np.linspace(<span class="number">-60</span>, <span class="number">60</span>, <span class="number">100</span>)</span><br><span class="line">y = sigmoid(z)</span><br><span class="line">plt.plot(z, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_3_0.png" alt="png"></p><p>Sigmoid函数类似一个单位阶跃函数。当x＝0时，Sigmoid函数值为0.5；随着x增大，Sigmoid函数值将逼近于1；随着x减小，Sigmoid函数将逼近于0。利用这个性质可以对它的输入做一个二分类。</p><p>为了实现Logistic回归分类器，我们可以在每个特征上都乘以一个回归系数，然后把它的所有的结果值相加，将这个总和带入Sigmoid函数中，进而得到一个范围在0~1之间是数值。当大于0.5的时候，将数据分类为1；当小于0.5的时候，将数据分类为0。</p><p>Sigmoid函数的输入记为z:</p><p>$$z=w_0x_0 + w_1x_1 + w_2x_2 + \cdot \cdot \cdot + w_n x_n$$</p><h2 id="Sigmoid函数的导数"><a href="#Sigmoid函数的导数" class="headerlink" title="Sigmoid函数的导数"></a>Sigmoid函数的导数</h2><p>Sigmoid导数具体推导过程如下：</p><p>$$<br>\begin{align}<br>f^{\prime}(z) &amp;= (\frac{1}{1+e^{-z}})^{\prime}\\<br>&amp;=\frac{e^{-z}}{(1+e^{-z})^2}\\<br>&amp;=\frac{1+e^{-z}-1}{(1+e^{-z})^2}\\<br>&amp;=\frac{1}{(1+e^{-z})}(1-\frac{1}{(1+e^{-z})})\\<br>&amp;=f(z)(1-f(z))<br>\end{align}<br>$$</p><h2 id="梯度上升法"><a href="#梯度上升法" class="headerlink" title="梯度上升法"></a>梯度上升法</h2><p>梯度上升法：顾名思义就是利用梯度方向，寻找到某函数的最大值。</p><p>梯度上升算法迭代公式：<br>$$w:=w+\alpha \nabla_w f(w)$$</p><p>梯度下降法：和梯度上升想法，利用梯度方法，寻找某个函数的最小值。<br>梯度下降算法迭代公式：<br>$$w:=w-\alpha \nabla_w f(w)$$</p><p><img src="./Fig5_2.png" alt=""></p><p>梯度上升算法每次更新之后，都会重新估计移动的方法，即梯度。</p><h2 id="Logistic-回归梯度上升优化法"><a href="#Logistic-回归梯度上升优化法" class="headerlink" title="Logistic 回归梯度上升优化法"></a>Logistic 回归梯度上升优化法</h2><h3 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    dataMat = []; labelMat = []</span><br><span class="line">    fr = open(<span class="string">'testSet.txt'</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        lineArr = line.strip().split()</span><br><span class="line">        dataMat.append([<span class="number">1.0</span>, float(lineArr[<span class="number">0</span>]), float(lineArr[<span class="number">1</span>])])</span><br><span class="line">        labelMat.append(int(lineArr[<span class="number">2</span>]))</span><br><span class="line">    <span class="keyword">return</span> dataMat,labelMat</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dataArray, labelMat = loadDataSet()</span><br><span class="line">print(<span class="string">"Total: "</span>, len(dataArray))</span><br><span class="line">print(<span class="string">"The first sample: "</span>, dataArray[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">"The second sample: "</span>, dataArray[<span class="number">1</span>])</span><br><span class="line">print(<span class="string">"Label: "</span>, labelMat)</span><br></pre></td></tr></table></figure><pre><code>(&apos;Total: &apos;, 100)(&apos;The first sample: &apos;, [1.0, -0.017612, 14.053064])(&apos;The second sample: &apos;, [1.0, -1.395634, 4.662541])(&apos;Label: &apos;, [0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0])</code></pre><h3 id="数据集梯度上升"><a href="#数据集梯度上升" class="headerlink" title="数据集梯度上升"></a>数据集梯度上升</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(inX)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1</span>+np.exp(-inX))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradAscent</span><span class="params">(dataMatIn, classLabels)</span>:</span></span><br><span class="line">    dataMatrix = np.mat(dataMatIn)             <span class="comment">#convert to NumPy matrix</span></span><br><span class="line">    labelMat = np.mat(classLabels).transpose() <span class="comment">#convert to NumPy matrix</span></span><br><span class="line">    m,n = np.shape(dataMatrix)</span><br><span class="line">    alpha = <span class="number">0.001</span></span><br><span class="line">    maxCycles = <span class="number">500</span></span><br><span class="line">    weights = np.ones((n,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(maxCycles):              <span class="comment">#heavy on matrix operations</span></span><br><span class="line">        h = sigmoid(dataMatrix*weights)     <span class="comment">#matrix mult</span></span><br><span class="line">        error = (labelMat - h)              <span class="comment">#vector subtraction</span></span><br><span class="line">        weights = weights + alpha * dataMatrix.transpose()* error <span class="comment">#matrix mult</span></span><br><span class="line">    <span class="keyword">return</span> weights</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gradAscent(dataArray, labelMat)</span><br></pre></td></tr></table></figure><pre><code>matrix([[ 4.12414349],        [ 0.48007329],        [-0.6168482 ]])</code></pre><h3 id="绘制数据和决策边界"><a href="#绘制数据和决策边界" class="headerlink" title="绘制数据和决策边界"></a>绘制数据和决策边界</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotBestFit</span><span class="params">(weights)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    dataMat,labelMat=loadDataSet()</span><br><span class="line">    dataArr = np.array(dataMat)</span><br><span class="line">    n = np.shape(dataArr)[<span class="number">0</span>] </span><br><span class="line">    xcord1 = []; ycord1 = []</span><br><span class="line">    xcord2 = []; ycord2 = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">if</span> int(labelMat[i])== <span class="number">1</span>:</span><br><span class="line">            xcord1.append(dataArr[i,<span class="number">1</span>]); ycord1.append(dataArr[i,<span class="number">2</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            xcord2.append(dataArr[i,<span class="number">1</span>]); ycord2.append(dataArr[i,<span class="number">2</span>])</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    ax.scatter(xcord1, ycord1, s=<span class="number">30</span>, c=<span class="string">'red'</span>, marker=<span class="string">'s'</span>)</span><br><span class="line">    ax.scatter(xcord2, ycord2, s=<span class="number">30</span>, c=<span class="string">'green'</span>)</span><br><span class="line">    x = np.arange(<span class="number">-3.0</span>, <span class="number">3.0</span>, <span class="number">0.1</span>)</span><br><span class="line">    y = (-weights[<span class="number">0</span>]-weights[<span class="number">1</span>]*x)/weights[<span class="number">2</span>]</span><br><span class="line">    ax.plot(x, y)</span><br><span class="line">    plt.xlabel(<span class="string">'X1'</span>); plt.ylabel(<span class="string">'X2'</span>);</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">weights = gradAscent(dataArray, labelMat)</span><br><span class="line">plotBestFit(weights.getA())</span><br></pre></td></tr></table></figure><p><img src="output_17_0.png" alt="png"></p><h2 id="１个epoch的随机梯度上升"><a href="#１个epoch的随机梯度上升" class="headerlink" title="１个epoch的随机梯度上升"></a>１个epoch的随机梯度上升</h2><p>梯度上升算法在每次更新系数的时候都需要便利整个数据集，如果数据集的样本比较大，该方法的复杂度和计算代价就很高。有一种改进的方法叫做随机梯度上升方法。该方法的思想是选取一个样本，计算该样本的梯度，更新系数，再选取下一个样本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent0</span><span class="params">(dataMatrix, classLabels)</span>:</span></span><br><span class="line">    m,n = np.shape(dataMatrix)</span><br><span class="line">    alpha = <span class="number">0.01</span></span><br><span class="line">    weights = np.ones(n)   <span class="comment">#initialize to all ones</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        h = sigmoid(sum(dataMatrix[i]*weights))</span><br><span class="line">        error = classLabels[i] - h</span><br><span class="line">        weights = weights + alpha * error * dataMatrix[i]</span><br><span class="line">    <span class="keyword">return</span> weights</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">weights = stocGradAscent0(np.array(dataArray), labelMat)</span><br><span class="line">plotBestFit(weights)</span><br></pre></td></tr></table></figure><p><img src="output_20_0.png" alt="png"></p><p>上图之后遍历了一次数据集，这样的模型还处于欠拟合状态。需要多次遍历数据集才能优化好模型，接下来我们会运行200次迭代。</p><h2 id="200个epoch的随机梯度上升"><a href="#200个epoch的随机梯度上升" class="headerlink" title="200个epoch的随机梯度上升"></a>200个epoch的随机梯度上升</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent0</span><span class="params">(dataMatrix, classLabels)</span>:</span></span><br><span class="line">    X0, X1, X2 = [], [], []</span><br><span class="line">    m,n = np.shape(dataMatrix)</span><br><span class="line">    alpha = <span class="number">0.01</span></span><br><span class="line">    weights = np.ones(n)   <span class="comment">#initialize to all ones</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">200</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            h = sigmoid(sum(dataMatrix[i]*weights))</span><br><span class="line">            error = classLabels[i] - h</span><br><span class="line">            weights = weights + alpha * error * dataMatrix[i]</span><br><span class="line">            X0.append(weights[<span class="number">0</span>])</span><br><span class="line">            X1.append(weights[<span class="number">1</span>])</span><br><span class="line">            X2.append(weights[<span class="number">2</span>])</span><br><span class="line">    <span class="keyword">return</span> weights, X0, X1, X2</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">weights, X0, X1, X2 = stocGradAscent0(np.array(dataArray), labelMat)</span><br><span class="line">plotBestFit(weights)</span><br></pre></td></tr></table></figure><p><img src="output_24_0.png" alt="png"></p><h3 id="可视化权重-weights-的变化"><a href="#可视化权重-weights-的变化" class="headerlink" title="可视化权重(weights)的变化"></a>可视化权重(weights)的变化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(<span class="number">3</span>, <span class="number">1</span>, figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">ax[<span class="number">0</span>].plot(np.arange(len(X0)), np.array(X0))</span><br><span class="line">ax[<span class="number">1</span>].plot(np.arange(len(X1)), np.array(X1))</span><br><span class="line">ax[<span class="number">2</span>].plot(np.arange(len(X2)), np.array(X2))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_26_0.png" alt="png"></p><p>从上图可以看出，算法正在逐渐收敛。由于数据集并不是线性可分的，所以存在一些不能正确分类的样本点，每次更新权重引起了周期的变化。</p><h2 id="更新过后的随机梯度上升算法"><a href="#更新过后的随机梯度上升算法" class="headerlink" title="更新过后的随机梯度上升算法"></a>更新过后的随机梯度上升算法</h2><ol><li>学习率alpha会在每次迭代之后调整。</li><li>采用随机选取样本的更新策略，减少周期性的波动。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent1</span><span class="params">(dataMatrix, classLabels, numIter=<span class="number">150</span>)</span>:</span></span><br><span class="line">    X0, X1, X2 = [], [], []</span><br><span class="line">    m,n = np.shape(dataMatrix)</span><br><span class="line">    weights = np.ones(n)   <span class="comment">#initialize to all ones</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(numIter):</span><br><span class="line">        dataIndex = range(m)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            alpha = <span class="number">4</span>/(<span class="number">1.0</span>+j+i)+<span class="number">0.0001</span>    <span class="comment">#apha decreases with iteration, does not </span></span><br><span class="line">            randIndex = int(np.random.uniform(<span class="number">0</span>,len(dataIndex)))<span class="comment">#go to 0 because of the constant</span></span><br><span class="line">            h = sigmoid(sum(dataMatrix[randIndex]*weights))</span><br><span class="line">            error = classLabels[randIndex] - h</span><br><span class="line">            weights = weights + alpha * error * dataMatrix[randIndex]</span><br><span class="line">            X0.append(weights[<span class="number">0</span>])</span><br><span class="line">            X1.append(weights[<span class="number">1</span>])</span><br><span class="line">            X2.append(weights[<span class="number">2</span>])</span><br><span class="line">            <span class="keyword">del</span>(dataIndex[randIndex])</span><br><span class="line">    <span class="keyword">return</span> weights, X0, X1, X2</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">weights, X0, X1, X2 = stocGradAscent1(np.array(dataArray), labelMat)</span><br><span class="line">plotBestFit(weights)</span><br></pre></td></tr></table></figure><p><img src="output_30_0.png" alt="png"></p><h3 id="可视化权重-weights-的变化-1"><a href="#可视化权重-weights-的变化-1" class="headerlink" title="可视化权重(weights)的变化"></a>可视化权重(weights)的变化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(<span class="number">3</span>, <span class="number">1</span>, figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">ax[<span class="number">0</span>].plot(np.arange(len(X0)), np.array(X0))</span><br><span class="line">ax[<span class="number">1</span>].plot(np.arange(len(X1)), np.array(X1))</span><br><span class="line">ax[<span class="number">2</span>].plot(np.arange(len(X2)), np.array(X2))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_32_0.png" alt="png"></p><h1 id="示例：从疝气病症预测病马的死亡率"><a href="#示例：从疝气病症预测病马的死亡率" class="headerlink" title="示例：从疝气病症预测病马的死亡率"></a>示例：从疝气病症预测病马的死亡率</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyVector</span><span class="params">(inX, weights)</span>:</span></span><br><span class="line">    prob = sigmoid(sum(inX*weights))</span><br><span class="line">    <span class="keyword">if</span> prob &gt; <span class="number">0.5</span>: <span class="keyword">return</span> <span class="number">1.0</span></span><br><span class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">colicTest</span><span class="params">()</span>:</span></span><br><span class="line">    frTrain = open(<span class="string">'horseColicTraining.txt'</span>, <span class="string">'r'</span>); frTest = open(<span class="string">'horseColicTest.txt'</span>, <span class="string">'r'</span>)</span><br><span class="line">    trainingSet = []; trainingLabels = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> frTrain.readlines():</span><br><span class="line">        currLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        lineArr =[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">21</span>):</span><br><span class="line">            lineArr.append(float(currLine[i]))</span><br><span class="line">        trainingSet.append(lineArr)</span><br><span class="line">        trainingLabels.append(float(currLine[<span class="number">21</span>]))</span><br><span class="line">    trainWeights, X0, X1, X2 = stocGradAscent1(np.array(trainingSet), trainingLabels, <span class="number">1000</span>)</span><br><span class="line">    errorCount = <span class="number">0</span>; numTestVec = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> frTest.readlines():</span><br><span class="line">        numTestVec += <span class="number">1.0</span></span><br><span class="line">        currLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        lineArr =[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">21</span>):</span><br><span class="line">            lineArr.append(float(currLine[i]))</span><br><span class="line">        <span class="keyword">if</span> int(classifyVector(np.array(lineArr), trainWeights))!= int(currLine[<span class="number">21</span>]):</span><br><span class="line">            errorCount += <span class="number">1</span></span><br><span class="line">    errorRate = (float(errorCount)/numTestVec)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"the error rate of this test is: %f"</span> % errorRate</span><br><span class="line">    <span class="keyword">return</span> errorRate</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiTest</span><span class="params">()</span>:</span></span><br><span class="line">    numTests = <span class="number">10</span>; errorSum=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(numTests):</span><br><span class="line">        errorSum += colicTest()</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"after %d iterations the average error rate is: %f"</span> % (numTests, errorSum/float(numTests))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">multiTest()</span><br></pre></td></tr></table></figure><pre><code>/home/tianliang/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in expthe error rate of this test is: 0.328358the error rate of this test is: 0.432836the error rate of this test is: 0.388060the error rate of this test is: 0.373134the error rate of this test is: 0.373134the error rate of this test is: 0.447761the error rate of this test is: 0.343284the error rate of this test is: 0.313433the error rate of this test is: 0.328358the error rate of this test is: 0.462687after 10 iterations the average error rate is: 0.379104</code></pre>]]></content>
    
    <summary type="html">
    
      Logistic Regression And Code
    
    </summary>
    
      <category term="Machine Learning" scheme="https://www.starlg.cn/categories/Machine-Learning/"/>
    
    
  </entry>
  
  <entry>
    <title>CornerNet: Detection Objects as Paired Keypoints</title>
    <link href="https://www.starlg.cn/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/"/>
    <id>https://www.starlg.cn/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/</id>
    <published>2018-09-02T14:08:13.000Z</published>
    <updated>2018-09-02T14:35:34.600Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>CornerNet: Detection Objects as Paired Keypoints　这篇论文发表在ECCV2018，本人感觉非常有意思，所以和大家分享一下。</p><p>Arxiv: <a href="https://arxiv.org/abs/1808.01244" target="_blank" rel="noopener">https://arxiv.org/abs/1808.01244</a><br>Github: <a href="https://github.com/umich-vl/" target="_blank" rel="noopener">https://github.com/umich-vl/</a></p><hr><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>传统的目标检测都是给出紧致的候选框，本论文独具匠心，通过一对关键点（目标的左上角和右下角）来检测一个目标框。通过检测关键点的这种方式，可以消除利用先验知识设计anchor boxes这个需求。作者提出角点池化（corner pooling），角点池化可以帮助网络更好的定位角点。最终实验表明，CornerNet在MS COCO数据集上实现了42.1%的AP，优于所有现存的单级(one-stage)检测器。</p><a id="more"></a><hr><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig1.png" title="We detect an object as a pair of bounding box corners grouped together."><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig2.png" title="Often there is no local evidence to determine the location of a bounding box corner. We address this issue by proposing a new type of pooling layer."><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig3.png" title="Corner pooling: for each channel, we take the maximum values (red dots) in two directions (red lines), each from a separate feature map, and add the two maximums together (blue dot)."><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig4.png" title="Overview of CornerNet. The backbone network is followed by two prediction modules, one for the top-left corners and the other for the bottom-right corners. Using the predictions from both modules, we locate and group the corners."><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig5.png" title="“Ground-truth” heatmaps for training."><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig6.png" title="The top-left corner pooling layer can be implemented very efficiently. We scan from left to right for the horizontal max-pooling and from bottom to top for the vertical max-pooling. We then add two max-pooled feature maps."><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig7.png" title="The prediction module starts with a modified residual block, in which we replace the first convolution module with our corner pooling module. The modified residual block is then followed by a convolution module. We have multiple branches for predict- ing the heatmaps, embeddings and offsets"><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig8.png" title="Example bounding box predictions overlaid on predicted heatmaps of corners.">]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;CornerNet: Detection Objects as Paired Keypoints　这篇论文发表在ECCV2018，本人感觉非常有意思，所以和大家分享一下。&lt;/p&gt;
&lt;p&gt;Arxiv: &lt;a href=&quot;https://arxiv.org/abs/1808.01244&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://arxiv.org/abs/1808.01244&lt;/a&gt;&lt;br&gt;Github: &lt;a href=&quot;https://github.com/umich-vl/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/umich-vl/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h3&gt;&lt;p&gt;传统的目标检测都是给出紧致的候选框，本论文独具匠心，通过一对关键点（目标的左上角和右下角）来检测一个目标框。通过检测关键点的这种方式，可以消除利用先验知识设计anchor boxes这个需求。作者提出角点池化（corner pooling），角点池化可以帮助网络更好的定位角点。最终实验表明，CornerNet在MS COCO数据集上实现了42.1%的AP，优于所有现存的单级(one-stage)检测器。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Object Detection" scheme="https://www.starlg.cn/tags/Object-Detection/"/>
    
  </entry>
  
  <entry>
    <title>行人检测（Pedestrian Detection）论文整理</title>
    <link href="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/"/>
    <id>https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/</id>
    <published>2018-08-17T03:26:22.000Z</published>
    <updated>2019-07-16T07:40:09.160Z</updated>
    
    <content type="html"><![CDATA[<h2 id="同步github地址"><a href="#同步github地址" class="headerlink" title="同步github地址"></a>同步github地址</h2><p>本文档同步至github:<a href="https://github.com/xingkongliang/Pedestrian-Detection" target="_blank" rel="noopener">here</a></p><h2 id="相关科研工作者"><a href="#相关科研工作者" class="headerlink" title="相关科研工作者"></a>相关科研工作者</h2><ul><li><a href="https://scholar.google.com/citations?user=a8Y2OJMAAAAJ&amp;hl=zh-CN" target="_blank" rel="noopener">Piotr Dollár scholar</a></li><li><a href="https://pdollar.github.io/" target="_blank" rel="noopener">Piotr Dollár homepage</a></li><li><a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=pOSMWfQAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target="_blank" rel="noopener">张姗姗 scholar</a></li><li><a href="https://sites.google.com/site/shanshanzhangshomepage/" target="_blank" rel="noopener">张姗姗 homepage</a></li><li><a href="https://scholar.google.com/citations?user=pw_0Z_UAAAAJ&amp;%20hl=en" target="_blank" rel="noopener">欧阳万里 scholar</a></li><li><a href="http://www.ee.cuhk.edu.hk/~wlouyang/" target="_blank" rel="noopener">欧阳万里 homepage</a></li></ul><h2 id="开放的代码"><a href="#开放的代码" class="headerlink" title="开放的代码"></a>开放的代码</h2><ul><li><a href="https://github.com/liuwei16/CSP" target="_blank" rel="noopener"><strong>liuwei16/CSP</strong></a></li></ul><p>[CVPR-2019] High-level Semantic Feature Detection:A New Perspective for Pedestrian Detection [<a href="https://arxiv.org/abs/1904.02948" target="_blank" rel="noopener">paper</a>]</p><ul><li><a href="https://github.com/liuwei16/ALFNet" target="_blank" rel="noopener"><strong>liuwei16/ALFNet</strong></a></li></ul><p>[ECCV-2018] Learning Efficient Single-stage Pedestrian Detectors by Asymptotic Localization Fitting</p><ul><li><a href="https://github.com/rainofmine/Bi-box_Regression" target="_blank" rel="noopener"><strong>rainofmine/Bi-box_Regression 非官方实现</strong></a></li></ul><p>[ECCV-2018] Bi-box Regression for Pedestrian Detection and Occlusion Estimation</p><ul><li><a href="https://github.com/rainofmine/Repulsion_Loss" target="_blank" rel="noopener"><strong>rainofmine/Repulsion_Loss 非官方实现</strong></a></li></ul><p>[CVPR-2018] Repulsion Loss: Detecting Pedestrians in a Crowd</p><ul><li><a href="https://github.com/garrickbrazil/SDS-RCNN" target="_blank" rel="noopener"><strong>garrickbrazil/SDS-RCNN</strong></a></li></ul><p>[ICCV-2017] Illuminating Pedestrians via Simultaneous Detection &amp; Segmentation</p><ul><li><a href="https://github.com/zhangliliang/RPN_BF" target="_blank" rel="noopener"><strong>zhangliliang/RPN_BF</strong></a></li></ul><p>[ECCV-2016] Is Faster R-CNN Doing Well for Pedestrian Detection?</p><h2 id="Paper-List"><a href="#Paper-List" class="headerlink" title="Paper List"></a>Paper List</h2><ul><li>[CVPR-2019 oral] Adaptive NMS: Refining Pedestrian Detection in a Crowd [<a href="https://arxiv.org/abs/1904.02948" target="_blank" rel="noopener">paper</a>]</li><li>[CVPR-2019] High-level Semantic Feature Detection:A New Perspective for Pedestrian Detection [<a href="https://arxiv.org/abs/1904.02948" target="_blank" rel="noopener">paper</a>] [<a href="https://github.com/liuwei16/CSP" target="_blank" rel="noopener"><strong>code</strong></a>]</li><li>[CVPR-2019] SSA-CNN: Semantic Self-Attention CNN for Pedestrian Detection</li><li>[CVPR-2019] Pedestrian Detection in Thermal Images using Saliency Maps</li><li>[TIP-2018] Too Far to See? Not Really:- Pedestrian Detection with Scale-Aware Localization Policy</li><li>[ECCV-2018] Bi-box Regression for Pedestrian Detection and Occlusion Estimation [<a href="https://github.com/rainofmine/Bi-box_Regression" target="_blank" rel="noopener"><strong>code</strong></a>]</li><li>[ECCV-2018] Learning Efficient Single-stage Pedestrian Detectors by Asymptotic Localization Fitting [<a href="https://github.com/liuwei16/ALFNet" target="_blank" rel="noopener"><strong>code</strong></a>]</li><li>[ECCV-2018] Graininess-Aware Deep Feature Learning for Pedestrian Detection</li><li>[ECCV-2018] Occlusion-aware R-CNN: Detecting Pedestrians in a Crowd</li><li>[ECCV-2018] Small-scale Pedestrian Detection Based on Somatic Topology Localization and Temporal Feature Aggregation</li><li>[CVPR-2018] Improving Occlusion and Hard Negative Handling for Single-Stage Pedestrian Detectors</li><li>[CVPR-2018] Occluded Pedestrian Detection Through Guided Attention in CNNs</li><li>[CVPR-2018] Repulsion Loss: Detecting Pedestrians in a Crowd [<a href="https://github.com/rainofmine/Repulsion_Loss" target="_blank" rel="noopener"><strong>code</strong></a>]</li><li>[TCSVT-2018] Pushing the Limits of Deep CNNs for Pedestrian Detection</li><li>[Trans Multimedia-2018] Scale-aware Fast R-CNN for Pedestrian Detection</li><li>[TPAMI-2017] Jointly Learning Deep Features, Deformable Parts, Occlusion and Classification for Pedestrian Detection</li><li>[BMVC-2017] PCN: Part and Context Information for Pedestrian Detection with CNNs</li><li>[CVPR-2017] CityPersons: A Diverse Dataset for Pedestrian Detection</li><li>[CVPR-2017] Learning Cross-Modal Deep Representations for Robust Pedestrian Detection</li><li>[CVPR-2017] What Can Help Pedestrian Detection?</li><li>[ICCV-2017] Multi-label Learning of Part Detectors for Heavily Occluded Pedestrian Detection</li><li>[ICCV-2017] Illuminating Pedestrians via Simultaneous Detection &amp; Segmentation [<a href="https://github.com/garrickbrazil/SDS-RCNN" target="_blank" rel="noopener"><strong>code</strong></a>]</li><li>[TPAMI-2017] Towards Reaching Human Performance in Pedestrian Detection</li><li>[Transactions on Multimedia-2017] Scale-Aware Fast R-CNN for Pedestrian Detection</li><li>[CVPR-2016] Semantic Channels for Fast Pedestrian Detection</li><li>[CVPR-2016] How Far are We from Solving Pedestrian Detection?</li><li>![CVPR-2016] Pedestrian Detection Inspired by Appearance Constancy and Shape Symmetry</li><li>![CVPR-2016] Semantic Channels for Fast Pedestrian Detection</li><li>![ECCV-2016] Is Faster R-CNN Doing Well for Pedestrian Detection? [<a href="https://github.com/zhangliliang/RPN_BF" target="_blank" rel="noopener"><strong>code</strong></a>]</li><li>[CVPR-2015] Taking a Deeper Look at Pedestrians</li><li>![ICCV-2015] Learning Complexity-Aware Cascades for Deep Pedestrian Detection</li><li>[ICCV-2015] Deep Learning Strong Parts for Pedestrian Detection</li><li>![ECCV-2014] Deep Learning of Scene-specific Classifier for Pedestrian Detection</li><li>[CVPR-2013] Joint Deep Learning for Pedestrian Detection</li><li>[CVPR-2012] A Discriminative Deep Model for Pedestrian Detection with Occlusion Handling</li><li>[CVPR-2010] Multi-Cue Pedestrian Classification With Partial Occlusion Handling</li><li>[CVPR-2009] Pedestrian detection: A benchmark</li><li>[CVPR-2008] People-Tracking-by-Detection and People-Detection-by-Tracking</li><li>[ECCV-2006] Human Detection Using Oriented Histograms of Flow and Appearance</li><li>[CVPR-2005] Histograms of Oriented Gradients for Human Detection</li></ul><h2 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h2><h3 id="CVPR-2019-oral-Adaptive-NMS-Refining-Pedestrian-Detection-in-a-Crowd"><a href="#CVPR-2019-oral-Adaptive-NMS-Refining-Pedestrian-Detection-in-a-Crowd" class="headerlink" title="[CVPR-2019 oral] Adaptive NMS: Refining Pedestrian Detection in a Crowd"></a>[CVPR-2019 oral] Adaptive NMS: Refining Pedestrian Detection in a Crowd</h3><p><img src="./CVPR19_CSP_Adaptive_NMS.png" alt="CVPR19_CSP_Adaptive_NMS"></p><ul><li>paper: <a href="https://arxiv.org/abs/1904.02948" target="_blank" rel="noopener">https://arxiv.org/abs/1904.02948</a></li></ul><h3 id="CVPR-2019-High-level-Semantic-Feature-Detection-A-New-Perspective-for-Pedestrian-Detection"><a href="#CVPR-2019-High-level-Semantic-Feature-Detection-A-New-Perspective-for-Pedestrian-Detection" class="headerlink" title="[CVPR-2019] High-level Semantic Feature Detection:A New Perspective for Pedestrian Detection"></a>[CVPR-2019] High-level Semantic Feature Detection:A New Perspective for Pedestrian Detection</h3><p><img src="./CVPR19_CSP_PedestrianDetection.png" alt="Alt text"></p><ul><li>paper: <a href="https://arxiv.org/abs/1904.02948" target="_blank" rel="noopener">https://arxiv.org/abs/1904.02948</a></li><li>github: <a href="https://github.com/liuwei16/CSP" target="_blank" rel="noopener">https://github.com/liuwei16/CSP</a></li></ul><h3 id="CVPR-2019-SSA-CNN-Semantic-Self-Attention-CNN-for-Pedestrian-Detection"><a href="#CVPR-2019-SSA-CNN-Semantic-Self-Attention-CNN-for-Pedestrian-Detection" class="headerlink" title="[CVPR-2019] SSA-CNN: Semantic Self-Attention CNN for Pedestrian Detection"></a>[CVPR-2019] SSA-CNN: Semantic Self-Attention CNN for Pedestrian Detection</h3><p><img src="./CVPR19_SSA-CNN.png" alt="Alt text"></p><ul><li>paper: <a href="https://arxiv.org/abs/1902.09080v1" target="_blank" rel="noopener">https://arxiv.org/abs/1902.09080v1</a></li></ul><h3 id="CVPR-2019-Pedestrian-Detection-in-Thermal-Images-using-Saliency-Maps"><a href="#CVPR-2019-Pedestrian-Detection-in-Thermal-Images-using-Saliency-Maps" class="headerlink" title="[CVPR-2019] Pedestrian Detection in Thermal Images using Saliency Maps"></a>[CVPR-2019] Pedestrian Detection in Thermal Images using Saliency Maps</h3><ul><li>paper: <a href="https://arxiv.org/abs/1904.06859" target="_blank" rel="noopener">https://arxiv.org/abs/1904.06859</a></li></ul><h3 id="TIP-2018-Too-Far-to-See-Not-Really-Pedestrian-Detection-with-Scale-Aware-Localization-Policy"><a href="#TIP-2018-Too-Far-to-See-Not-Really-Pedestrian-Detection-with-Scale-Aware-Localization-Policy" class="headerlink" title="[TIP-2018] Too Far to See? Not Really: Pedestrian Detection with Scale-Aware Localization Policy"></a>[TIP-2018] Too Far to See? Not Really: Pedestrian Detection with Scale-Aware Localization Policy</h3><p><img src="./1533980426553.png" alt="Alt text| left | 300x0"></p><ul><li>paper:</li><li>project website:</li><li>slides:</li><li>github:</li></ul><h3 id="Transactions-on-Multimedia-201８-Scale-Aware-Fast-R-CNN-for-Pedestrian-Detection"><a href="#Transactions-on-Multimedia-201８-Scale-Aware-Fast-R-CNN-for-Pedestrian-Detection" class="headerlink" title="[Transactions on Multimedia-201８] Scale-Aware Fast R-CNN for Pedestrian Detection"></a>[Transactions on Multimedia-201８] Scale-Aware Fast R-CNN for Pedestrian Detection</h3><p><img src="./1533980383783.png" alt="Alt text| left | 300x0"></p><ul><li>paper: <a href="https://ieeexplore.ieee.org/abstract/document/8060595/" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/8060595/</a></li><li>project website:</li><li>slides:</li><li>github:</li></ul><h3 id="ECCV-2018-Bi-box-Regression-for-Pedestrian-Detection-and-Occlusion-Estimation"><a href="#ECCV-2018-Bi-box-Regression-for-Pedestrian-Detection-and-Occlusion-Estimation" class="headerlink" title="[ECCV-2018] Bi-box Regression for Pedestrian Detection and Occlusion Estimation"></a>[ECCV-2018] Bi-box Regression for Pedestrian Detection and Occlusion Estimation</h3><p><img src="./ECCV2018-Bi-box_Regression_2.png" alt="Alt text| left | 300x0"><br><img src="./ECCV2018-Bi-box_Regression.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:</li><li>paper:<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/CHUNLUAN_ZHOU_Bi-box_Regression_for_ECCV_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ECCV_2018/papers/CHUNLUAN_ZHOU_Bi-box_Regression_for_ECCV_2018_paper.pdf</a></li><li>slides:</li><li>github: <a href="https://github.com/rainofmine/Bi-box_Regression" target="_blank" rel="noopener">https://github.com/rainofmine/Bi-box_Regression</a></li></ul><h3 id="ECCV-2018-Learning-Efficient-Single-stage-Pedestrian-Detectors-by-Asymptotic-Localization-Fitting"><a href="#ECCV-2018-Learning-Efficient-Single-stage-Pedestrian-Detectors-by-Asymptotic-Localization-Fitting" class="headerlink" title="[ECCV-2018] Learning Efficient Single-stage Pedestrian Detectors by Asymptotic Localization Fitting"></a>[ECCV-2018] Learning Efficient Single-stage Pedestrian Detectors by Asymptotic Localization Fitting</h3><p><img src="./ECCV2-18-Learning_Efficien_Single-stage_Pedestrian_Detectors.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:</li><li>paper:<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Wei_Liu_Learning_Efficient_Single-stage_ECCV_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ECCV_2018/papers/Wei_Liu_Learning_Efficient_Single-stage_ECCV_2018_paper.pdf</a></li><li>project website:</li><li>slides:</li><li>github: <a href="https://github.com/liuwei16/ALFNet" target="_blank" rel="noopener">https://github.com/liuwei16/ALFNet</a></li></ul><h3 id="ECCV-2018-Graininess-Aware-Deep-Feature-Learning-for-Pedestrian-Detection"><a href="#ECCV-2018-Graininess-Aware-Deep-Feature-Learning-for-Pedestrian-Detection" class="headerlink" title="[ECCV-2018] Graininess-Aware Deep Feature Learning for Pedestrian Detection"></a>[ECCV-2018] Graininess-Aware Deep Feature Learning for Pedestrian Detection</h3><p><img src="./ECCV2018-Graininess-Aware_Deep_Learning.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:</li><li>paper:<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Chunze_Lin_Graininess-Aware_Deep_Feature_ECCV_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ECCV_2018/papers/Chunze_Lin_Graininess-Aware_Deep_Feature_ECCV_2018_paper.pdf</a></li><li>project website:</li><li>slides:</li><li>github:</li></ul><h3 id="ECCV-2018-Occlusion-aware-R-CNN-Detecting-Pedestrians-in-a-Crowd"><a href="#ECCV-2018-Occlusion-aware-R-CNN-Detecting-Pedestrians-in-a-Crowd" class="headerlink" title="[ECCV-2018] Occlusion-aware R-CNN: Detecting Pedestrians in a Crowd"></a>[ECCV-2018] Occlusion-aware R-CNN: Detecting Pedestrians in a Crowd</h3><p><img src="./ECCV2018-Occlusion-aware_R-CNN.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:<a href="http://arxiv.org/abs/1807.08407" target="_blank" rel="noopener">http://arxiv.org/abs/1807.08407</a></li><li>project website:</li><li>slides:</li><li>github:</li></ul><h3 id="ECCV-2018-Small-scale-Pedestrian-Detection-Based-on-Somatic-Topology-Localization-and-Temporal-Feature-Aggregation"><a href="#ECCV-2018-Small-scale-Pedestrian-Detection-Based-on-Somatic-Topology-Localization-and-Temporal-Feature-Aggregation" class="headerlink" title="[ECCV-2018] Small-scale Pedestrian Detection Based on Somatic Topology Localization and Temporal Feature Aggregation"></a>[ECCV-2018] Small-scale Pedestrian Detection Based on Somatic Topology Localization and Temporal Feature Aggregation</h3><p><img src="./1533979932529.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:<a href="https://arxiv.org/abs/1807.01438" target="_blank" rel="noopener">https://arxiv.org/abs/1807.01438</a></li><li>project website:</li><li>slides:</li><li>github:</li></ul><h3 id="CVPR-2018-Improving-Occlusion-and-Hard-Negative-Handling-for-Single-Stage-Pedestrian-Detectors"><a href="#CVPR-2018-Improving-Occlusion-and-Hard-Negative-Handling-for-Single-Stage-Pedestrian-Detectors" class="headerlink" title="[CVPR-2018] Improving Occlusion and Hard Negative Handling for Single-Stage Pedestrian Detectors"></a>[CVPR-2018] Improving Occlusion and Hard Negative Handling for Single-Stage Pedestrian Detectors</h3><p><img src="./1533980803719.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:</li><li>paper: <a href="http://vision.snu.ac.kr/projects/partgridnet/data/noh_2018.pdf" target="_blank" rel="noopener">http://vision.snu.ac.kr/projects/partgridnet/data/noh_2018.pdf</a></li><li>project website: <a href="http://vision.snu.ac.kr/projects/partgridnet/" target="_blank" rel="noopener">http://vision.snu.ac.kr/projects/partgridnet/</a></li><li>slides:</li><li>github:</li></ul><h3 id="CVPR-2018-Occluded-Pedestrian-Detection-Through-Guided-Attention-in-CNNs"><a href="#CVPR-2018-Occluded-Pedestrian-Detection-Through-Guided-Attention-in-CNNs" class="headerlink" title="[CVPR-2018] Occluded Pedestrian Detection Through Guided Attention in CNNs"></a>[CVPR-2018] Occluded Pedestrian Detection Through Guided Attention in CNNs</h3><p><img src="./1533980145178.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:</li><li>paper: <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Occluded_Pedestrian_Detection_CVPR_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Occluded_Pedestrian_Detection_CVPR_2018_paper.pdf</a></li><li>project website:</li><li>slides:</li><li>github:</li></ul><h3 id="CVPR-2018-Repulsion-Loss-Detecting-Pedestrians-in-a-Crowd"><a href="#CVPR-2018-Repulsion-Loss-Detecting-Pedestrians-in-a-Crowd" class="headerlink" title="[CVPR-2018] Repulsion Loss: Detecting Pedestrians in a Crowd"></a>[CVPR-2018] Repulsion Loss: Detecting Pedestrians in a Crowd</h3><p><img src="./1528195001788.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:<a href="http://arxiv.org/abs/1711.07752" target="_blank" rel="noopener">http://arxiv.org/abs/1711.07752</a></li><li>project website:</li><li>slides:</li><li>github:</li><li>blog: <a href="https://zhuanlan.zhihu.com/p/41288115" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/41288115</a></li></ul><h3 id="TPAMI-2017-Jointly-Learning-Deep-Features-Deformable-Parts-Occlusion-and-Classification-for-Pedestrian-Detection"><a href="#TPAMI-2017-Jointly-Learning-Deep-Features-Deformable-Parts-Occlusion-and-Classification-for-Pedestrian-Detection" class="headerlink" title="[TPAMI-2017] Jointly Learning Deep Features, Deformable Parts, Occlusion and Classification for Pedestrian Detection"></a>[TPAMI-2017] Jointly Learning Deep Features, Deformable Parts, Occlusion and Classification for Pedestrian Detection</h3><p><img src="./1537261066815.png" alt="Alt text| left | 300x0"></p><ul><li>paper: <a href="https://ieeexplore.ieee.org/abstract/document/8008790/" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/8008790/</a></li><li>project website:</li><li>slides:</li><li>github caffe:</li></ul><h3 id="BMVC-2017-PCN-Part-and-Context-Information-for-Pedestrian-Detection-with-CNNs"><a href="#BMVC-2017-PCN-Part-and-Context-Information-for-Pedestrian-Detection-with-CNNs" class="headerlink" title="[BMVC-2017] PCN: Part and Context Information for Pedestrian Detection with CNNs"></a>[BMVC-2017] PCN: Part and Context Information for Pedestrian Detection with CNNs</h3><p><img src="./1533980559400.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1804.044838" target="_blank" rel="noopener">https://arxiv.org/abs/1804.044838</a></li><li>project website:</li><li>slides:</li><li>github caffe:</li></ul><h3 id="CVPR-2017-CityPersons-A-Diverse-Dataset-for-Pedestrian-Detection"><a href="#CVPR-2017-CityPersons-A-Diverse-Dataset-for-Pedestrian-Detection" class="headerlink" title="[CVPR-2017] CityPersons: A Diverse Dataset for Pedestrian Detection"></a>[CVPR-2017] CityPersons: A Diverse Dataset for Pedestrian Detection</h3><p><img src="./1528194369562.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1702.05693" target="_blank" rel="noopener">http://arxiv.org/abs/1702.05693</a></li><li>project website:</li><li>slides:</li><li>github caffe:</li></ul><hr><h3 id="CVPR-2017-Learning-Cross-Modal-Deep-Representations-for-Robust-Pedestrian-Detection"><a href="#CVPR-2017-Learning-Cross-Modal-Deep-Representations-for-Robust-Pedestrian-Detection" class="headerlink" title="[CVPR-2017] Learning Cross-Modal Deep Representations for Robust Pedestrian Detection"></a>[CVPR-2017] Learning Cross-Modal Deep Representations for Robust Pedestrian Detection</h3><p><img src="./1528194560698.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1704.02431" target="_blank" rel="noopener">https://arxiv.org/abs/1704.02431</a></li><li>project website:</li><li>slides:</li><li>github caffe:</li></ul><p><img src="./1528194591022.png" alt="Alt text"><br><img src="./1528194606094.png" alt="Alt text"></p><h3 id="CVPR-2017-What-Can-Help-Pedestrian-Detection"><a href="#CVPR-2017-What-Can-Help-Pedestrian-Detection" class="headerlink" title="[CVPR-2017] What Can Help Pedestrian Detection?"></a>[CVPR-2017] What Can Help Pedestrian Detection?</h3><ul><li>arxiv: <a href="https://arxiv.org/abs/1704.02431" target="_blank" rel="noopener">https://arxiv.org/abs/1704.02431</a></li><li>project website:</li><li>slides:</li><li>github caffe:</li></ul><h3 id="TPAMI-2017-Towards-Reaching-Human-Performance-in-Pedestrian-Detection"><a href="#TPAMI-2017-Towards-Reaching-Human-Performance-in-Pedestrian-Detection" class="headerlink" title="[TPAMI-2017] Towards Reaching Human Performance in Pedestrian Detection"></a>[TPAMI-2017] Towards Reaching Human Performance in Pedestrian Detection</h3><ul><li>paper: <a href="http://ieeexplore.ieee.org/document/7917260/" target="_blank" rel="noopener">http://ieeexplore.ieee.org/document/7917260/</a></li><li>arxiv:</li><li>project website:</li><li>slides:</li><li>github caffe:</li></ul><h3 id="ICCV-2017-Multi-label-Learning-of-Part-Detectors-for-Heavily-Occluded-Pedestrian-Detection"><a href="#ICCV-2017-Multi-label-Learning-of-Part-Detectors-for-Heavily-Occluded-Pedestrian-Detection" class="headerlink" title="[ICCV-2017] Multi-label Learning of Part Detectors for Heavily Occluded Pedestrian Detection"></a>[ICCV-2017] Multi-label Learning of Part Detectors for Heavily Occluded Pedestrian Detection</h3><ul><li>paper: <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhou_Multi-Label_Learning_of_ICCV_2017_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhou_Multi-Label_Learning_of_ICCV_2017_paper.pdf</a></li><li>arxiv:</li><li>project website:</li><li>slides:</li></ul><h3 id="ICCV-2017-Illuminating-Pedestrians-via-Simultaneous-Detection-amp-Segmentation"><a href="#ICCV-2017-Illuminating-Pedestrians-via-Simultaneous-Detection-amp-Segmentation" class="headerlink" title="[ICCV-2017]Illuminating Pedestrians via Simultaneous Detection &amp; Segmentation"></a>[ICCV-2017]Illuminating Pedestrians via Simultaneous Detection &amp; Segmentation</h3><p><img src="http://cvlab.cse.msu.edu/images/teasers/pedestrian-intro.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1706.08564" target="_blank" rel="noopener">https://arxiv.org/abs/1706.08564</a></li><li>project website: <a href="http://cvlab.cse.msu.edu/project-pedestrian-detection.html" target="_blank" rel="noopener">http://cvlab.cse.msu.edu/project-pedestrian-detection.html</a></li><li>slides:</li><li>github caffe: <a href="https://github.com/garrickbrazil/SDS-RCNN" target="_blank" rel="noopener">https://github.com/garrickbrazil/SDS-RCNN</a></li></ul><h3 id="CVPR-2016-Semantic-Channels-for-Fast-Pedestrian-Detection"><a href="#CVPR-2016-Semantic-Channels-for-Fast-Pedestrian-Detection" class="headerlink" title="[CVPR-2016] Semantic Channels for Fast Pedestrian Detection"></a>[CVPR-2016] Semantic Channels for Fast Pedestrian Detection</h3><p><img src="./1528195250768.png" alt="Alt text| left | 300x0"></p><ul><li>paper: <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Costea_Semantic_Channels_for_CVPR_2016_paper.pdf" target="_blank" rel="noopener">https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Costea_Semantic_Channels_for_CVPR_2016_paper.pdf</a></li><li>project website:</li><li>slides:</li><li>github caffe:</li></ul><h3 id="CVPR-2016-How-Far-areWe-from-Solving-Pedestrian-Detection"><a href="#CVPR-2016-How-Far-areWe-from-Solving-Pedestrian-Detection" class="headerlink" title="[CVPR-2016] How Far areWe from Solving Pedestrian Detection?"></a>[CVPR-2016] How Far areWe from Solving Pedestrian Detection?</h3><ul><li>paper: <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/app/S06-29.pdf" target="_blank" rel="noopener">https://www.cv-foundation.org/openaccess/content_cvpr_2016/app/S06-29.pdf</a></li><li>project website:</li><li>slides:</li><li>github caffe:</li></ul><h3 id="ICCV-2015-Deep-Learning-Strong-Parts-for-Pedestrian-Detection"><a href="#ICCV-2015-Deep-Learning-Strong-Parts-for-Pedestrian-Detection" class="headerlink" title="[ICCV-2015] Deep Learning Strong Parts for Pedestrian Detection"></a>[ICCV-2015] Deep Learning Strong Parts for Pedestrian Detection</h3><p><img src="./1537260670049.png" alt="Alt text| left | 300x0"></p><ul><li>paper: <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Tian_Deep_Learning_Strong_ICCV_2015_paper.htmler.html" target="_blank" rel="noopener">https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Tian_Deep_Learning_Strong_ICCV_2015_paper.htmler.html</a></li><li>project website:</li><li>slides:</li><li>github caffe:</li></ul><h3 id="CVPR-2013-Joint-Deep-Learning-for-Pedestrian-Detection-Wanli"><a href="#CVPR-2013-Joint-Deep-Learning-for-Pedestrian-Detection-Wanli" class="headerlink" title="[CVPR-2013] Joint Deep Learning for Pedestrian Detection Wanli"></a>[CVPR-2013] Joint Deep Learning for Pedestrian Detection Wanli</h3><p><img src="./1537260505221.png" alt="Alt text| left | 300x0"></p><ul><li>paper: <a href="https://www.cv-foundation.org/openaccess/content_iccv_2013/html/Ouyang_Joint_Deep_Learning_2013_ICCV_paper.html" target="_blank" rel="noopener">https://www.cv-foundation.org/openaccess/content_iccv_2013/html/Ouyang_Joint_Deep_Learning_2013_ICCV_paper.html</a></li><li>project website:</li><li>slides:</li><li>github caffe:</li></ul><h3 id="CVPR-2012-A-Discriminative-Deep-Model-for-Pedestrian-Detection-with-Occlusion-Handling"><a href="#CVPR-2012-A-Discriminative-Deep-Model-for-Pedestrian-Detection-with-Occlusion-Handling" class="headerlink" title="[CVPR-2012] A Discriminative Deep Model for Pedestrian Detection with Occlusion Handling"></a>[CVPR-2012] A Discriminative Deep Model for Pedestrian Detection with Occlusion Handling</h3><p><img src="./1537260310332.png" alt="Alt text| left | 300x0"></p><ul><li>paper: <a href="http://mmlab.ie.cuhk.edu.hk/pdf/ouyangWcvpr2012.pdf" target="_blank" rel="noopener">http://mmlab.ie.cuhk.edu.hk/pdf/ouyangWcvpr2012.pdf</a></li><li>paper: <a href="https://ieeexplore.ieee.org/abstract/document/6248062/" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/6248062/</a></li><li>project website:</li><li>slides:</li><li>github caffe:</li></ul><h3 id="CVPR-2010-Multi-Cue-Pedestrian-Classification-With-Partial-Occlusion-Handling"><a href="#CVPR-2010-Multi-Cue-Pedestrian-Classification-With-Partial-Occlusion-Handling" class="headerlink" title="[CVPR-2010] Multi-Cue Pedestrian Classification With Partial Occlusion Handling"></a>[CVPR-2010] Multi-Cue Pedestrian Classification With Partial Occlusion Handling</h3><p><img src="./1537260117170.png" alt="Alt text| left | 300x0"></p><ul><li>paper: <a href="https://ieeexplore.ieee.org/abstract/document/5540111/" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/5540111/</a></li><li>project website:</li><li>slides:</li><li>github caffe:</li></ul><h2 id="行人检测数据集"><a href="#行人检测数据集" class="headerlink" title="行人检测数据集"></a>行人检测数据集</h2><h3 id="CityPersons"><a href="#CityPersons" class="headerlink" title="CityPersons"></a>CityPersons</h3><p><img src="./1534569661113.png" alt="Alt text"></p><p>CityPersons数据集是在Cityscapes数据集基础上建立的，使用了Cityscapes数据集的数据，对一些类别进行了精确的标注。该数据集是在[CVPR-2017] CityPersons: A Diverse Dataset for Pedestrian Detection这篇论文中提出的，更多细节可以通过阅读该论文了解。</p><p>上图中左侧是行人标注，右侧是原始的CityScapes数据集。</p><ul><li><a href="https://bitbucket.org/shanshanzhang/citypersons" target="_blank" rel="noopener"><strong>标注和评估文件</strong></a></li><li><a href="https://www.cityscapes-dataset.com/" target="_blank" rel="noopener"><strong>数据集下载</strong></a></li></ul><p>文件格式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#评测文件</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/evaluation/eval_script/coco.py</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/evaluation/eval_script/eval_demo.py</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/evaluation/eval_script/eval_MR_multisetup.py</span><br><span class="line"></span><br><span class="line">#注释文件</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/annotations</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/annotations/anno_train.mat</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/annotations/anno_val.mat</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/annotations/README.txt</span><br><span class="line">#图片数据</span><br><span class="line"></span><br><span class="line">$/Cityscapes/leftImg8bit/train/*</span><br><span class="line">$/Cityscapes/leftImg8bit/val/*</span><br><span class="line">$/Cityscapes/leftImg8bit/test/*</span><br></pre></td></tr></table></figure><p>注释文件格式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">CityPersons annotations</span><br><span class="line">(1) data structure:</span><br><span class="line">    one image per cell</span><br><span class="line">    in each cell, there are three fields: city_name; im_name; bbs (bounding box annotations)</span><br><span class="line"></span><br><span class="line">(2) bounding box annotation format:</span><br><span class="line">　　 one object instance per row:</span><br><span class="line">　　 [class_label, x1,y1,w,h, instance_id, x1_vis, y1_vis, w_vis, h_vis]</span><br><span class="line"></span><br><span class="line">(3) class label definition:</span><br><span class="line">　 class_label =0: ignore regions (fake humans, e.g. people on posters, reflections etc.)</span><br><span class="line">    class_label =1: pedestrians</span><br><span class="line">    class_label =2: riders</span><br><span class="line">    class_label =3: sitting persons</span><br><span class="line">    class_label =4: other persons with unusual postures</span><br><span class="line">    class_label =5: group of people</span><br><span class="line"></span><br><span class="line">(4) boxes:</span><br><span class="line">　　visible boxes [x1_vis, y1_vis, w_vis, h_vis] are automatically generated from segmentation masks;</span><br><span class="line">      (x1,y1) is the upper left corner.</span><br><span class="line">      if class_label==1 or 2</span><br><span class="line">        [x1,y1,w,h] is a well-aligned bounding box to the full body ;</span><br><span class="line">      else</span><br><span class="line">        [x1,y1,w,h] = [x1_vis, y1_vis, w_vis, h_vis];</span><br></pre></td></tr></table></figure></p><h3 id="Caltech"><a href="#Caltech" class="headerlink" title="Caltech"></a>Caltech</h3><p><img src="1517407508293.png" alt="caltech"></p><ul><li><a href="http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/" target="_blank" rel="noopener"><strong>Caltech官网</strong></a><br>更所细节请阅读这篇论文，<br><a href="http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/files/PAMI12pedestrians.pdf" target="_blank" rel="noopener">[TAPAMI-2012] Pedestrian Detection: An Evaluation of the State of the Art</a></li></ul><p><img src="./1534570096814.png" alt="Alt text"></p><h3 id="KITTI"><a href="#KITTI" class="headerlink" title="KITTI"></a>KITTI</h3><p><img src="./1534569869602.png" alt="Alt text"></p><ul><li><a href="http://www.cvlibs.net/datasets/kitti/" target="_blank" rel="noopener"><strong>KITTI官网</strong></a></li></ul><h2 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a>性能比较</h2><p>数据来自 <a href="https://bitbucket.org/shanshanzhang/citypersons/src/default/" target="_blank" rel="noopener">CityPersons</a> 官网。</p><table><thead><tr><th style="text-align:center">Method</th><th style="text-align:center">MR (Reasonable)</th><th style="text-align:center">MR (Reasonable_small)</th><th style="text-align:center">MR (Reasonable_occ=heavy)</th><th style="text-align:center">MR (All)</th></tr></thead><tbody><tr><td style="text-align:center">YT-PedDet</td><td style="text-align:center">8.41%</td><td style="text-align:center">10.60%</td><td style="text-align:center">37.88%</td><td style="text-align:center">37.22%</td></tr><tr><td style="text-align:center">STNet</td><td style="text-align:center">9.78%</td><td style="text-align:center">10.95%</td><td style="text-align:center">36.16%</td><td style="text-align:center">31.36%</td></tr><tr><td style="text-align:center">DVRNet</td><td style="text-align:center">10.99%</td><td style="text-align:center">15.68%</td><td style="text-align:center">43.77%</td><td style="text-align:center">41.48%</td></tr><tr><td style="text-align:center">HBA-RCNN</td><td style="text-align:center">11.06%</td><td style="text-align:center">14.77%</td><td style="text-align:center">43.61%</td><td style="text-align:center">39.54%</td></tr><tr><td style="text-align:center">OR-CNN</td><td style="text-align:center">11.32%</td><td style="text-align:center">14.19%</td><td style="text-align:center">51.43%</td><td style="text-align:center">40.19%</td></tr><tr><td style="text-align:center">Repultion Loss</td><td style="text-align:center">11.48%</td><td style="text-align:center">15.67%</td><td style="text-align:center">52.59%</td><td style="text-align:center">39.17%</td></tr><tr><td style="text-align:center">Adapted FasterRCNN</td><td style="text-align:center">12.97%</td><td style="text-align:center">37.24%</td><td style="text-align:center">50.47%</td><td style="text-align:center">43.86%</td></tr><tr><td style="text-align:center">MS-CNN</td><td style="text-align:center">13.32%</td><td style="text-align:center">15.86%</td><td style="text-align:center">51.88%</td><td style="text-align:center">39.94%</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      行人检测（Pedestrian Detection）论文整理，包含论文链接和代码地址。
    
    </summary>
    
    
      <category term="Pedestrian Detection" scheme="https://www.starlg.cn/tags/Pedestrian-Detection/"/>
    
  </entry>
  
  <entry>
    <title>Keras Tutorial</title>
    <link href="https://www.starlg.cn/2018/08/14/Keras-Tutorial/"/>
    <id>https://www.starlg.cn/2018/08/14/Keras-Tutorial/</id>
    <published>2018-08-14T14:40:03.000Z</published>
    <updated>2018-09-11T13:13:39.717Z</updated>
    
    <content type="html"><![CDATA[<p>Github地址：<a href="https://github.com/xingkongliang/Keras-Tutorials" target="_blank" rel="noopener">here</a></p><h1 id="Keras-Tutorials"><a href="#Keras-Tutorials" class="headerlink" title="Keras-Tutorials"></a>Keras-Tutorials</h1><blockquote><p>版本：0.0.1</p></blockquote><blockquote><p>作者：张天亮</p></blockquote><blockquote><p>邮箱：<a href="mailto:zhangtianliang13@mails.ucas.ac.cn" target="_blank" rel="noopener">zhangtianliang13@mails.ucas.ac.cn</a></p></blockquote><p>Github 加载 .ipynb 的速度较慢，建议在 <a href="http://nbviewer.ipython.org/github/xingkongliang/Keras-Tutorials" target="_blank" rel="noopener">Nbviewer</a> 中查看该项目。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>大部分内容来自keras项目中的<a href="https://github.com/fchollet/keras/tree/master/examples" target="_blank" rel="noopener">examples</a></p><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/01.mnist_mpl.ipynb" target="_blank" rel="noopener">01.多层感知机实现</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/02.save_model.ipynb" target="_blank" rel="noopener">02.模型的保存</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/03.load_model.ipynb" target="_blank" rel="noopener">03.模型的加载</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/04.plot_acc_loss.ipynb" target="_blank" rel="noopener">04.绘制精度和损失曲线</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/05.mnist_cnn.ipynb" target="_blank" rel="noopener">05.卷积神经网络实现</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/06.cifar10_cnn.ipynb" target="_blank" rel="noopener">06.CIFAR10_cnn</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/07.mnist_lstm.ipynb" target="_blank" rel="noopener">07.mnist_lstm</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/08.vgg-16.ipynb" target="_blank" rel="noopener">08.VGG16调用</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/09.conv_filter_visualization.ipynb" target="_blank" rel="noopener">09.卷积滤波器可视化</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/10.variational_autoencoder.ipynb" target="_blank" rel="noopener">10.variational_autoencoder</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/11.mnist_transfer_cnn.ipynb" target="_blank" rel="noopener">11.锁定层fine-tuning网络</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/12.mnist_sklearn_wrapper.ipynb" target="_blank" rel="noopener">12.使用sklearn wrapper进行的参数搜索</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/13.Keras_with_tensorflow.ipynb" target="_blank" rel="noopener">13.Keras和Tensorflow联合使用</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/14.finetune_InceptionV3.ipynb" target="_blank" rel="noopener">14.Finetune InceptionV3样例</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/15.autoencoder.ipynb" target="_blank" rel="noopener">15.自编码器</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/16.Convolutional_autoencoder.ipynb" target="_blank" rel="noopener">16.卷积自编码器</a></li></ul><p>更多Keras使用方法请查看手册</p><ul><li><a href="http://keras-cn.readthedocs.io/en/latest/" target="_blank" rel="noopener">中文手册</a></li><li><a href="https://keras.io/" target="_blank" rel="noopener">英文手册</a></li><li><a href="https://github.com/fchollet/keras" target="_blank" rel="noopener">github</a></li></ul>]]></content>
    
    <summary type="html">
    
      Keras基本教程，jupyter notebook。
    
    </summary>
    
      <category term="Deep Learning" scheme="https://www.starlg.cn/categories/Deep-Learning/"/>
    
    
      <category term="Keras" scheme="https://www.starlg.cn/tags/Keras/"/>
    
  </entry>
  
  <entry>
    <title>Generative Adversarial Nets</title>
    <link href="https://www.starlg.cn/2018/08/14/Generative-Adversarial-Nets/"/>
    <id>https://www.starlg.cn/2018/08/14/Generative-Adversarial-Nets/</id>
    <published>2018-08-14T13:21:12.000Z</published>
    <updated>2018-08-14T14:45:18.283Z</updated>
    
    <content type="html"><![CDATA[<h2 id="DCGANs-in-TensorFlow"><a href="#DCGANs-in-TensorFlow" class="headerlink" title="DCGANs in TensorFlow"></a>DCGANs in TensorFlow</h2><p><a href="https://github.com/carpedm20/DCGAN-tensorflow" target="_blank" rel="noopener">carpedm20/DCGAN-tensorflow</a><br>我们定义网络结构：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(self, z)</span>:</span></span><br><span class="line">    self.z_, self.h0_w, self.h0_b = linear(z, self.gf_dim*<span class="number">8</span>*<span class="number">4</span>*<span class="number">4</span>,</span><br><span class="line">                                           <span class="string">'g_h0_lin'</span>, with_w=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    self.h0 = tf.reshape(self.z_, [<span class="number">-1</span>, <span class="number">4</span>, <span class="number">4</span>, self.gf_dim * <span class="number">8</span>])</span><br><span class="line">    h0 = tf.nn.relu(self.g_bn0(self.h0))</span><br><span class="line"></span><br><span class="line">    self.h1, self.h1_w, self.h1_b = conv2d_transpose(h0,</span><br><span class="line">        [self.batch_size, <span class="number">8</span>, <span class="number">8</span>, self.gf_dim*<span class="number">4</span>], name=<span class="string">'g_h1'</span>, with_w=<span class="keyword">True</span>)</span><br><span class="line">    h1 = tf.nn.relu(self.g_bn1(self.h1))</span><br><span class="line"></span><br><span class="line">    h2, self.h2_w, self.h2_b = conv2d_transpose(h1,</span><br><span class="line">        [self.batch_size, <span class="number">16</span>, <span class="number">16</span>, self.gf_dim*<span class="number">2</span>], name=<span class="string">'g_h2'</span>, with_w=<span class="keyword">True</span>)</span><br><span class="line">    h2 = tf.nn.relu(self.g_bn2(h2))</span><br><span class="line"></span><br><span class="line">    h3, self.h3_w, self.h3_b = conv2d_transpose(h2,</span><br><span class="line">        [self.batch_size, <span class="number">32</span>, <span class="number">32</span>, self.gf_dim*<span class="number">1</span>], name=<span class="string">'g_h3'</span>, with_w=<span class="keyword">True</span>)</span><br><span class="line">    h3 = tf.nn.relu(self.g_bn3(h3))</span><br><span class="line"></span><br><span class="line">    h4, self.h4_w, self.h4_b = conv2d_transpose(h3,</span><br><span class="line">        [self.batch_size, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>], name=<span class="string">'g_h4'</span>, with_w=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.nn.tanh(h4)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(self, image, reuse=False)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> reuse:</span><br><span class="line">        tf.get_variable_scope().reuse_variables()</span><br><span class="line"></span><br><span class="line">    h0 = lrelu(conv2d(image, self.df_dim, name=<span class="string">'d_h0_conv'</span>))</span><br><span class="line">    h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim*<span class="number">2</span>, name=<span class="string">'d_h1_conv'</span>)))</span><br><span class="line">    h2 = lrelu(self.d_bn2(conv2d(h1, self.df_dim*<span class="number">4</span>, name=<span class="string">'d_h2_conv'</span>)))</span><br><span class="line">    h3 = lrelu(self.d_bn3(conv2d(h2, self.df_dim*<span class="number">8</span>, name=<span class="string">'d_h3_conv'</span>)))</span><br><span class="line">    h4 = linear(tf.reshape(h3, [<span class="number">-1</span>, <span class="number">8192</span>]), <span class="number">1</span>, <span class="string">'d_h3_lin'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.nn.sigmoid(h4), h4</span><br></pre></td></tr></table></figure><p>当我们初始化这个类时，我们将使用这些函数来创建模型。 我们需要两个版本的鉴别器共享（或重用）参数。 一个用于来自数据分布的图像的minibatch，另一个用于来自发生器的图像的minibatch。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.G = self.generator(self.z)</span><br><span class="line">self.D, self.D_logits = self.discriminator(self.images)</span><br><span class="line">self.D_, self.D_logits_ = self.discriminator(self.G, reuse=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>接下来我们定义损失函数。我们在D的预测值和我们理想的判别器输出值之间使用<a href="https://en.wikipedia.org/wiki/Cross_entropy" target="_blank" rel="noopener">交叉熵</a>，而没有只用求和，因为这样的效果更好。判别器希望对“真实”数据的预测全部是1，并且来自生成器的“假”数据的预测全部是零。生成器希望判别器对所有假样本的预测都是1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">self.d_loss_real = tf.reduce_mean(</span><br><span class="line">    tf.nn.sigmoid_cross_entropy_with_logits(self.D_logits,</span><br><span class="line">                                            tf.ones_like(self.D)))</span><br><span class="line">self.d_loss_fake = tf.reduce_mean(</span><br><span class="line">    tf.nn.sigmoid_cross_entropy_with_logits(self.D_logits_,</span><br><span class="line">                                            tf.zeros_like(self.D_)))</span><br><span class="line">self.d_loss = self.d_loss_real + self.d_loss_fake</span><br><span class="line"></span><br><span class="line">self.g_loss = tf.reduce_mean(</span><br><span class="line">    tf.nn.sigmoid_cross_entropy_with_logits(self.D_logits_,</span><br><span class="line">                                            tf.ones_like(self.D_)))</span><br></pre></td></tr></table></figure><p>收集每个模型的变量，以便可以单独进行训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">t_vars = tf.trainable_variables()</span><br><span class="line"></span><br><span class="line">self.d_vars = [var <span class="keyword">for</span> var <span class="keyword">in</span> t_vars <span class="keyword">if</span> <span class="string">'d_'</span> <span class="keyword">in</span> var.name]</span><br><span class="line">self.g_vars = [var <span class="keyword">for</span> var <span class="keyword">in</span> t_vars <span class="keyword">if</span> <span class="string">'g_'</span> <span class="keyword">in</span> var.name]</span><br></pre></td></tr></table></figure><p>现在我们准备好优化参数，我们将使用<a href="https://arxiv.org/abs/1412.6980" target="_blank" rel="noopener">ADAM</a>，这是一种在现代深度学习中常见的自适应非凸优化方法。ADAM通常与SGD竞争，并且（通常）不需要手动调节学习速率，动量和其他超参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">d_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \</span><br><span class="line">                    .minimize(self.d_loss, var_list=self.d_vars)</span><br><span class="line">g_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \</span><br><span class="line">                    .minimize(self.g_loss, var_list=self.g_vars)</span><br></pre></td></tr></table></figure><p>我们已经准备好了解我们的数据。在每个epoch中，我们在每个minibatch中采样一些图像，并且运行优化器更新网络。有趣的是，如果G仅更新一次，判别器的损失则不会为零。另外，我认为<code>d_loss_fake</code>和<code>d_loss_real</code>在最后的额外的调用回到是一点点不必要的计算，并且是冗余的，因为这些值是作为<code>d_optim</code>和<code>g_optim</code>的一部分计算的。作为TensorFlow中的练习，您可以尝试优化此部分并将RP发送到原始库。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> xrange(config.epoch):</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> xrange(<span class="number">0</span>, batch_idxs):</span><br><span class="line">        batch_images = ...</span><br><span class="line">        batch_z = np.random.uniform(<span class="number">-1</span>, <span class="number">1</span>, [config.batch_size, self.z_dim]) \</span><br><span class="line">                    .astype(np.float32)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update D network</span></span><br><span class="line">        _, summary_str = self.sess.run([d_optim, self.d_sum],</span><br><span class="line">            feed_dict=&#123; self.images: batch_images, self.z: batch_z &#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update G network</span></span><br><span class="line">        _, summary_str = self.sess.run([g_optim, self.g_sum],</span><br><span class="line">            feed_dict=&#123; self.z: batch_z &#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Run g_optim twice to make sure that d_loss does not go to zero</span></span><br><span class="line">        <span class="comment"># (different from paper)</span></span><br><span class="line">        _, summary_str = self.sess.run([g_optim, self.g_sum],</span><br><span class="line">            feed_dict=&#123; self.z: batch_z &#125;)</span><br><span class="line"></span><br><span class="line">        errD_fake = self.d_loss_fake.eval(&#123;self.z: batch_z&#125;)</span><br><span class="line">        errD_real = self.d_loss_real.eval(&#123;self.images: batch_images&#125;)</span><br><span class="line">        errG = self.g_loss.eval(&#123;self.z: batch_z&#125;)</span><br></pre></td></tr></table></figure><h3 id="Generative-Adversarial-Networks代码整理"><a href="#Generative-Adversarial-Networks代码整理" class="headerlink" title="Generative Adversarial Networks代码整理"></a>Generative Adversarial Networks代码整理</h3><ul><li><p><a href="https://github.com/openai/InfoGAN" target="_blank" rel="noopener"><strong>InfoGAN-TensorFlow</strong></a>:InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</p></li><li><p><a href="https://github.com/junyanz/iGAN" target="_blank" rel="noopener"><strong>iGAN-Theano</strong></a>:Generative Visual Manipulation on the Natural Image Manifold</p></li><li><p><a href="https://github.com/LantaoYu/SeqGAN" target="_blank" rel="noopener"><strong>SeqGAN-TensorFlow</strong></a>:SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient</p></li><li><p><a href="https://github.com/carpedm20/DCGAN-tensorflow" target="_blank" rel="noopener"><strong>DCGAN-Tensorflow</strong></a>:Deep Convolutional Generative Adversarial Networks </p></li><li><p><a href="https://github.com/Newmu/dcgan_code" target="_blank" rel="noopener"><strong>dcgan_code-Theano</strong></a>:Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</p></li><li><p><a href="https://github.com/openai/improved-gan" target="_blank" rel="noopener"><strong>improved-gan-Theano</strong></a>:Improved Techniques for Training GANs</p></li><li><p><a href="https://github.com/mattya/chainer-DCGAN" target="_blank" rel="noopener"><strong>chainer-DCGAN</strong></a>:Chainer implementation of Deep Convolutional Generative Adversarial Network</p></li><li><p><a href="https://github.com/jacobgil/keras-dcgan" target="_blank" rel="noopener"><strong>keras-dcgan</strong></a></p></li></ul>]]></content>
    
    <summary type="html">
    
      一些GANs资料和简单代码解析。
    
    </summary>
    
      <category term="Deep Learning" scheme="https://www.starlg.cn/categories/Deep-Learning/"/>
    
    
      <category term="GAN" scheme="https://www.starlg.cn/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>How to use hexo?</title>
    <link href="https://www.starlg.cn/2018/08/14/How-to-use-hexo/"/>
    <id>https://www.starlg.cn/2018/08/14/How-to-use-hexo/</id>
    <published>2018-08-14T07:21:22.000Z</published>
    <updated>2018-09-02T14:33:26.398Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Hexo基本指令"><a href="#Hexo基本指令" class="headerlink" title="Hexo基本指令"></a>Hexo基本指令</h2><h3 id="init"><a href="#init" class="headerlink" title="init"></a>init</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo init [folder]</span><br></pre></td></tr></table></figure><p>新建一个网站，如果没有设置｀folder｀，Hexo默认在目前的文件夹建立网站。</p><h3 id="new"><a href="#new" class="headerlink" title="new"></a>new</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new [layout] &lt;title&gt;</span><br></pre></td></tr></table></figure><p>新建一片文章。如果没有设置<code>layout</code>的话，默认使用_config.yml中的default_layout参数代替。如果标题包含空格的话，请使用引号括起来。</p><h3 id="generate"><a href="#generate" class="headerlink" title="generate"></a>generate</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br><span class="line">$ hexo g  # 简写</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="publish"><a href="#publish" class="headerlink" title="publish"></a>publish</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo publish [layout] &lt;filename&gt;</span><br></pre></td></tr></table></figure><p>发表草稿。</p><h3 id="server"><a href="#server" class="headerlink" title="server"></a>server</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>启动服务器。默认情况下，访问网址为：<code>http://localhost:4000/</code>。</p><table><thead><tr><th style="text-align:center">选项</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center"><code>-p</code>,<code>--port</code></td><td style="text-align:center">重设端口</td></tr><tr><td style="text-align:center"><code>-s</code>, <code>--static</code></td><td style="text-align:center">只使用静态文本</td></tr><tr><td style="text-align:center"><code>-l</code>,<code>--log</code></td><td style="text-align:center">启动日记记录，使用覆盖记录格式</td></tr></tbody></table><h3 id="deploy"><a href="#deploy" class="headerlink" title="deploy"></a>deploy</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br><span class="line">$ hexo d  # 简写</span><br></pre></td></tr></table></figure><h3 id="render"><a href="#render" class="headerlink" title="render"></a>render</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo render &lt;file1&gt; [file2] ...</span><br></pre></td></tr></table></figure><p>渲染文件。</p><h3 id="clean"><a href="#clean" class="headerlink" title="clean"></a>clean</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean</span><br></pre></td></tr></table></figure><p>清楚缓存文件(<code>db.json</code>)好已经生成的静态文件(<code>public</code>)。</p><p>在某些情况(尤其是更换主题后)，如果发现您对站点的更改没有生效，可以使用此命令。</p><h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo list &lt;type&gt;</span><br></pre></td></tr></table></figure><p>列出网站资料。</p><h3 id="version"><a href="#version" class="headerlink" title="version"></a>version</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo version</span><br></pre></td></tr></table></figure><p>显示Hexo版本。</p><h3 id="显示草稿"><a href="#显示草稿" class="headerlink" title="显示草稿"></a>显示草稿</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo --draft</span><br></pre></td></tr></table></figure><p>显示<code>source/_drafts</code>文件夹中的草稿文件。</p><h3 id="自定义CWD"><a href="#自定义CWD" class="headerlink" title="自定义CWD"></a>自定义CWD</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo --cwd /path/to/cwd</span><br></pre></td></tr></table></figure><p>自定义当前工作目录(Current working dirctory)的路径。</p><h3 id="在主页截断"><a href="#在主页截断" class="headerlink" title="在主页截断"></a>在主页截断</h3><ul><li><p>方法1:<br>在文中插入以下代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--more--&gt;</span><br></pre></td></tr></table></figure></li><li><p>方法2:<br>在文章中的<code>front-matter</code>中添加description，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: </span><br><span class="line">date: 2018-08-14 15:21:22</span><br><span class="line">categories: </span><br><span class="line">tags: </span><br><span class="line">description: 描述。。</span><br><span class="line">---</span><br></pre></td></tr></table></figure></li></ul><h3 id="分类和标签"><a href="#分类和标签" class="headerlink" title="分类和标签"></a>分类和标签</h3><p>只有文章支持分类和标签，您可以在 Front-matter 中设置。在其他系统中，分类和标签听起来很接近，但是在 Hexo 中两者有着明显的差别：分类具有顺序性和层次性，也就是说 <code>Foo</code>, <code>Bar</code> 不等于 <code>Bar</code>, <code>Foo</code>；而标签没有顺序和层次。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">categories:</span><br><span class="line">- Diary</span><br><span class="line">tags:</span><br><span class="line">- PS3</span><br><span class="line">- Games</span><br></pre></td></tr></table></figure><h3 id="定义一段代码。"><a href="#定义一段代码。" class="headerlink" title="定义一段代码。"></a>定义一段代码。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    print(<span class="string">'now is '</span>, i)</span><br></pre></td></tr></table></figure><p>显示一幅图像。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;% asset_img 003.jpg This is an example image %&#125;</span><br></pre></td></tr></table></figure></p><img src="/2018/08/14/How-to-use-hexo/003.jpg" title="This is an example image"><h2 id="Hexo-资源"><a href="#Hexo-资源" class="headerlink" title="Hexo 资源"></a>Hexo 资源</h2><p><a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">hexo官网</a></p><p><a href="http://theme-next.iissnan.com/" target="_blank" rel="noopener">theme-next使用说明</a></p><p><a href="https://www.zhihu.com/question/21193762" target="_blank" rel="noopener">使用hexo，如果换了电脑怎么更新博客？</a></p><p>其他参考博客：<br><a href="https://blog.csdn.net/u011475210/article/details/79023429" target="_blank" rel="noopener">我的个人博客之旅：从jekyll到hexo</a><br><a href="http://mashirosorata.vicp.io/HEXO-NEXT%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE.html" target="_blank" rel="noopener">HEXO+NEXT主题个性化配置</a></p><p><a href="https://segmentfault.com/a/1190000009544924#articleHeader21" target="_blank" rel="noopener">hexo的next主题个性化配置教程</a></p><p><a href="http://blog.csdn.net/MasterAnt_D/article/details/56839222#t50" target="_blank" rel="noopener">基于Hexo+Node.js+github+coding搭建个人博客——进阶篇(从入门到入土)</a></p>]]></content>
    
    <summary type="html">
    
      使用Hexo的基本方法。
    
    </summary>
    
    
  </entry>
  
</feed>
