<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Tianliang</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://xingkongliang.github.io/"/>
  <updated>2018-08-14T14:44:50.943Z</updated>
  <id>https://xingkongliang.github.io/</id>
  
  <author>
    <name>Tianliang Zhang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Keras Tutorial</title>
    <link href="https://xingkongliang.github.io/2018/08/14/Keras-Tutorial/"/>
    <id>https://xingkongliang.github.io/2018/08/14/Keras-Tutorial/</id>
    <published>2018-08-14T14:40:03.000Z</published>
    <updated>2018-08-14T14:44:50.943Z</updated>
    
    <content type="html"><![CDATA[<p>Github地址：<a href="https://github.com/xingkongliang/Keras-Tutorials" target="_blank" rel="noopener">here</a></p><h1 id="Keras-Tutorials"><a href="#Keras-Tutorials" class="headerlink" title="Keras-Tutorials"></a>Keras-Tutorials</h1><blockquote><p>版本：0.0.1</p></blockquote><blockquote><p>作者：张天亮</p></blockquote><blockquote><p>邮箱：<a href="mailto:zhangtianliang13@mails.ucas.ac.cn" target="_blank" rel="noopener">zhangtianliang13@mails.ucas.ac.cn</a></p></blockquote><p>Github 加载 .ipynb 的速度较慢，建议在 <a href="http://nbviewer.ipython.org/github/xingkongliang/Keras-Tutorials" target="_blank" rel="noopener">Nbviewer</a> 中查看该项目。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>大部分内容来自keras项目中的<a href="https://github.com/fchollet/keras/tree/master/examples" target="_blank" rel="noopener">examples</a></p><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="01.mnist_mpl.ipynb">01.多层感知机实现</a></li><li><a href="02.save_model.ipynb">02.模型的保存</a></li><li><a href="03.load_model.ipynb">03.模型的加载</a></li><li><a href="04.plot_acc_loss.ipynb">04.绘制精度和损失曲线</a></li><li><a href="05.mnist_cnn.ipynb">05.卷积神经网络实现</a></li><li><a href="06.cifar10_cnn.ipynb">06.CIFAR10_cnn</a></li><li><a href="07.mnist_lstm.ipynb">07.mnist_lstm</a></li><li><a href="08.vgg-16.ipynb">08.VGG16调用</a></li><li><a href="09.conv_filter_visualization.ipynb">09.卷积滤波器可视化</a></li><li><a href="10.variational_autoencoder.ipynb">10.variational_autoencoder</a></li><li><a href="11.mnist_transfer_cnn.ipynb">11.锁定层fine-tuning网络</a></li><li><a href="12.mnist_sklearn_wrapper.ipynb">12.使用sklearn wrapper进行的参数搜索</a></li><li><a href="13.Keras_with_tensorflow.ipynb">13.Keras和Tensorflow联合使用</a></li><li><a href="14.finetune_InceptionV3.ipynb">14.Finetune InceptionV3样例</a></li><li><a href="15.autoencoder.ipynb">15.自编码器</a></li><li><a href="16.Convolutional_autoencoder.ipynb">16.卷积自编码器</a></li></ul><p>更多Keras使用方法请查看手册</p><ul><li><a href="http://keras-cn.readthedocs.io/en/latest/" target="_blank" rel="noopener">中文手册</a></li><li><a href="https://keras.io/" target="_blank" rel="noopener">英文手册</a></li><li><a href="https://github.com/fchollet/keras" target="_blank" rel="noopener">github</a></li></ul>]]></content>
    
    <summary type="html">
    
      Keras基本教程，jupyter notebook。
    
    </summary>
    
      <category term="Deep Learning" scheme="https://xingkongliang.github.io/categories/Deep-Learning/"/>
    
    
      <category term="Keras" scheme="https://xingkongliang.github.io/tags/Keras/"/>
    
  </entry>
  
  <entry>
    <title>Generative Adversarial Nets</title>
    <link href="https://xingkongliang.github.io/2018/08/14/Generative-Adversarial-Nets/"/>
    <id>https://xingkongliang.github.io/2018/08/14/Generative-Adversarial-Nets/</id>
    <published>2018-08-14T13:21:12.000Z</published>
    <updated>2018-08-14T14:45:18.283Z</updated>
    
    <content type="html"><![CDATA[<h2 id="DCGANs-in-TensorFlow"><a href="#DCGANs-in-TensorFlow" class="headerlink" title="DCGANs in TensorFlow"></a>DCGANs in TensorFlow</h2><p><a href="https://github.com/carpedm20/DCGAN-tensorflow" target="_blank" rel="noopener">carpedm20/DCGAN-tensorflow</a><br>我们定义网络结构：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(self, z)</span>:</span></span><br><span class="line">    self.z_, self.h0_w, self.h0_b = linear(z, self.gf_dim*<span class="number">8</span>*<span class="number">4</span>*<span class="number">4</span>,</span><br><span class="line">                                           <span class="string">'g_h0_lin'</span>, with_w=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    self.h0 = tf.reshape(self.z_, [<span class="number">-1</span>, <span class="number">4</span>, <span class="number">4</span>, self.gf_dim * <span class="number">8</span>])</span><br><span class="line">    h0 = tf.nn.relu(self.g_bn0(self.h0))</span><br><span class="line"></span><br><span class="line">    self.h1, self.h1_w, self.h1_b = conv2d_transpose(h0,</span><br><span class="line">        [self.batch_size, <span class="number">8</span>, <span class="number">8</span>, self.gf_dim*<span class="number">4</span>], name=<span class="string">'g_h1'</span>, with_w=<span class="keyword">True</span>)</span><br><span class="line">    h1 = tf.nn.relu(self.g_bn1(self.h1))</span><br><span class="line"></span><br><span class="line">    h2, self.h2_w, self.h2_b = conv2d_transpose(h1,</span><br><span class="line">        [self.batch_size, <span class="number">16</span>, <span class="number">16</span>, self.gf_dim*<span class="number">2</span>], name=<span class="string">'g_h2'</span>, with_w=<span class="keyword">True</span>)</span><br><span class="line">    h2 = tf.nn.relu(self.g_bn2(h2))</span><br><span class="line"></span><br><span class="line">    h3, self.h3_w, self.h3_b = conv2d_transpose(h2,</span><br><span class="line">        [self.batch_size, <span class="number">32</span>, <span class="number">32</span>, self.gf_dim*<span class="number">1</span>], name=<span class="string">'g_h3'</span>, with_w=<span class="keyword">True</span>)</span><br><span class="line">    h3 = tf.nn.relu(self.g_bn3(h3))</span><br><span class="line"></span><br><span class="line">    h4, self.h4_w, self.h4_b = conv2d_transpose(h3,</span><br><span class="line">        [self.batch_size, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>], name=<span class="string">'g_h4'</span>, with_w=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.nn.tanh(h4)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(self, image, reuse=False)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> reuse:</span><br><span class="line">        tf.get_variable_scope().reuse_variables()</span><br><span class="line"></span><br><span class="line">    h0 = lrelu(conv2d(image, self.df_dim, name=<span class="string">'d_h0_conv'</span>))</span><br><span class="line">    h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim*<span class="number">2</span>, name=<span class="string">'d_h1_conv'</span>)))</span><br><span class="line">    h2 = lrelu(self.d_bn2(conv2d(h1, self.df_dim*<span class="number">4</span>, name=<span class="string">'d_h2_conv'</span>)))</span><br><span class="line">    h3 = lrelu(self.d_bn3(conv2d(h2, self.df_dim*<span class="number">8</span>, name=<span class="string">'d_h3_conv'</span>)))</span><br><span class="line">    h4 = linear(tf.reshape(h3, [<span class="number">-1</span>, <span class="number">8192</span>]), <span class="number">1</span>, <span class="string">'d_h3_lin'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.nn.sigmoid(h4), h4</span><br></pre></td></tr></table></figure><p>当我们初始化这个类时，我们将使用这些函数来创建模型。 我们需要两个版本的鉴别器共享（或重用）参数。 一个用于来自数据分布的图像的minibatch，另一个用于来自发生器的图像的minibatch。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.G = self.generator(self.z)</span><br><span class="line">self.D, self.D_logits = self.discriminator(self.images)</span><br><span class="line">self.D_, self.D_logits_ = self.discriminator(self.G, reuse=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>接下来我们定义损失函数。我们在D的预测值和我们理想的判别器输出值之间使用<a href="https://en.wikipedia.org/wiki/Cross_entropy" target="_blank" rel="noopener">交叉熵</a>，而没有只用求和，因为这样的效果更好。判别器希望对“真实”数据的预测全部是1，并且来自生成器的“假”数据的预测全部是零。生成器希望判别器对所有假样本的预测都是1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">self.d_loss_real = tf.reduce_mean(</span><br><span class="line">    tf.nn.sigmoid_cross_entropy_with_logits(self.D_logits,</span><br><span class="line">                                            tf.ones_like(self.D)))</span><br><span class="line">self.d_loss_fake = tf.reduce_mean(</span><br><span class="line">    tf.nn.sigmoid_cross_entropy_with_logits(self.D_logits_,</span><br><span class="line">                                            tf.zeros_like(self.D_)))</span><br><span class="line">self.d_loss = self.d_loss_real + self.d_loss_fake</span><br><span class="line"></span><br><span class="line">self.g_loss = tf.reduce_mean(</span><br><span class="line">    tf.nn.sigmoid_cross_entropy_with_logits(self.D_logits_,</span><br><span class="line">                                            tf.ones_like(self.D_)))</span><br></pre></td></tr></table></figure><p>收集每个模型的变量，以便可以单独进行训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">t_vars = tf.trainable_variables()</span><br><span class="line"></span><br><span class="line">self.d_vars = [var <span class="keyword">for</span> var <span class="keyword">in</span> t_vars <span class="keyword">if</span> <span class="string">'d_'</span> <span class="keyword">in</span> var.name]</span><br><span class="line">self.g_vars = [var <span class="keyword">for</span> var <span class="keyword">in</span> t_vars <span class="keyword">if</span> <span class="string">'g_'</span> <span class="keyword">in</span> var.name]</span><br></pre></td></tr></table></figure><p>现在我们准备好优化参数，我们将使用<a href="https://arxiv.org/abs/1412.6980" target="_blank" rel="noopener">ADAM</a>，这是一种在现代深度学习中常见的自适应非凸优化方法。ADAM通常与SGD竞争，并且（通常）不需要手动调节学习速率，动量和其他超参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">d_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \</span><br><span class="line">                    .minimize(self.d_loss, var_list=self.d_vars)</span><br><span class="line">g_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \</span><br><span class="line">                    .minimize(self.g_loss, var_list=self.g_vars)</span><br></pre></td></tr></table></figure><p>我们已经准备好了解我们的数据。在每个epoch中，我们在每个minibatch中采样一些图像，并且运行优化器更新网络。有趣的是，如果G仅更新一次，判别器的损失则不会为零。另外，我认为<code>d_loss_fake</code>和<code>d_loss_real</code>在最后的额外的调用回到是一点点不必要的计算，并且是冗余的，因为这些值是作为<code>d_optim</code>和<code>g_optim</code>的一部分计算的。作为TensorFlow中的练习，您可以尝试优化此部分并将RP发送到原始库。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> xrange(config.epoch):</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> xrange(<span class="number">0</span>, batch_idxs):</span><br><span class="line">        batch_images = ...</span><br><span class="line">        batch_z = np.random.uniform(<span class="number">-1</span>, <span class="number">1</span>, [config.batch_size, self.z_dim]) \</span><br><span class="line">                    .astype(np.float32)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update D network</span></span><br><span class="line">        _, summary_str = self.sess.run([d_optim, self.d_sum],</span><br><span class="line">            feed_dict=&#123; self.images: batch_images, self.z: batch_z &#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update G network</span></span><br><span class="line">        _, summary_str = self.sess.run([g_optim, self.g_sum],</span><br><span class="line">            feed_dict=&#123; self.z: batch_z &#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Run g_optim twice to make sure that d_loss does not go to zero</span></span><br><span class="line">        <span class="comment"># (different from paper)</span></span><br><span class="line">        _, summary_str = self.sess.run([g_optim, self.g_sum],</span><br><span class="line">            feed_dict=&#123; self.z: batch_z &#125;)</span><br><span class="line"></span><br><span class="line">        errD_fake = self.d_loss_fake.eval(&#123;self.z: batch_z&#125;)</span><br><span class="line">        errD_real = self.d_loss_real.eval(&#123;self.images: batch_images&#125;)</span><br><span class="line">        errG = self.g_loss.eval(&#123;self.z: batch_z&#125;)</span><br></pre></td></tr></table></figure><h3 id="Generative-Adversarial-Networks代码整理"><a href="#Generative-Adversarial-Networks代码整理" class="headerlink" title="Generative Adversarial Networks代码整理"></a>Generative Adversarial Networks代码整理</h3><ul><li><p><a href="https://github.com/openai/InfoGAN" target="_blank" rel="noopener"><strong>InfoGAN-TensorFlow</strong></a>:InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</p></li><li><p><a href="https://github.com/junyanz/iGAN" target="_blank" rel="noopener"><strong>iGAN-Theano</strong></a>:Generative Visual Manipulation on the Natural Image Manifold</p></li><li><p><a href="https://github.com/LantaoYu/SeqGAN" target="_blank" rel="noopener"><strong>SeqGAN-TensorFlow</strong></a>:SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient</p></li><li><p><a href="https://github.com/carpedm20/DCGAN-tensorflow" target="_blank" rel="noopener"><strong>DCGAN-Tensorflow</strong></a>:Deep Convolutional Generative Adversarial Networks </p></li><li><p><a href="https://github.com/Newmu/dcgan_code" target="_blank" rel="noopener"><strong>dcgan_code-Theano</strong></a>:Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</p></li><li><p><a href="https://github.com/openai/improved-gan" target="_blank" rel="noopener"><strong>improved-gan-Theano</strong></a>:Improved Techniques for Training GANs</p></li><li><p><a href="https://github.com/mattya/chainer-DCGAN" target="_blank" rel="noopener"><strong>chainer-DCGAN</strong></a>:Chainer implementation of Deep Convolutional Generative Adversarial Network</p></li><li><p><a href="https://github.com/jacobgil/keras-dcgan" target="_blank" rel="noopener"><strong>keras-dcgan</strong></a></p></li></ul>]]></content>
    
    <summary type="html">
    
      一些GANs资料和简单代码解析。
    
    </summary>
    
      <category term="Deep Learning" scheme="https://xingkongliang.github.io/categories/Deep-Learning/"/>
    
    
      <category term="GAN" scheme="https://xingkongliang.github.io/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>How to use hexo?</title>
    <link href="https://xingkongliang.github.io/2018/08/14/How-to-use-hexo/"/>
    <id>https://xingkongliang.github.io/2018/08/14/How-to-use-hexo/</id>
    <published>2018-08-14T07:21:22.000Z</published>
    <updated>2018-08-14T13:19:05.765Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Hexo基本指令"><a href="#Hexo基本指令" class="headerlink" title="Hexo基本指令"></a>Hexo基本指令</h2><h3 id="init"><a href="#init" class="headerlink" title="init"></a>init</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo init [folder]</span><br></pre></td></tr></table></figure><p>新建一个网站，如果没有设置｀folder｀，Hexo默认在目前的文件夹建立网站。</p><h3 id="new"><a href="#new" class="headerlink" title="new"></a>new</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new [layout] &lt;title&gt;</span><br></pre></td></tr></table></figure><p>新建一片文章。如果没有设置<code>layout</code>的话，默认使用_config.yml中的default_layout参数代替。如果标题包含空格的话，请使用引号括起来。</p><h3 id="generate"><a href="#generate" class="headerlink" title="generate"></a>generate</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br><span class="line">$ hexo g  # 简写</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="publish"><a href="#publish" class="headerlink" title="publish"></a>publish</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo publish [layout] &lt;filename&gt;</span><br></pre></td></tr></table></figure><p>发表草稿。</p><h3 id="server"><a href="#server" class="headerlink" title="server"></a>server</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>启动服务器。默认情况下，访问网址为：<code>http://localhost:4000/</code>。</p><table><thead><tr><th style="text-align:center">选项</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center"><code>-p</code>,<code>--port</code></td><td style="text-align:center">重设端口</td></tr><tr><td style="text-align:center"><code>-s</code>, <code>--static</code></td><td style="text-align:center">只使用静态文本</td></tr><tr><td style="text-align:center"><code>-l</code>,<code>--log</code></td><td style="text-align:center">启动日记记录，使用覆盖记录格式</td></tr></tbody></table><h3 id="deploy"><a href="#deploy" class="headerlink" title="deploy"></a>deploy</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br><span class="line">$ hexo d  # 简写</span><br></pre></td></tr></table></figure><h3 id="render"><a href="#render" class="headerlink" title="render"></a>render</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo render &lt;file1&gt; [file2] ...</span><br></pre></td></tr></table></figure><p>渲染文件。</p><h3 id="clean"><a href="#clean" class="headerlink" title="clean"></a>clean</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean</span><br></pre></td></tr></table></figure><p>清楚缓存文件(<code>db.json</code>)好已经生成的静态文件(<code>public</code>)。</p><p>在某些情况(尤其是更换主题后)，如果发现您对站点的更改没有生效，可以使用此命令。</p><h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo list &lt;type&gt;</span><br></pre></td></tr></table></figure><p>列出网站资料。</p><h3 id="version"><a href="#version" class="headerlink" title="version"></a>version</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo version</span><br></pre></td></tr></table></figure><p>显示Hexo版本。</p><h3 id="显示草稿"><a href="#显示草稿" class="headerlink" title="显示草稿"></a>显示草稿</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo --draft</span><br></pre></td></tr></table></figure><p>显示<code>source/_drafts</code>文件夹中的草稿文件。</p><h3 id="自定义CWD"><a href="#自定义CWD" class="headerlink" title="自定义CWD"></a>自定义CWD</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo --cwd /path/to/cwd</span><br></pre></td></tr></table></figure><p>自定义当前工作目录(Current working dirctory)的路径。</p><h3 id="在主页截断"><a href="#在主页截断" class="headerlink" title="在主页截断"></a>在主页截断</h3><ul><li><p>方法1:<br>在文中插入以下代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--more--&gt;</span><br></pre></td></tr></table></figure></li><li><p>方法2:<br>在文章中的<code>front-matter</code>中添加description，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: </span><br><span class="line">date: 2018-08-14 15:21:22</span><br><span class="line">categories: </span><br><span class="line">tags: </span><br><span class="line">description: 描述。。</span><br><span class="line">---</span><br></pre></td></tr></table></figure></li></ul><h3 id="分类和标签"><a href="#分类和标签" class="headerlink" title="分类和标签"></a>分类和标签</h3><p>只有文章支持分类和标签，您可以在 Front-matter 中设置。在其他系统中，分类和标签听起来很接近，但是在 Hexo 中两者有着明显的差别：分类具有顺序性和层次性，也就是说 <code>Foo</code>, <code>Bar</code> 不等于 <code>Bar</code>, <code>Foo</code>；而标签没有顺序和层次。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">categories:</span><br><span class="line">- Diary</span><br><span class="line">tags:</span><br><span class="line">- PS3</span><br><span class="line">- Games</span><br></pre></td></tr></table></figure><h3 id="定义一段代码。"><a href="#定义一段代码。" class="headerlink" title="定义一段代码。"></a>定义一段代码。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    print(<span class="string">'now is '</span>, i)</span><br></pre></td></tr></table></figure><p>显示一幅图像。<br><img src="/2018/08/14/How-to-use-hexo/003.jpg" title="This is an example image"></p><h2 id="Hexo-资源"><a href="#Hexo-资源" class="headerlink" title="Hexo 资源"></a>Hexo 资源</h2><p><a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">hexo官网</a></p><p><a href="http://theme-next.iissnan.com/" target="_blank" rel="noopener">theme-next使用说明</a></p><p><a href="https://www.zhihu.com/question/21193762" target="_blank" rel="noopener">使用hexo，如果换了电脑怎么更新博客？</a></p><p>其他参考博客：<br><a href="https://blog.csdn.net/u011475210/article/details/79023429" target="_blank" rel="noopener">我的个人博客之旅：从jekyll到hexo</a><br><a href="http://mashirosorata.vicp.io/HEXO-NEXT%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE.html" target="_blank" rel="noopener">HEXO+NEXT主题个性化配置</a></p><p><a href="https://segmentfault.com/a/1190000009544924#articleHeader21" target="_blank" rel="noopener">hexo的next主题个性化配置教程</a></p><p><a href="http://blog.csdn.net/MasterAnt_D/article/details/56839222#t50" target="_blank" rel="noopener">基于Hexo+Node.js+github+coding搭建个人博客——进阶篇(从入门到入土)</a></p>]]></content>
    
    <summary type="html">
    
      使用Hexo的基本方法。
    
    </summary>
    
    
  </entry>
  
</feed>
