<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Tianliang</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.starlg.cn/"/>
  <updated>2018-09-09T05:57:42.588Z</updated>
  <id>https://www.starlg.cn/</id>
  
  <author>
    <name>Tianliang Zhang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Conda使用指南</title>
    <link href="https://www.starlg.cn/2018/09/09/Conda-Tutorials/"/>
    <id>https://www.starlg.cn/2018/09/09/Conda-Tutorials/</id>
    <published>2018-09-09T05:07:18.000Z</published>
    <updated>2018-09-09T05:57:42.588Z</updated>
    
    <content type="html"><![CDATA[<img src="/2018/09/09/Conda-Tutorials/anconda.png" title="Anconda"><p>Python渐渐成为最流行的编程语言之一，在数据分析、机器学习和深度学习等方向Python语言更是主流。Python的版本比较多，并且它的库也非常广泛，同时库和库之间存在很多依赖关系，所以在库的安装和版本的管理上很麻烦。Conda是一个管理版本和Python环境的工具，它使用起来非常容易。</p><p>首先你需要安装<a href="https://www.anaconda.com/" target="_blank" rel="noopener">Anconda</a>软件，点击链接<a href="https://www.anaconda.com/download/" target="_blank" rel="noopener">download</a>。选择对应的系统和版本类型。</p><h2 id="Conda的环境管理"><a href="#Conda的环境管理" class="headerlink" title="Conda的环境管理"></a>Conda的环境管理</h2><h3 id="创建环境"><a href="#创建环境" class="headerlink" title="创建环境"></a>创建环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个名为python34的环境，指定Python版本是3.5（不用管是3.5.x，conda会为我们自动寻找3.５.x中的最新版本）</span><br><span class="line">conda create --name py35 python=3.5</span><br></pre></td></tr></table></figure><h3 id="激活环境"><a href="#激活环境" class="headerlink" title="激活环境"></a>激活环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 安装好后，使用activate激活某个环境</span><br><span class="line">activate py35 # for Windows</span><br><span class="line">source activate py35 # for Linux &amp; Mac</span><br><span class="line">(py35) user@user-XPS-8920:~$</span><br><span class="line"> # 激活后，会发现terminal输入的地方多了py35的字样，实际上，此时系统做的事情就是把默认2.7环境从PATH中去除，再把3.4对应的命令加入PATH</span><br><span class="line"> </span><br><span class="line">(py35) user@user-XPS-8920:~$ python --version</span><br><span class="line">Python 3.5.5 :: Anaconda, Inc.</span><br><span class="line"># 可以得到`Python 3.5.5 :: Anaconda, Inc.`，即系统已经切换到了3.５的环境</span><br></pre></td></tr></table></figure><h3 id="返回主环境"><a href="#返回主环境" class="headerlink" title="返回主环境"></a>返回主环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 如果想返回默认的python 2.7环境，运行</span><br><span class="line">deactivate py35 # for Windows</span><br><span class="line">source deactivate py35 # for Linux &amp; Mac</span><br></pre></td></tr></table></figure><h3 id="删除环境"><a href="#删除环境" class="headerlink" title="删除环境"></a>删除环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 删除一个已有的环境</span><br><span class="line">conda remove --name py35 --all</span><br></pre></td></tr></table></figure><h3 id="查看系统中的所有环境"><a href="#查看系统中的所有环境" class="headerlink" title="查看系统中的所有环境"></a>查看系统中的所有环境</h3><p>用户安装的不同Python环境会放在<code>~/anaconda/envs</code>目录下。查看当前系统中已经安装了哪些环境，使用<code>conda info -e</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">user@user-XPS-8920:~$ conda info -e</span><br><span class="line"># conda environments:</span><br><span class="line">#</span><br><span class="line">base                  *  /home/user/anaconda2</span><br><span class="line">caffe                    /home/user/anaconda2/envs/caffe</span><br><span class="line">py35                    /home/user/anaconda2/envs/py35</span><br><span class="line">tf                       /home/user/anaconda2/envs/tf</span><br></pre></td></tr></table></figure><h2 id="Conda的包管理"><a href="#Conda的包管理" class="headerlink" title="Conda的包管理"></a>Conda的包管理</h2><h3 id="安装库"><a href="#安装库" class="headerlink" title="安装库"></a>安装库</h3><p>为当前环境安装库<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># numpy</span><br><span class="line">conda install numpy</span><br><span class="line"># conda会从从远程搜索numpy的相关信息和依赖项目</span><br></pre></td></tr></table></figure></p><p>###　查看已经安装的库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 查看已经安装的packages</span><br><span class="line">conda list</span><br><span class="line"># 最新版的conda是从site-packages文件夹中搜索已经安装的包，可以显示出通过各种方式安装的包</span><br></pre></td></tr></table></figure><h3 id="查看某个环境的已安装包"><a href="#查看某个环境的已安装包" class="headerlink" title="查看某个环境的已安装包"></a>查看某个环境的已安装包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查看某个指定环境的已安装包</span><br><span class="line">conda list -n py35</span><br></pre></td></tr></table></figure><h3 id="搜索package的信息"><a href="#搜索package的信息" class="headerlink" title="搜索package的信息"></a>搜索package的信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查找package信息</span><br><span class="line">conda search numpy</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Loading channels: done</span><br><span class="line"># Name                  Version           Build  Channel             </span><br><span class="line">numpy                     1.5.1          py26_1  pkgs/free           </span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">numpy                    1.15.1  py37hec00662_0  anaconda/pkgs/main  </span><br><span class="line">numpy                    1.15.1  py37hec00662_0  pkgs/main</span><br></pre></td></tr></table></figure><h3 id="安装package到指定的环境"><a href="#安装package到指定的环境" class="headerlink" title="安装package到指定的环境"></a>安装package到指定的环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 安装package</span><br><span class="line">conda install -n py35 numpy</span><br><span class="line"># 如果不用-n指定环境名称，则被安装在当前活跃环境</span><br><span class="line"># 也可以通过-c指定通过某个channel安装</span><br></pre></td></tr></table></figure><h3 id="更新package"><a href="#更新package" class="headerlink" title="更新package"></a>更新package</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 更新package</span><br><span class="line">conda update -n py35 numpy</span><br></pre></td></tr></table></figure><h3 id="删除package"><a href="#删除package" class="headerlink" title="删除package"></a>删除package</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 删除package</span><br><span class="line">conda remove -n py35 numpy</span><br></pre></td></tr></table></figure><h3 id="更新conda"><a href="#更新conda" class="headerlink" title="更新conda"></a>更新conda</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 更新conda，保持conda最新</span><br><span class="line">conda update conda</span><br></pre></td></tr></table></figure><h3 id="更新anaconda"><a href="#更新anaconda" class="headerlink" title="更新anaconda"></a>更新anaconda</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 更新anaconda</span><br><span class="line">conda update anaconda</span><br></pre></td></tr></table></figure><h3 id="更新Python"><a href="#更新Python" class="headerlink" title="更新Python"></a>更新Python</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 更新python</span><br><span class="line">conda update python</span><br><span class="line"># 假设当前环境是python 3.5, conda会将python升级为3.5.x系列的当前最新版本</span><br></pre></td></tr></table></figure><h2 id="设置国内镜像"><a href="#设置国内镜像" class="headerlink" title="设置国内镜像"></a>设置国内镜像</h2><p>因为Anaconda.org的服务器在国外，所有有些库下载缓慢，可以使用清华Anaconda镜像源。</p><p>网站地址: <a href="https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/" target="_blank" rel="noopener">清华大学开源软件镜像站</a></p><h3 id="Anaconda-镜像"><a href="#Anaconda-镜像" class="headerlink" title="Anaconda　镜像"></a>Anaconda　镜像</h3><p>Anaconda 安装包可以到 <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/</a> 下载。</p><p>TUNA还提供了Anaconda仓库的镜像，运行以下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></table></figure></p><p>即可添加 Anaconda Python 免费仓库。</p><p>运行 <code>conda install numpy</code> 测试一下吧。</p><h3 id="Miniconda-镜像"><a href="#Miniconda-镜像" class="headerlink" title="Miniconda　镜像"></a>Miniconda　镜像</h3><p>Miniconda 是一个 Anaconda 的轻量级替代，默认只包含了 python 和 conda，但是可以通过 pip 和 conda 来安装所需要的包。</p><p>Miniconda 安装包可以到 <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/</a> 下载。</p>]]></content>
    
    <summary type="html">
    
      Python环境管理工具
    
    </summary>
    
      <category term="Python" scheme="https://www.starlg.cn/categories/Python/"/>
    
    
  </entry>
  
  <entry>
    <title>[MLIA] Logistic Regression</title>
    <link href="https://www.starlg.cn/2018/09/05/MLIA-Logistic-Regression/"/>
    <id>https://www.starlg.cn/2018/09/05/MLIA-Logistic-Regression/</id>
    <published>2018-09-05T14:45:58.000Z</published>
    <updated>2018-09-06T02:42:43.010Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h1><p>本代码来自Machine Learning in Action。</p><p>想要了解更多的朋友可以参考此书。</p><h2 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h2><p>$$\sigma(z) = \frac{1}{(1+e^{-z})}$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(inX)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1</span>+np.exp(-inX))</span><br><span class="line"></span><br><span class="line">z = np.linspace(<span class="number">-5</span>, <span class="number">5</span>, <span class="number">100</span>)</span><br><span class="line">y = sigmoid(z)</span><br><span class="line">plt.plot(z, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_2_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">z = np.linspace(<span class="number">-60</span>, <span class="number">60</span>, <span class="number">100</span>)</span><br><span class="line">y = sigmoid(z)</span><br><span class="line">plt.plot(z, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_3_0.png" alt="png"></p><p>Sigmoid函数类似一个单位阶跃函数。当x＝0时，Sigmoid函数值为0.5；随着x增大，Sigmoid函数值将逼近于1；随着x减小，Sigmoid函数将逼近于0。利用这个性质可以对它的输入做一个二分类。</p><p>为了实现Logistic回归分类器，我们可以在每个特征上都乘以一个回归系数，然后把它的所有的结果值相加，将这个总和带入Sigmoid函数中，进而得到一个范围在0~1之间是数值。当大于0.5的时候，将数据分类为1；当小于0.5的时候，将数据分类为0。</p><p>Sigmoid函数的输入记为z:</p><p>$$z=w_0x_0 + w_1x_1 + w_2x_2 + \cdot \cdot \cdot + w_n x_n$$</p><h2 id="Sigmoid函数的导数"><a href="#Sigmoid函数的导数" class="headerlink" title="Sigmoid函数的导数"></a>Sigmoid函数的导数</h2><p>Sigmoid导数具体推导过程如下：</p><p>$$<br>\begin{align}<br>f^{\prime}(z) &amp;= (\frac{1}{1+e^{-z}})^{\prime}\\<br>&amp;=\frac{e^{-z}}{(1+e^{-z})^2}\\<br>&amp;=\frac{1+e^{-z}-1}{(1+e^{-z})^2}\\<br>&amp;=\frac{1}{(1+e^{-z})}(1-\frac{1}{(1+e^{-z})})\\<br>&amp;=f(z)(1-f(z))<br>\end{align}<br>$$</p><h2 id="梯度上升法"><a href="#梯度上升法" class="headerlink" title="梯度上升法"></a>梯度上升法</h2><p>梯度上升法：顾名思义就是利用梯度方向，寻找到某函数的最大值。</p><p>梯度上升算法迭代公式：<br>$$w:=w+\alpha \nabla_w f(w)$$</p><p>梯度下降法：和梯度上升想法，利用梯度方法，寻找某个函数的最小值。<br>梯度下降算法迭代公式：<br>$$w:=w-\alpha \nabla_w f(w)$$</p><p><img src="./Fig5_2.png" alt=""></p><p>梯度上升算法每次更新之后，都会重新估计移动的方法，即梯度。</p><h2 id="Logistic-回归梯度上升优化法"><a href="#Logistic-回归梯度上升优化法" class="headerlink" title="Logistic 回归梯度上升优化法"></a>Logistic 回归梯度上升优化法</h2><h3 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    dataMat = []; labelMat = []</span><br><span class="line">    fr = open(<span class="string">'testSet.txt'</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        lineArr = line.strip().split()</span><br><span class="line">        dataMat.append([<span class="number">1.0</span>, float(lineArr[<span class="number">0</span>]), float(lineArr[<span class="number">1</span>])])</span><br><span class="line">        labelMat.append(int(lineArr[<span class="number">2</span>]))</span><br><span class="line">    <span class="keyword">return</span> dataMat,labelMat</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dataArray, labelMat = loadDataSet()</span><br><span class="line">print(<span class="string">"Total: "</span>, len(dataArray))</span><br><span class="line">print(<span class="string">"The first sample: "</span>, dataArray[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">"The second sample: "</span>, dataArray[<span class="number">1</span>])</span><br><span class="line">print(<span class="string">"Label: "</span>, labelMat)</span><br></pre></td></tr></table></figure><pre><code>(&apos;Total: &apos;, 100)(&apos;The first sample: &apos;, [1.0, -0.017612, 14.053064])(&apos;The second sample: &apos;, [1.0, -1.395634, 4.662541])(&apos;Label: &apos;, [0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0])</code></pre><h3 id="数据集梯度上升"><a href="#数据集梯度上升" class="headerlink" title="数据集梯度上升"></a>数据集梯度上升</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(inX)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1</span>+np.exp(-inX))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradAscent</span><span class="params">(dataMatIn, classLabels)</span>:</span></span><br><span class="line">    dataMatrix = np.mat(dataMatIn)             <span class="comment">#convert to NumPy matrix</span></span><br><span class="line">    labelMat = np.mat(classLabels).transpose() <span class="comment">#convert to NumPy matrix</span></span><br><span class="line">    m,n = np.shape(dataMatrix)</span><br><span class="line">    alpha = <span class="number">0.001</span></span><br><span class="line">    maxCycles = <span class="number">500</span></span><br><span class="line">    weights = np.ones((n,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(maxCycles):              <span class="comment">#heavy on matrix operations</span></span><br><span class="line">        h = sigmoid(dataMatrix*weights)     <span class="comment">#matrix mult</span></span><br><span class="line">        error = (labelMat - h)              <span class="comment">#vector subtraction</span></span><br><span class="line">        weights = weights + alpha * dataMatrix.transpose()* error <span class="comment">#matrix mult</span></span><br><span class="line">    <span class="keyword">return</span> weights</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gradAscent(dataArray, labelMat)</span><br></pre></td></tr></table></figure><pre><code>matrix([[ 4.12414349],        [ 0.48007329],        [-0.6168482 ]])</code></pre><h3 id="绘制数据和决策边界"><a href="#绘制数据和决策边界" class="headerlink" title="绘制数据和决策边界"></a>绘制数据和决策边界</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotBestFit</span><span class="params">(weights)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    dataMat,labelMat=loadDataSet()</span><br><span class="line">    dataArr = np.array(dataMat)</span><br><span class="line">    n = np.shape(dataArr)[<span class="number">0</span>] </span><br><span class="line">    xcord1 = []; ycord1 = []</span><br><span class="line">    xcord2 = []; ycord2 = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">if</span> int(labelMat[i])== <span class="number">1</span>:</span><br><span class="line">            xcord1.append(dataArr[i,<span class="number">1</span>]); ycord1.append(dataArr[i,<span class="number">2</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            xcord2.append(dataArr[i,<span class="number">1</span>]); ycord2.append(dataArr[i,<span class="number">2</span>])</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    ax.scatter(xcord1, ycord1, s=<span class="number">30</span>, c=<span class="string">'red'</span>, marker=<span class="string">'s'</span>)</span><br><span class="line">    ax.scatter(xcord2, ycord2, s=<span class="number">30</span>, c=<span class="string">'green'</span>)</span><br><span class="line">    x = np.arange(<span class="number">-3.0</span>, <span class="number">3.0</span>, <span class="number">0.1</span>)</span><br><span class="line">    y = (-weights[<span class="number">0</span>]-weights[<span class="number">1</span>]*x)/weights[<span class="number">2</span>]</span><br><span class="line">    ax.plot(x, y)</span><br><span class="line">    plt.xlabel(<span class="string">'X1'</span>); plt.ylabel(<span class="string">'X2'</span>);</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">weights = gradAscent(dataArray, labelMat)</span><br><span class="line">plotBestFit(weights.getA())</span><br></pre></td></tr></table></figure><p><img src="output_17_0.png" alt="png"></p><h2 id="１个epoch的随机梯度上升"><a href="#１个epoch的随机梯度上升" class="headerlink" title="１个epoch的随机梯度上升"></a>１个epoch的随机梯度上升</h2><p>梯度上升算法在每次更新系数的时候都需要便利整个数据集，如果数据集的样本比较大，该方法的复杂度和计算代价就很高。有一种改进的方法叫做随机梯度上升方法。该方法的思想是选取一个样本，计算该样本的梯度，更新系数，再选取下一个样本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent0</span><span class="params">(dataMatrix, classLabels)</span>:</span></span><br><span class="line">    m,n = np.shape(dataMatrix)</span><br><span class="line">    alpha = <span class="number">0.01</span></span><br><span class="line">    weights = np.ones(n)   <span class="comment">#initialize to all ones</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        h = sigmoid(sum(dataMatrix[i]*weights))</span><br><span class="line">        error = classLabels[i] - h</span><br><span class="line">        weights = weights + alpha * error * dataMatrix[i]</span><br><span class="line">    <span class="keyword">return</span> weights</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">weights = stocGradAscent0(np.array(dataArray), labelMat)</span><br><span class="line">plotBestFit(weights)</span><br></pre></td></tr></table></figure><p><img src="output_20_0.png" alt="png"></p><p>上图之后遍历了一次数据集，这样的模型还处于欠拟合状态。需要多次遍历数据集才能优化好模型，接下来我们会运行200次迭代。</p><h2 id="200个epoch的随机梯度上升"><a href="#200个epoch的随机梯度上升" class="headerlink" title="200个epoch的随机梯度上升"></a>200个epoch的随机梯度上升</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent0</span><span class="params">(dataMatrix, classLabels)</span>:</span></span><br><span class="line">    X0, X1, X2 = [], [], []</span><br><span class="line">    m,n = np.shape(dataMatrix)</span><br><span class="line">    alpha = <span class="number">0.01</span></span><br><span class="line">    weights = np.ones(n)   <span class="comment">#initialize to all ones</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">200</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            h = sigmoid(sum(dataMatrix[i]*weights))</span><br><span class="line">            error = classLabels[i] - h</span><br><span class="line">            weights = weights + alpha * error * dataMatrix[i]</span><br><span class="line">            X0.append(weights[<span class="number">0</span>])</span><br><span class="line">            X1.append(weights[<span class="number">1</span>])</span><br><span class="line">            X2.append(weights[<span class="number">2</span>])</span><br><span class="line">    <span class="keyword">return</span> weights, X0, X1, X2</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">weights, X0, X1, X2 = stocGradAscent0(np.array(dataArray), labelMat)</span><br><span class="line">plotBestFit(weights)</span><br></pre></td></tr></table></figure><p><img src="output_24_0.png" alt="png"></p><h3 id="可视化权重-weights-的变化"><a href="#可视化权重-weights-的变化" class="headerlink" title="可视化权重(weights)的变化"></a>可视化权重(weights)的变化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(<span class="number">3</span>, <span class="number">1</span>, figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">ax[<span class="number">0</span>].plot(np.arange(len(X0)), np.array(X0))</span><br><span class="line">ax[<span class="number">1</span>].plot(np.arange(len(X1)), np.array(X1))</span><br><span class="line">ax[<span class="number">2</span>].plot(np.arange(len(X2)), np.array(X2))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_26_0.png" alt="png"></p><p>从上图可以看出，算法正在逐渐收敛。由于数据集并不是线性可分的，所以存在一些不能正确分类的样本点，每次更新权重引起了周期的变化。</p><h2 id="更新过后的随机梯度上升算法"><a href="#更新过后的随机梯度上升算法" class="headerlink" title="更新过后的随机梯度上升算法"></a>更新过后的随机梯度上升算法</h2><ol><li>学习率alpha会在每次迭代之后调整。</li><li>采用随机选取样本的更新策略，减少周期性的波动。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent1</span><span class="params">(dataMatrix, classLabels, numIter=<span class="number">150</span>)</span>:</span></span><br><span class="line">    X0, X1, X2 = [], [], []</span><br><span class="line">    m,n = np.shape(dataMatrix)</span><br><span class="line">    weights = np.ones(n)   <span class="comment">#initialize to all ones</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(numIter):</span><br><span class="line">        dataIndex = range(m)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            alpha = <span class="number">4</span>/(<span class="number">1.0</span>+j+i)+<span class="number">0.0001</span>    <span class="comment">#apha decreases with iteration, does not </span></span><br><span class="line">            randIndex = int(np.random.uniform(<span class="number">0</span>,len(dataIndex)))<span class="comment">#go to 0 because of the constant</span></span><br><span class="line">            h = sigmoid(sum(dataMatrix[randIndex]*weights))</span><br><span class="line">            error = classLabels[randIndex] - h</span><br><span class="line">            weights = weights + alpha * error * dataMatrix[randIndex]</span><br><span class="line">            X0.append(weights[<span class="number">0</span>])</span><br><span class="line">            X1.append(weights[<span class="number">1</span>])</span><br><span class="line">            X2.append(weights[<span class="number">2</span>])</span><br><span class="line">            <span class="keyword">del</span>(dataIndex[randIndex])</span><br><span class="line">    <span class="keyword">return</span> weights, X0, X1, X2</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">weights, X0, X1, X2 = stocGradAscent1(np.array(dataArray), labelMat)</span><br><span class="line">plotBestFit(weights)</span><br></pre></td></tr></table></figure><p><img src="output_30_0.png" alt="png"></p><h3 id="可视化权重-weights-的变化-1"><a href="#可视化权重-weights-的变化-1" class="headerlink" title="可视化权重(weights)的变化"></a>可视化权重(weights)的变化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(<span class="number">3</span>, <span class="number">1</span>, figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">ax[<span class="number">0</span>].plot(np.arange(len(X0)), np.array(X0))</span><br><span class="line">ax[<span class="number">1</span>].plot(np.arange(len(X1)), np.array(X1))</span><br><span class="line">ax[<span class="number">2</span>].plot(np.arange(len(X2)), np.array(X2))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_32_0.png" alt="png"></p><h1 id="示例：从疝气病症预测病马的死亡率"><a href="#示例：从疝气病症预测病马的死亡率" class="headerlink" title="示例：从疝气病症预测病马的死亡率"></a>示例：从疝气病症预测病马的死亡率</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyVector</span><span class="params">(inX, weights)</span>:</span></span><br><span class="line">    prob = sigmoid(sum(inX*weights))</span><br><span class="line">    <span class="keyword">if</span> prob &gt; <span class="number">0.5</span>: <span class="keyword">return</span> <span class="number">1.0</span></span><br><span class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">colicTest</span><span class="params">()</span>:</span></span><br><span class="line">    frTrain = open(<span class="string">'horseColicTraining.txt'</span>, <span class="string">'r'</span>); frTest = open(<span class="string">'horseColicTest.txt'</span>, <span class="string">'r'</span>)</span><br><span class="line">    trainingSet = []; trainingLabels = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> frTrain.readlines():</span><br><span class="line">        currLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        lineArr =[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">21</span>):</span><br><span class="line">            lineArr.append(float(currLine[i]))</span><br><span class="line">        trainingSet.append(lineArr)</span><br><span class="line">        trainingLabels.append(float(currLine[<span class="number">21</span>]))</span><br><span class="line">    trainWeights, X0, X1, X2 = stocGradAscent1(np.array(trainingSet), trainingLabels, <span class="number">1000</span>)</span><br><span class="line">    errorCount = <span class="number">0</span>; numTestVec = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> frTest.readlines():</span><br><span class="line">        numTestVec += <span class="number">1.0</span></span><br><span class="line">        currLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        lineArr =[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">21</span>):</span><br><span class="line">            lineArr.append(float(currLine[i]))</span><br><span class="line">        <span class="keyword">if</span> int(classifyVector(np.array(lineArr), trainWeights))!= int(currLine[<span class="number">21</span>]):</span><br><span class="line">            errorCount += <span class="number">1</span></span><br><span class="line">    errorRate = (float(errorCount)/numTestVec)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"the error rate of this test is: %f"</span> % errorRate</span><br><span class="line">    <span class="keyword">return</span> errorRate</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiTest</span><span class="params">()</span>:</span></span><br><span class="line">    numTests = <span class="number">10</span>; errorSum=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(numTests):</span><br><span class="line">        errorSum += colicTest()</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"after %d iterations the average error rate is: %f"</span> % (numTests, errorSum/float(numTests))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">multiTest()</span><br></pre></td></tr></table></figure><pre><code>/home/tianliang/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in expthe error rate of this test is: 0.328358the error rate of this test is: 0.432836the error rate of this test is: 0.388060the error rate of this test is: 0.373134the error rate of this test is: 0.373134the error rate of this test is: 0.447761the error rate of this test is: 0.343284the error rate of this test is: 0.313433the error rate of this test is: 0.328358the error rate of this test is: 0.462687after 10 iterations the average error rate is: 0.379104</code></pre>]]></content>
    
    <summary type="html">
    
      Logistic Regression And Code
    
    </summary>
    
      <category term="Machine Learning" scheme="https://www.starlg.cn/categories/Machine-Learning/"/>
    
    
  </entry>
  
  <entry>
    <title>CornerNet: Detection Objects as Paired Keypoints</title>
    <link href="https://www.starlg.cn/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/"/>
    <id>https://www.starlg.cn/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/</id>
    <published>2018-09-02T14:08:13.000Z</published>
    <updated>2018-09-02T14:35:34.600Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>CornerNet: Detection Objects as Paired Keypoints　这篇论文发表在ECCV2018，本人感觉非常有意思，所以和大家分享一下。</p><p>Arxiv: <a href="https://arxiv.org/abs/1808.01244" target="_blank" rel="noopener">https://arxiv.org/abs/1808.01244</a><br>Github: <a href="https://github.com/umich-vl/" target="_blank" rel="noopener">https://github.com/umich-vl/</a></p><hr><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>传统的目标检测都是给出紧致的候选框，本论文独具匠心，通过一对关键点（目标的左上角和右下角）来检测一个目标框。通过检测关键点的这种方式，可以消除利用先验知识设计anchor boxes这个需求。作者提出角点池化（corner pooling），角点池化可以帮助网络更好的定位角点。最终实验表明，CornerNet在MS COCO数据集上实现了42.1%的AP，优于所有现存的单级(one-stage)检测器。</p><a id="more"></a><hr><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig1.png" title="We detect an object as a pair of bounding box corners grouped together."><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig2.png" title="Often there is no local evidence to determine the location of a bounding box corner. We address this issue by proposing a new type of pooling layer."><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig3.png" title="Corner pooling: for each channel, we take the maximum values (red dots) in two directions (red lines), each from a separate feature map, and add the two maximums together (blue dot)."><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig4.png" title="Overview of CornerNet. The backbone network is followed by two prediction modules, one for the top-left corners and the other for the bottom-right corners. Using the predictions from both modules, we locate and group the corners."><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig5.png" title="“Ground-truth” heatmaps for training."><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig6.png" title="The top-left corner pooling layer can be implemented very efficiently. We scan from left to right for the horizontal max-pooling and from bottom to top for the vertical max-pooling. We then add two max-pooled feature maps."><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig7.png" title="The prediction module starts with a modified residual block, in which we replace the first convolution module with our corner pooling module. The modified residual block is then followed by a convolution module. We have multiple branches for predict- ing the heatmaps, embeddings and offsets"><img src="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/Fig8.png" title="Example bounding box predictions overlaid on predicted heatmaps of corners.">]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;CornerNet: Detection Objects as Paired Keypoints　这篇论文发表在ECCV2018，本人感觉非常有意思，所以和大家分享一下。&lt;/p&gt;
&lt;p&gt;Arxiv: &lt;a href=&quot;https://arxiv.org/abs/1808.01244&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://arxiv.org/abs/1808.01244&lt;/a&gt;&lt;br&gt;Github: &lt;a href=&quot;https://github.com/umich-vl/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/umich-vl/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h3&gt;&lt;p&gt;传统的目标检测都是给出紧致的候选框，本论文独具匠心，通过一对关键点（目标的左上角和右下角）来检测一个目标框。通过检测关键点的这种方式，可以消除利用先验知识设计anchor boxes这个需求。作者提出角点池化（corner pooling），角点池化可以帮助网络更好的定位角点。最终实验表明，CornerNet在MS COCO数据集上实现了42.1%的AP，优于所有现存的单级(one-stage)检测器。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Object Detection" scheme="https://www.starlg.cn/tags/Object-Detection/"/>
    
  </entry>
  
  <entry>
    <title>行人检测（Pedestrian Detection）论文整理</title>
    <link href="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/"/>
    <id>https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/</id>
    <published>2018-08-17T03:26:22.000Z</published>
    <updated>2018-09-18T09:18:49.256Z</updated>
    
    <content type="html"><![CDATA[<h2 id="相关科研工作者"><a href="#相关科研工作者" class="headerlink" title="相关科研工作者"></a>相关科研工作者</h2><ul><li><a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=pOSMWfQAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target="_blank" rel="noopener">张姗姗 scholar</a></li><li><a href="https://sites.google.com/site/shanshanzhangshomepage/" target="_blank" rel="noopener">张姗姗 homepage</a></li><li><a href="https://scholar.google.com/citations?user=pw_0Z_UAAAAJ&amp;%20hl=en" target="_blank" rel="noopener">欧阳万里 scholar</a></li><li><a href="http://www.ee.cuhk.edu.hk/~wlouyang/" target="_blank" rel="noopener">欧阳万里 homepage</a></li></ul><h2 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h2><h3 id="TIP-2018-Too-Far-to-See-Not-Really-Pedestrian-Detection-with-Scale-Aware-Localization-Policy"><a href="#TIP-2018-Too-Far-to-See-Not-Really-Pedestrian-Detection-with-Scale-Aware-Localization-Policy" class="headerlink" title="[TIP-2018] Too Far to See? Not Really: Pedestrian Detection with Scale-Aware Localization Policy"></a>[TIP-2018] Too Far to See? Not Really: Pedestrian Detection with Scale-Aware Localization Policy</h3><p><img src="./1533980426553.png" alt="Alt text| left | 300x0"></p><ul><li>paper: </li><li>project website: </li><li>slides: </li><li>github: </li></ul><h3 id="Transactions-on-Multimedia-201８-Scale-Aware-Fast-R-CNN-for-Pedestrian-Detection"><a href="#Transactions-on-Multimedia-201８-Scale-Aware-Fast-R-CNN-for-Pedestrian-Detection" class="headerlink" title="[Transactions on Multimedia-201８] Scale-Aware Fast R-CNN for Pedestrian Detection"></a>[Transactions on Multimedia-201８] Scale-Aware Fast R-CNN for Pedestrian Detection</h3><p><img src="./1533980383783.png" alt="Alt text| left | 300x0"></p><ul><li>paper: <a href="https://ieeexplore.ieee.org/abstract/document/8060595/" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/8060595/</a></li><li>project website: </li><li>slides: </li><li>github: </li></ul><h3 id="ECCV-2018-Bi-box-Regression-for-Pedestrian-Detection-and-Occlusion-Estimation"><a href="#ECCV-2018-Bi-box-Regression-for-Pedestrian-Detection-and-Occlusion-Estimation" class="headerlink" title="[ECCV-2018] Bi-box Regression for Pedestrian Detection and Occlusion Estimation"></a>[ECCV-2018] Bi-box Regression for Pedestrian Detection and Occlusion Estimation</h3><p><img src="./ECCV2018-Bi-box_Regression_2.png" alt="Alt text| left | 300x0"><br><img src="./ECCV2018-Bi-box_Regression.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:</li><li>paper:<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/CHUNLUAN_ZHOU_Bi-box_Regression_for_ECCV_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ECCV_2018/papers/CHUNLUAN_ZHOU_Bi-box_Regression_for_ECCV_2018_paper.pdf</a></li><li>slides: </li><li>github: </li></ul><h3 id="ECCV-2018-Learning-Efficient-Single-stage-Pedestrian-Detectors-by-Asymptotic-Localization-Fitting"><a href="#ECCV-2018-Learning-Efficient-Single-stage-Pedestrian-Detectors-by-Asymptotic-Localization-Fitting" class="headerlink" title="[ECCV-2018] Learning Efficient Single-stage Pedestrian Detectors by Asymptotic Localization Fitting"></a>[ECCV-2018] Learning Efficient Single-stage Pedestrian Detectors by Asymptotic Localization Fitting</h3><p><img src="./ECCV2-18-Learning_Efficien_Single-stage_Pedestrian_Detectors.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:</li><li>paper:<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Wei_Liu_Learning_Efficient_Single-stage_ECCV_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ECCV_2018/papers/Wei_Liu_Learning_Efficient_Single-stage_ECCV_2018_paper.pdf</a></li><li>project website: </li><li>slides: </li><li>github: </li></ul><h3 id="ECCV-2018-Graininess-Aware-Deep-Feature-Learning-for-Pedestrian-Detection"><a href="#ECCV-2018-Graininess-Aware-Deep-Feature-Learning-for-Pedestrian-Detection" class="headerlink" title="[ECCV-2018] Graininess-Aware Deep Feature Learning for Pedestrian Detection"></a>[ECCV-2018] Graininess-Aware Deep Feature Learning for Pedestrian Detection</h3><p><img src="./ECCV2018-Graininess-Aware_Deep_Learning.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:</li><li>paper:<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Chunze_Lin_Graininess-Aware_Deep_Feature_ECCV_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ECCV_2018/papers/Chunze_Lin_Graininess-Aware_Deep_Feature_ECCV_2018_paper.pdf</a></li><li>project website: </li><li>slides: </li><li>github: </li></ul><h3 id="ECCV-2018-Occlusion-aware-R-CNN-Detecting-Pedestrians-in-a-Crowd"><a href="#ECCV-2018-Occlusion-aware-R-CNN-Detecting-Pedestrians-in-a-Crowd" class="headerlink" title="[ECCV-2018] Occlusion-aware R-CNN: Detecting Pedestrians in a Crowd"></a>[ECCV-2018] Occlusion-aware R-CNN: Detecting Pedestrians in a Crowd</h3><p><img src="./ECCV2018-Occlusion-aware_R-CNN.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:<a href="http://arxiv.org/abs/1807.08407" target="_blank" rel="noopener">http://arxiv.org/abs/1807.08407</a></li><li>project website: </li><li>slides: </li><li>github: </li></ul><h3 id="ECCV-2018-Small-scale-Pedestrian-Detection-Based-on-Somatic-Topology-Localization-and-Temporal-Feature-Aggregation"><a href="#ECCV-2018-Small-scale-Pedestrian-Detection-Based-on-Somatic-Topology-Localization-and-Temporal-Feature-Aggregation" class="headerlink" title="[ECCV-2018] Small-scale Pedestrian Detection Based on Somatic Topology Localization and Temporal Feature Aggregation"></a>[ECCV-2018] Small-scale Pedestrian Detection Based on Somatic Topology Localization and Temporal Feature Aggregation</h3><p><img src="./1533979932529.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:<a href="https://arxiv.org/abs/1807.01438" target="_blank" rel="noopener">https://arxiv.org/abs/1807.01438</a></li><li>project website: </li><li>slides: </li><li>github: </li></ul><h3 id="CVPR-2018-Improving-Occlusion-and-Hard-Negative-Handling-for-Single-Stage-Pedestrian-Detectors"><a href="#CVPR-2018-Improving-Occlusion-and-Hard-Negative-Handling-for-Single-Stage-Pedestrian-Detectors" class="headerlink" title="[CVPR-2018] Improving Occlusion and Hard Negative Handling for Single-Stage Pedestrian Detectors"></a>[CVPR-2018] Improving Occlusion and Hard Negative Handling for Single-Stage Pedestrian Detectors</h3><p><img src="./1533980803719.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:</li><li>paper: <a href="http://vision.snu.ac.kr/projects/partgridnet/data/noh_2018.pdf" target="_blank" rel="noopener">http://vision.snu.ac.kr/projects/partgridnet/data/noh_2018.pdf</a></li><li>project website: <a href="http://vision.snu.ac.kr/projects/partgridnet/" target="_blank" rel="noopener">http://vision.snu.ac.kr/projects/partgridnet/</a></li><li>slides: </li><li>github: </li></ul><h3 id="CVPR-2018-Occluded-Pedestrian-Detection-Through-Guided-Attention-in-CNNs"><a href="#CVPR-2018-Occluded-Pedestrian-Detection-Through-Guided-Attention-in-CNNs" class="headerlink" title="[CVPR-2018] Occluded Pedestrian Detection Through Guided Attention in CNNs"></a>[CVPR-2018] Occluded Pedestrian Detection Through Guided Attention in CNNs</h3><p><img src="./1533980145178.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:</li><li>paper: <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Occluded_Pedestrian_Detection_CVPR_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Occluded_Pedestrian_Detection_CVPR_2018_paper.pdf</a></li><li>project website: </li><li>slides: </li><li>github: </li></ul><h3 id="CVPR-2018-Repulsion-Loss-Detecting-Pedestrians-in-a-Crowd"><a href="#CVPR-2018-Repulsion-Loss-Detecting-Pedestrians-in-a-Crowd" class="headerlink" title="[CVPR-2018] Repulsion Loss: Detecting Pedestrians in a Crowd"></a>[CVPR-2018] Repulsion Loss: Detecting Pedestrians in a Crowd</h3><p><img src="./1528195001788.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv:<a href="http://arxiv.org/abs/1711.07752" target="_blank" rel="noopener">http://arxiv.org/abs/1711.07752</a></li><li>project website: </li><li>slides: </li><li>github: </li><li>blog: <a href="https://zhuanlan.zhihu.com/p/41288115" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/41288115</a></li></ul><h3 id="TPAMI-2017-Jointly-Learning-Deep-Features-Deformable-Parts-Occlusion-and-Classification-for-Pedestrian-Detection"><a href="#TPAMI-2017-Jointly-Learning-Deep-Features-Deformable-Parts-Occlusion-and-Classification-for-Pedestrian-Detection" class="headerlink" title="[TPAMI-2017] Jointly Learning Deep Features, Deformable Parts, Occlusion and Classification for Pedestrian Detection"></a>[TPAMI-2017] Jointly Learning Deep Features, Deformable Parts, Occlusion and Classification for Pedestrian Detection</h3><p><img src="./1537261066815.png" alt="Alt text| left | 300x0"></p><ul><li>paper: <a href="https://ieeexplore.ieee.org/abstract/document/8008790/" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/8008790/</a></li><li>project website: </li><li>slides: </li><li>github caffe: </li></ul><h3 id="BMVC-2017-PCN-Part-and-Context-Information-for-Pedestrian-Detection-with-CNNs"><a href="#BMVC-2017-PCN-Part-and-Context-Information-for-Pedestrian-Detection-with-CNNs" class="headerlink" title="[BMVC-2017] PCN: Part and Context Information for Pedestrian Detection with CNNs"></a>[BMVC-2017] PCN: Part and Context Information for Pedestrian Detection with CNNs</h3><p><img src="./1533980559400.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1804.044838" target="_blank" rel="noopener">https://arxiv.org/abs/1804.044838</a></li><li>project website: </li><li>slides: </li><li>github caffe: </li></ul><h3 id="CVPR-2017-CityPersons-A-Diverse-Dataset-for-Pedestrian-Detection"><a href="#CVPR-2017-CityPersons-A-Diverse-Dataset-for-Pedestrian-Detection" class="headerlink" title="[CVPR-2017] CityPersons: A Diverse Dataset for Pedestrian Detection"></a>[CVPR-2017] CityPersons: A Diverse Dataset for Pedestrian Detection</h3><p><img src="./1528194369562.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv: <a href="http://arxiv.org/abs/1702.05693" target="_blank" rel="noopener">http://arxiv.org/abs/1702.05693</a></li><li>project website: </li><li>slides: </li><li>github caffe: </li></ul><hr><h3 id="CVPR-2017-Learning-Cross-Modal-Deep-Representations-for-Robust-Pedestrian-Detection"><a href="#CVPR-2017-Learning-Cross-Modal-Deep-Representations-for-Robust-Pedestrian-Detection" class="headerlink" title="[CVPR-2017] Learning Cross-Modal Deep Representations for Robust Pedestrian Detection"></a>[CVPR-2017] Learning Cross-Modal Deep Representations for Robust Pedestrian Detection</h3><p><img src="./1528194560698.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1704.02431" target="_blank" rel="noopener">https://arxiv.org/abs/1704.02431</a></li><li>project website: </li><li>slides: </li><li>github caffe: </li></ul><p><img src="./1528194591022.png" alt="Alt text"><br><img src="./1528194606094.png" alt="Alt text"></p><h3 id="CVPR-2017-What-Can-Help-Pedestrian-Detection"><a href="#CVPR-2017-What-Can-Help-Pedestrian-Detection" class="headerlink" title="[CVPR-2017] What Can Help Pedestrian Detection?"></a>[CVPR-2017] What Can Help Pedestrian Detection?</h3><ul><li>arxiv: <a href="https://arxiv.org/abs/1704.02431" target="_blank" rel="noopener">https://arxiv.org/abs/1704.02431</a></li><li>project website: </li><li>slides: </li><li>github caffe: </li></ul><h3 id="TPAMI-2017-Towards-Reaching-Human-Performance-in-Pedestrian-Detection"><a href="#TPAMI-2017-Towards-Reaching-Human-Performance-in-Pedestrian-Detection" class="headerlink" title="[TPAMI-2017] Towards Reaching Human Performance in Pedestrian Detection"></a>[TPAMI-2017] Towards Reaching Human Performance in Pedestrian Detection</h3><ul><li>paper: <a href="http://ieeexplore.ieee.org/document/7917260/" target="_blank" rel="noopener">http://ieeexplore.ieee.org/document/7917260/</a></li><li>arxiv: </li><li>project website: </li><li>slides: </li><li>github caffe: </li></ul><h3 id="ICCV-2017-Multi-label-Learning-of-Part-Detectors-for-Heavily-Occluded-Pedestrian-Detection"><a href="#ICCV-2017-Multi-label-Learning-of-Part-Detectors-for-Heavily-Occluded-Pedestrian-Detection" class="headerlink" title="[ICCV-2017] Multi-label Learning of Part Detectors for Heavily Occluded Pedestrian Detection"></a>[ICCV-2017] Multi-label Learning of Part Detectors for Heavily Occluded Pedestrian Detection</h3><ul><li>paper: <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhou_Multi-Label_Learning_of_ICCV_2017_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhou_Multi-Label_Learning_of_ICCV_2017_paper.pdf</a></li><li>arxiv: </li><li>project website: </li><li>slides: </li></ul><h3 id="ICCV-2017-Illuminating-Pedestrians-via-Simultaneous-Detection-amp-Segmentation"><a href="#ICCV-2017-Illuminating-Pedestrians-via-Simultaneous-Detection-amp-Segmentation" class="headerlink" title="[ICCV-2017]Illuminating Pedestrians via Simultaneous Detection &amp; Segmentation"></a>[ICCV-2017]Illuminating Pedestrians via Simultaneous Detection &amp; Segmentation</h3><p><img src="http://cvlab.cse.msu.edu/images/teasers/pedestrian-intro.png" alt="Alt text| left | 300x0"></p><ul><li>arxiv: <a href="https://arxiv.org/abs/1706.08564" target="_blank" rel="noopener">https://arxiv.org/abs/1706.08564</a></li><li>project website: <a href="http://cvlab.cse.msu.edu/project-pedestrian-detection.html" target="_blank" rel="noopener">http://cvlab.cse.msu.edu/project-pedestrian-detection.html</a></li><li>slides: </li><li>github caffe: <a href="https://github.com/garrickbrazil/SDS-RCNN" target="_blank" rel="noopener">https://github.com/garrickbrazil/SDS-RCNN</a></li></ul><h3 id="CVPR-2016-Semantic-Channels-for-Fast-Pedestrian-Detection"><a href="#CVPR-2016-Semantic-Channels-for-Fast-Pedestrian-Detection" class="headerlink" title="[CVPR-2016] Semantic Channels for Fast Pedestrian Detection"></a>[CVPR-2016] Semantic Channels for Fast Pedestrian Detection</h3><p><img src="./1528195250768.png" alt="Alt text| left | 300x0"></p><ul><li>paper: <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Costea_Semantic_Channels_for_CVPR_2016_paper.pdf" target="_blank" rel="noopener">https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Costea_Semantic_Channels_for_CVPR_2016_paper.pdf</a></li><li>project website: </li><li>slides: </li><li>github caffe: </li></ul><h3 id="CVPR-2016-How-Far-areWe-from-Solving-Pedestrian-Detection"><a href="#CVPR-2016-How-Far-areWe-from-Solving-Pedestrian-Detection" class="headerlink" title="[CVPR-2016] How Far areWe from Solving Pedestrian Detection?"></a>[CVPR-2016] How Far areWe from Solving Pedestrian Detection?</h3><ul><li>paper: <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/app/S06-29.pdf" target="_blank" rel="noopener">https://www.cv-foundation.org/openaccess/content_cvpr_2016/app/S06-29.pdf</a></li><li>project website: </li><li>slides: </li><li>github caffe: </li></ul><h3 id="ICCV-2015-Deep-Learning-Strong-Parts-for-Pedestrian-Detection"><a href="#ICCV-2015-Deep-Learning-Strong-Parts-for-Pedestrian-Detection" class="headerlink" title="[ICCV-2015] Deep Learning Strong Parts for Pedestrian Detection"></a>[ICCV-2015] Deep Learning Strong Parts for Pedestrian Detection</h3><p><img src="./1537260670049.png" alt="Alt text| left | 300x0"></p><ul><li>paper: <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Tian_Deep_Learning_Strong_ICCV_2015_paper.htmler.html" target="_blank" rel="noopener">https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Tian_Deep_Learning_Strong_ICCV_2015_paper.htmler.html</a></li><li>project website: </li><li>slides: </li><li>github caffe: </li></ul><h3 id="CVPR-2013-Joint-Deep-Learning-for-Pedestrian-Detection-Wanli"><a href="#CVPR-2013-Joint-Deep-Learning-for-Pedestrian-Detection-Wanli" class="headerlink" title="[CVPR-2013] Joint Deep Learning for Pedestrian Detection Wanli"></a>[CVPR-2013] Joint Deep Learning for Pedestrian Detection Wanli</h3><p><img src="./1537260505221.png" alt="Alt text| left | 300x0"></p><ul><li>paper: <a href="https://www.cv-foundation.org/openaccess/content_iccv_2013/html/Ouyang_Joint_Deep_Learning_2013_ICCV_paper.html" target="_blank" rel="noopener">https://www.cv-foundation.org/openaccess/content_iccv_2013/html/Ouyang_Joint_Deep_Learning_2013_ICCV_paper.html</a></li><li>project website: </li><li>slides: </li><li>github caffe: </li></ul><h3 id="CVPR-2012-A-Discriminative-Deep-Model-for-Pedestrian-Detection-with-Occlusion-Handling"><a href="#CVPR-2012-A-Discriminative-Deep-Model-for-Pedestrian-Detection-with-Occlusion-Handling" class="headerlink" title="[CVPR-2012] A Discriminative Deep Model for Pedestrian Detection with Occlusion Handling"></a>[CVPR-2012] A Discriminative Deep Model for Pedestrian Detection with Occlusion Handling</h3><p><img src="./1537260310332.png" alt="Alt text| left | 300x0"></p><ul><li>paper: <a href="http://mmlab.ie.cuhk.edu.hk/pdf/ouyangWcvpr2012.pdf" target="_blank" rel="noopener">http://mmlab.ie.cuhk.edu.hk/pdf/ouyangWcvpr2012.pdf</a></li><li>paper: <a href="https://ieeexplore.ieee.org/abstract/document/6248062/" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/6248062/</a></li><li>project website: </li><li>slides: </li><li>github caffe: </li></ul><h3 id="CVPR-2010-Multi-Cue-Pedestrian-Classification-With-Partial-Occlusion-Handling"><a href="#CVPR-2010-Multi-Cue-Pedestrian-Classification-With-Partial-Occlusion-Handling" class="headerlink" title="[CVPR-2010] Multi-Cue Pedestrian Classification With Partial Occlusion Handling"></a>[CVPR-2010] Multi-Cue Pedestrian Classification With Partial Occlusion Handling</h3><p><img src="./1537260117170.png" alt="Alt text| left | 300x0"></p><ul><li>paper: <a href="https://ieeexplore.ieee.org/abstract/document/5540111/" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/5540111/</a></li><li>project website: </li><li>slides: </li><li>github caffe: </li></ul><h2 id="行人检测数据集"><a href="#行人检测数据集" class="headerlink" title="行人检测数据集"></a>行人检测数据集</h2><h3 id="CityPersons"><a href="#CityPersons" class="headerlink" title="CityPersons"></a>CityPersons</h3><p><img src="./1534569661113.png" alt="Alt text"></p><p>CityPersons数据集是在Cityscapes数据集基础上建立的，使用了Cityscapes数据集的数据，对一些类别进行了精确的标注。该数据集是在[CVPR-2017] CityPersons: A Diverse Dataset for Pedestrian Detection这篇论文中提出的，更多细节可以通过阅读该论文了解。</p><p>上图中左侧是行人标注，右侧是原始的CityScapes数据集。</p><ul><li><a href="https://bitbucket.org/shanshanzhang/citypersons" target="_blank" rel="noopener"><strong>标注和评估文件</strong></a></li><li><a href="https://www.cityscapes-dataset.com/" target="_blank" rel="noopener"><strong>数据集下载</strong></a></li></ul><p>文件格式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#评测文件</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/evaluation/eval_script/coco.py</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/evaluation/eval_script/eval_demo.py</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/evaluation/eval_script/eval_MR_multisetup.py</span><br><span class="line"></span><br><span class="line">#注释文件</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/annotations</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/annotations/anno_train.mat</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/annotations/anno_val.mat</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/annotations/README.txt</span><br><span class="line">#图片数据</span><br><span class="line"></span><br><span class="line">$/Cityscapes/leftImg8bit/train/*</span><br><span class="line">$/Cityscapes/leftImg8bit/val/*</span><br><span class="line">$/Cityscapes/leftImg8bit/test/*</span><br></pre></td></tr></table></figure><p>注释文件格式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">CityPersons annotations</span><br><span class="line">(1) data structure: </span><br><span class="line">    one image per cell</span><br><span class="line">    in each cell, there are three fields: city_name; im_name; bbs (bounding box annotations)</span><br><span class="line"></span><br><span class="line">(2) bounding box annotation format:</span><br><span class="line">　　 one object instance per row:</span><br><span class="line">　　 [class_label, x1,y1,w,h, instance_id, x1_vis, y1_vis, w_vis, h_vis]</span><br><span class="line"></span><br><span class="line">(3) class label definition:</span><br><span class="line">　 class_label =0: ignore regions (fake humans, e.g. people on posters, reflections etc.)</span><br><span class="line">    class_label =1: pedestrians</span><br><span class="line">    class_label =2: riders</span><br><span class="line">    class_label =3: sitting persons</span><br><span class="line">    class_label =4: other persons with unusual postures</span><br><span class="line">    class_label =5: group of people</span><br><span class="line"></span><br><span class="line">(4) boxes:</span><br><span class="line">　　visible boxes [x1_vis, y1_vis, w_vis, h_vis] are automatically generated from segmentation masks; </span><br><span class="line">      (x1,y1) is the upper left corner.</span><br><span class="line">      if class_label==1 or 2</span><br><span class="line">        [x1,y1,w,h] is a well-aligned bounding box to the full body ;</span><br><span class="line">      else</span><br><span class="line">        [x1,y1,w,h] = [x1_vis, y1_vis, w_vis, h_vis];</span><br></pre></td></tr></table></figure></p><h3 id="Caltech"><a href="#Caltech" class="headerlink" title="Caltech"></a>Caltech</h3><p><img src="1517407508293.png" alt="caltech"></p><ul><li><a href="http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/" target="_blank" rel="noopener"><strong>Caltech官网</strong></a><br>更所细节请阅读这篇论文，<br><a href="http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/files/PAMI12pedestrians.pdf" target="_blank" rel="noopener">[TAPAMI-2012] Pedestrian Detection: An Evaluation of the State of the Art</a></li></ul><p><img src="./1534570096814.png" alt="Alt text"></p><h3 id="KITTI"><a href="#KITTI" class="headerlink" title="KITTI"></a>KITTI</h3><p><img src="./1534569869602.png" alt="Alt text"></p><ul><li><a href="http://www.cvlibs.net/datasets/kitti/" target="_blank" rel="noopener"><strong>KITTI官网</strong></a></li></ul>]]></content>
    
    <summary type="html">
    
      行人检测（Pedestrian Detection）论文整理，包含论文链接和代码地址。
    
    </summary>
    
    
      <category term="Pedestrian Detection" scheme="https://www.starlg.cn/tags/Pedestrian-Detection/"/>
    
  </entry>
  
  <entry>
    <title>Keras Tutorial</title>
    <link href="https://www.starlg.cn/2018/08/14/Keras-Tutorial/"/>
    <id>https://www.starlg.cn/2018/08/14/Keras-Tutorial/</id>
    <published>2018-08-14T14:40:03.000Z</published>
    <updated>2018-09-11T13:13:39.717Z</updated>
    
    <content type="html"><![CDATA[<p>Github地址：<a href="https://github.com/xingkongliang/Keras-Tutorials" target="_blank" rel="noopener">here</a></p><h1 id="Keras-Tutorials"><a href="#Keras-Tutorials" class="headerlink" title="Keras-Tutorials"></a>Keras-Tutorials</h1><blockquote><p>版本：0.0.1</p></blockquote><blockquote><p>作者：张天亮</p></blockquote><blockquote><p>邮箱：<a href="mailto:zhangtianliang13@mails.ucas.ac.cn" target="_blank" rel="noopener">zhangtianliang13@mails.ucas.ac.cn</a></p></blockquote><p>Github 加载 .ipynb 的速度较慢，建议在 <a href="http://nbviewer.ipython.org/github/xingkongliang/Keras-Tutorials" target="_blank" rel="noopener">Nbviewer</a> 中查看该项目。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>大部分内容来自keras项目中的<a href="https://github.com/fchollet/keras/tree/master/examples" target="_blank" rel="noopener">examples</a></p><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/01.mnist_mpl.ipynb" target="_blank" rel="noopener">01.多层感知机实现</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/02.save_model.ipynb" target="_blank" rel="noopener">02.模型的保存</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/03.load_model.ipynb" target="_blank" rel="noopener">03.模型的加载</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/04.plot_acc_loss.ipynb" target="_blank" rel="noopener">04.绘制精度和损失曲线</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/05.mnist_cnn.ipynb" target="_blank" rel="noopener">05.卷积神经网络实现</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/06.cifar10_cnn.ipynb" target="_blank" rel="noopener">06.CIFAR10_cnn</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/07.mnist_lstm.ipynb" target="_blank" rel="noopener">07.mnist_lstm</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/08.vgg-16.ipynb" target="_blank" rel="noopener">08.VGG16调用</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/09.conv_filter_visualization.ipynb" target="_blank" rel="noopener">09.卷积滤波器可视化</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/10.variational_autoencoder.ipynb" target="_blank" rel="noopener">10.variational_autoencoder</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/11.mnist_transfer_cnn.ipynb" target="_blank" rel="noopener">11.锁定层fine-tuning网络</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/12.mnist_sklearn_wrapper.ipynb" target="_blank" rel="noopener">12.使用sklearn wrapper进行的参数搜索</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/13.Keras_with_tensorflow.ipynb" target="_blank" rel="noopener">13.Keras和Tensorflow联合使用</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/14.finetune_InceptionV3.ipynb" target="_blank" rel="noopener">14.Finetune InceptionV3样例</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/15.autoencoder.ipynb" target="_blank" rel="noopener">15.自编码器</a></li><li><a href="https://github.com/xingkongliang/Keras-Tutorials/blob/master/16.Convolutional_autoencoder.ipynb" target="_blank" rel="noopener">16.卷积自编码器</a></li></ul><p>更多Keras使用方法请查看手册</p><ul><li><a href="http://keras-cn.readthedocs.io/en/latest/" target="_blank" rel="noopener">中文手册</a></li><li><a href="https://keras.io/" target="_blank" rel="noopener">英文手册</a></li><li><a href="https://github.com/fchollet/keras" target="_blank" rel="noopener">github</a></li></ul>]]></content>
    
    <summary type="html">
    
      Keras基本教程，jupyter notebook。
    
    </summary>
    
      <category term="Deep Learning" scheme="https://www.starlg.cn/categories/Deep-Learning/"/>
    
    
      <category term="Keras" scheme="https://www.starlg.cn/tags/Keras/"/>
    
  </entry>
  
  <entry>
    <title>Generative Adversarial Nets</title>
    <link href="https://www.starlg.cn/2018/08/14/Generative-Adversarial-Nets/"/>
    <id>https://www.starlg.cn/2018/08/14/Generative-Adversarial-Nets/</id>
    <published>2018-08-14T13:21:12.000Z</published>
    <updated>2018-08-14T14:45:18.283Z</updated>
    
    <content type="html"><![CDATA[<h2 id="DCGANs-in-TensorFlow"><a href="#DCGANs-in-TensorFlow" class="headerlink" title="DCGANs in TensorFlow"></a>DCGANs in TensorFlow</h2><p><a href="https://github.com/carpedm20/DCGAN-tensorflow" target="_blank" rel="noopener">carpedm20/DCGAN-tensorflow</a><br>我们定义网络结构：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(self, z)</span>:</span></span><br><span class="line">    self.z_, self.h0_w, self.h0_b = linear(z, self.gf_dim*<span class="number">8</span>*<span class="number">4</span>*<span class="number">4</span>,</span><br><span class="line">                                           <span class="string">'g_h0_lin'</span>, with_w=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    self.h0 = tf.reshape(self.z_, [<span class="number">-1</span>, <span class="number">4</span>, <span class="number">4</span>, self.gf_dim * <span class="number">8</span>])</span><br><span class="line">    h0 = tf.nn.relu(self.g_bn0(self.h0))</span><br><span class="line"></span><br><span class="line">    self.h1, self.h1_w, self.h1_b = conv2d_transpose(h0,</span><br><span class="line">        [self.batch_size, <span class="number">8</span>, <span class="number">8</span>, self.gf_dim*<span class="number">4</span>], name=<span class="string">'g_h1'</span>, with_w=<span class="keyword">True</span>)</span><br><span class="line">    h1 = tf.nn.relu(self.g_bn1(self.h1))</span><br><span class="line"></span><br><span class="line">    h2, self.h2_w, self.h2_b = conv2d_transpose(h1,</span><br><span class="line">        [self.batch_size, <span class="number">16</span>, <span class="number">16</span>, self.gf_dim*<span class="number">2</span>], name=<span class="string">'g_h2'</span>, with_w=<span class="keyword">True</span>)</span><br><span class="line">    h2 = tf.nn.relu(self.g_bn2(h2))</span><br><span class="line"></span><br><span class="line">    h3, self.h3_w, self.h3_b = conv2d_transpose(h2,</span><br><span class="line">        [self.batch_size, <span class="number">32</span>, <span class="number">32</span>, self.gf_dim*<span class="number">1</span>], name=<span class="string">'g_h3'</span>, with_w=<span class="keyword">True</span>)</span><br><span class="line">    h3 = tf.nn.relu(self.g_bn3(h3))</span><br><span class="line"></span><br><span class="line">    h4, self.h4_w, self.h4_b = conv2d_transpose(h3,</span><br><span class="line">        [self.batch_size, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>], name=<span class="string">'g_h4'</span>, with_w=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.nn.tanh(h4)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(self, image, reuse=False)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> reuse:</span><br><span class="line">        tf.get_variable_scope().reuse_variables()</span><br><span class="line"></span><br><span class="line">    h0 = lrelu(conv2d(image, self.df_dim, name=<span class="string">'d_h0_conv'</span>))</span><br><span class="line">    h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim*<span class="number">2</span>, name=<span class="string">'d_h1_conv'</span>)))</span><br><span class="line">    h2 = lrelu(self.d_bn2(conv2d(h1, self.df_dim*<span class="number">4</span>, name=<span class="string">'d_h2_conv'</span>)))</span><br><span class="line">    h3 = lrelu(self.d_bn3(conv2d(h2, self.df_dim*<span class="number">8</span>, name=<span class="string">'d_h3_conv'</span>)))</span><br><span class="line">    h4 = linear(tf.reshape(h3, [<span class="number">-1</span>, <span class="number">8192</span>]), <span class="number">1</span>, <span class="string">'d_h3_lin'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.nn.sigmoid(h4), h4</span><br></pre></td></tr></table></figure><p>当我们初始化这个类时，我们将使用这些函数来创建模型。 我们需要两个版本的鉴别器共享（或重用）参数。 一个用于来自数据分布的图像的minibatch，另一个用于来自发生器的图像的minibatch。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.G = self.generator(self.z)</span><br><span class="line">self.D, self.D_logits = self.discriminator(self.images)</span><br><span class="line">self.D_, self.D_logits_ = self.discriminator(self.G, reuse=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>接下来我们定义损失函数。我们在D的预测值和我们理想的判别器输出值之间使用<a href="https://en.wikipedia.org/wiki/Cross_entropy" target="_blank" rel="noopener">交叉熵</a>，而没有只用求和，因为这样的效果更好。判别器希望对“真实”数据的预测全部是1，并且来自生成器的“假”数据的预测全部是零。生成器希望判别器对所有假样本的预测都是1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">self.d_loss_real = tf.reduce_mean(</span><br><span class="line">    tf.nn.sigmoid_cross_entropy_with_logits(self.D_logits,</span><br><span class="line">                                            tf.ones_like(self.D)))</span><br><span class="line">self.d_loss_fake = tf.reduce_mean(</span><br><span class="line">    tf.nn.sigmoid_cross_entropy_with_logits(self.D_logits_,</span><br><span class="line">                                            tf.zeros_like(self.D_)))</span><br><span class="line">self.d_loss = self.d_loss_real + self.d_loss_fake</span><br><span class="line"></span><br><span class="line">self.g_loss = tf.reduce_mean(</span><br><span class="line">    tf.nn.sigmoid_cross_entropy_with_logits(self.D_logits_,</span><br><span class="line">                                            tf.ones_like(self.D_)))</span><br></pre></td></tr></table></figure><p>收集每个模型的变量，以便可以单独进行训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">t_vars = tf.trainable_variables()</span><br><span class="line"></span><br><span class="line">self.d_vars = [var <span class="keyword">for</span> var <span class="keyword">in</span> t_vars <span class="keyword">if</span> <span class="string">'d_'</span> <span class="keyword">in</span> var.name]</span><br><span class="line">self.g_vars = [var <span class="keyword">for</span> var <span class="keyword">in</span> t_vars <span class="keyword">if</span> <span class="string">'g_'</span> <span class="keyword">in</span> var.name]</span><br></pre></td></tr></table></figure><p>现在我们准备好优化参数，我们将使用<a href="https://arxiv.org/abs/1412.6980" target="_blank" rel="noopener">ADAM</a>，这是一种在现代深度学习中常见的自适应非凸优化方法。ADAM通常与SGD竞争，并且（通常）不需要手动调节学习速率，动量和其他超参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">d_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \</span><br><span class="line">                    .minimize(self.d_loss, var_list=self.d_vars)</span><br><span class="line">g_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \</span><br><span class="line">                    .minimize(self.g_loss, var_list=self.g_vars)</span><br></pre></td></tr></table></figure><p>我们已经准备好了解我们的数据。在每个epoch中，我们在每个minibatch中采样一些图像，并且运行优化器更新网络。有趣的是，如果G仅更新一次，判别器的损失则不会为零。另外，我认为<code>d_loss_fake</code>和<code>d_loss_real</code>在最后的额外的调用回到是一点点不必要的计算，并且是冗余的，因为这些值是作为<code>d_optim</code>和<code>g_optim</code>的一部分计算的。作为TensorFlow中的练习，您可以尝试优化此部分并将RP发送到原始库。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> xrange(config.epoch):</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> xrange(<span class="number">0</span>, batch_idxs):</span><br><span class="line">        batch_images = ...</span><br><span class="line">        batch_z = np.random.uniform(<span class="number">-1</span>, <span class="number">1</span>, [config.batch_size, self.z_dim]) \</span><br><span class="line">                    .astype(np.float32)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update D network</span></span><br><span class="line">        _, summary_str = self.sess.run([d_optim, self.d_sum],</span><br><span class="line">            feed_dict=&#123; self.images: batch_images, self.z: batch_z &#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update G network</span></span><br><span class="line">        _, summary_str = self.sess.run([g_optim, self.g_sum],</span><br><span class="line">            feed_dict=&#123; self.z: batch_z &#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Run g_optim twice to make sure that d_loss does not go to zero</span></span><br><span class="line">        <span class="comment"># (different from paper)</span></span><br><span class="line">        _, summary_str = self.sess.run([g_optim, self.g_sum],</span><br><span class="line">            feed_dict=&#123; self.z: batch_z &#125;)</span><br><span class="line"></span><br><span class="line">        errD_fake = self.d_loss_fake.eval(&#123;self.z: batch_z&#125;)</span><br><span class="line">        errD_real = self.d_loss_real.eval(&#123;self.images: batch_images&#125;)</span><br><span class="line">        errG = self.g_loss.eval(&#123;self.z: batch_z&#125;)</span><br></pre></td></tr></table></figure><h3 id="Generative-Adversarial-Networks代码整理"><a href="#Generative-Adversarial-Networks代码整理" class="headerlink" title="Generative Adversarial Networks代码整理"></a>Generative Adversarial Networks代码整理</h3><ul><li><p><a href="https://github.com/openai/InfoGAN" target="_blank" rel="noopener"><strong>InfoGAN-TensorFlow</strong></a>:InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</p></li><li><p><a href="https://github.com/junyanz/iGAN" target="_blank" rel="noopener"><strong>iGAN-Theano</strong></a>:Generative Visual Manipulation on the Natural Image Manifold</p></li><li><p><a href="https://github.com/LantaoYu/SeqGAN" target="_blank" rel="noopener"><strong>SeqGAN-TensorFlow</strong></a>:SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient</p></li><li><p><a href="https://github.com/carpedm20/DCGAN-tensorflow" target="_blank" rel="noopener"><strong>DCGAN-Tensorflow</strong></a>:Deep Convolutional Generative Adversarial Networks </p></li><li><p><a href="https://github.com/Newmu/dcgan_code" target="_blank" rel="noopener"><strong>dcgan_code-Theano</strong></a>:Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</p></li><li><p><a href="https://github.com/openai/improved-gan" target="_blank" rel="noopener"><strong>improved-gan-Theano</strong></a>:Improved Techniques for Training GANs</p></li><li><p><a href="https://github.com/mattya/chainer-DCGAN" target="_blank" rel="noopener"><strong>chainer-DCGAN</strong></a>:Chainer implementation of Deep Convolutional Generative Adversarial Network</p></li><li><p><a href="https://github.com/jacobgil/keras-dcgan" target="_blank" rel="noopener"><strong>keras-dcgan</strong></a></p></li></ul>]]></content>
    
    <summary type="html">
    
      一些GANs资料和简单代码解析。
    
    </summary>
    
      <category term="Deep Learning" scheme="https://www.starlg.cn/categories/Deep-Learning/"/>
    
    
      <category term="GAN" scheme="https://www.starlg.cn/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>How to use hexo?</title>
    <link href="https://www.starlg.cn/2018/08/14/How-to-use-hexo/"/>
    <id>https://www.starlg.cn/2018/08/14/How-to-use-hexo/</id>
    <published>2018-08-14T07:21:22.000Z</published>
    <updated>2018-09-02T14:33:26.398Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Hexo基本指令"><a href="#Hexo基本指令" class="headerlink" title="Hexo基本指令"></a>Hexo基本指令</h2><h3 id="init"><a href="#init" class="headerlink" title="init"></a>init</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo init [folder]</span><br></pre></td></tr></table></figure><p>新建一个网站，如果没有设置｀folder｀，Hexo默认在目前的文件夹建立网站。</p><h3 id="new"><a href="#new" class="headerlink" title="new"></a>new</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new [layout] &lt;title&gt;</span><br></pre></td></tr></table></figure><p>新建一片文章。如果没有设置<code>layout</code>的话，默认使用_config.yml中的default_layout参数代替。如果标题包含空格的话，请使用引号括起来。</p><h3 id="generate"><a href="#generate" class="headerlink" title="generate"></a>generate</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br><span class="line">$ hexo g  # 简写</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="publish"><a href="#publish" class="headerlink" title="publish"></a>publish</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo publish [layout] &lt;filename&gt;</span><br></pre></td></tr></table></figure><p>发表草稿。</p><h3 id="server"><a href="#server" class="headerlink" title="server"></a>server</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>启动服务器。默认情况下，访问网址为：<code>http://localhost:4000/</code>。</p><table><thead><tr><th style="text-align:center">选项</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center"><code>-p</code>,<code>--port</code></td><td style="text-align:center">重设端口</td></tr><tr><td style="text-align:center"><code>-s</code>, <code>--static</code></td><td style="text-align:center">只使用静态文本</td></tr><tr><td style="text-align:center"><code>-l</code>,<code>--log</code></td><td style="text-align:center">启动日记记录，使用覆盖记录格式</td></tr></tbody></table><h3 id="deploy"><a href="#deploy" class="headerlink" title="deploy"></a>deploy</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br><span class="line">$ hexo d  # 简写</span><br></pre></td></tr></table></figure><h3 id="render"><a href="#render" class="headerlink" title="render"></a>render</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo render &lt;file1&gt; [file2] ...</span><br></pre></td></tr></table></figure><p>渲染文件。</p><h3 id="clean"><a href="#clean" class="headerlink" title="clean"></a>clean</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean</span><br></pre></td></tr></table></figure><p>清楚缓存文件(<code>db.json</code>)好已经生成的静态文件(<code>public</code>)。</p><p>在某些情况(尤其是更换主题后)，如果发现您对站点的更改没有生效，可以使用此命令。</p><h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo list &lt;type&gt;</span><br></pre></td></tr></table></figure><p>列出网站资料。</p><h3 id="version"><a href="#version" class="headerlink" title="version"></a>version</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo version</span><br></pre></td></tr></table></figure><p>显示Hexo版本。</p><h3 id="显示草稿"><a href="#显示草稿" class="headerlink" title="显示草稿"></a>显示草稿</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo --draft</span><br></pre></td></tr></table></figure><p>显示<code>source/_drafts</code>文件夹中的草稿文件。</p><h3 id="自定义CWD"><a href="#自定义CWD" class="headerlink" title="自定义CWD"></a>自定义CWD</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo --cwd /path/to/cwd</span><br></pre></td></tr></table></figure><p>自定义当前工作目录(Current working dirctory)的路径。</p><h3 id="在主页截断"><a href="#在主页截断" class="headerlink" title="在主页截断"></a>在主页截断</h3><ul><li><p>方法1:<br>在文中插入以下代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--more--&gt;</span><br></pre></td></tr></table></figure></li><li><p>方法2:<br>在文章中的<code>front-matter</code>中添加description，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: </span><br><span class="line">date: 2018-08-14 15:21:22</span><br><span class="line">categories: </span><br><span class="line">tags: </span><br><span class="line">description: 描述。。</span><br><span class="line">---</span><br></pre></td></tr></table></figure></li></ul><h3 id="分类和标签"><a href="#分类和标签" class="headerlink" title="分类和标签"></a>分类和标签</h3><p>只有文章支持分类和标签，您可以在 Front-matter 中设置。在其他系统中，分类和标签听起来很接近，但是在 Hexo 中两者有着明显的差别：分类具有顺序性和层次性，也就是说 <code>Foo</code>, <code>Bar</code> 不等于 <code>Bar</code>, <code>Foo</code>；而标签没有顺序和层次。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">categories:</span><br><span class="line">- Diary</span><br><span class="line">tags:</span><br><span class="line">- PS3</span><br><span class="line">- Games</span><br></pre></td></tr></table></figure><h3 id="定义一段代码。"><a href="#定义一段代码。" class="headerlink" title="定义一段代码。"></a>定义一段代码。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    print(<span class="string">'now is '</span>, i)</span><br></pre></td></tr></table></figure><p>显示一幅图像。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;% asset_img 003.jpg This is an example image %&#125;</span><br></pre></td></tr></table></figure></p><img src="/2018/08/14/How-to-use-hexo/003.jpg" title="This is an example image"><h2 id="Hexo-资源"><a href="#Hexo-资源" class="headerlink" title="Hexo 资源"></a>Hexo 资源</h2><p><a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">hexo官网</a></p><p><a href="http://theme-next.iissnan.com/" target="_blank" rel="noopener">theme-next使用说明</a></p><p><a href="https://www.zhihu.com/question/21193762" target="_blank" rel="noopener">使用hexo，如果换了电脑怎么更新博客？</a></p><p>其他参考博客：<br><a href="https://blog.csdn.net/u011475210/article/details/79023429" target="_blank" rel="noopener">我的个人博客之旅：从jekyll到hexo</a><br><a href="http://mashirosorata.vicp.io/HEXO-NEXT%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE.html" target="_blank" rel="noopener">HEXO+NEXT主题个性化配置</a></p><p><a href="https://segmentfault.com/a/1190000009544924#articleHeader21" target="_blank" rel="noopener">hexo的next主题个性化配置教程</a></p><p><a href="http://blog.csdn.net/MasterAnt_D/article/details/56839222#t50" target="_blank" rel="noopener">基于Hexo+Node.js+github+coding搭建个人博客——进阶篇(从入门到入土)</a></p>]]></content>
    
    <summary type="html">
    
      使用Hexo的基本方法。
    
    </summary>
    
    
  </entry>
  
</feed>
